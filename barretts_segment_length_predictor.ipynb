{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd9df2e",
   "metadata": {},
   "source": [
    "Import external libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb6511d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classes and Methods for R developed in the\n",
      "Political Science Computational Laboratory\n",
      "Department of Political Science\n",
      "Stanford University\n",
      "Simon Jackman\n",
      "hurdle and zeroinfl functions by Achim Zeileis\n",
      "Loading required package: lattice\n",
      "Loading required package: ggplot2\n",
      "Registered S3 methods overwritten by 'ggplot2':\n",
      "  method         from \n",
      "  [.quosures     rlang\n",
      "  c.quosures     rlang\n",
      "  print.quosures rlang\n",
      "Warning message:\n",
      "“package ‘yardstick’ was built under R version 3.6.3”For binary classification, the first factor level is assumed to be the event.\n",
      "Use the argument `event_level = \"second\"` to alter this as needed.\n",
      "\n",
      "Attaching package: ‘yardstick’\n",
      "\n",
      "The following objects are masked from ‘package:caret’:\n",
      "\n",
      "    precision, recall, sensitivity, specificity\n",
      "\n",
      "\n",
      "Attaching package: ‘MLmetrics’\n",
      "\n",
      "The following objects are masked from ‘package:caret’:\n",
      "\n",
      "    MAE, RMSE\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    Recall\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#install.packages(\"dplyr\")\n",
    "library(\"readxl\")\n",
    "library(\"pscl\")\n",
    "library(caret)\n",
    "library(yardstick)\n",
    "library(data.table)\n",
    "library(MLmetrics)\n",
    "library(ggplot2)\n",
    "library(MASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62f6efa",
   "metadata": {},
   "source": [
    "Read in tile count data for BEST2 and BEST3 and manual count data for BEST3. Change paths to ```barretts-segment-length-predictor``` directory as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dd6c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best2_tff3_tile_data <- read_excel(\"~/Documents/barrets-segment-length-predictor/data/BEST2_TFF3_AND_GASTRIC_TILE_COUNTS_QC_PASSING.xlsx\")\n",
    "best2_prague_length_data <- read_excel(\"~/Documents/barrets-segment-length-predictor/data/BEST2_ENDOSCOPY_CRF_CLEANED_SHORTENED.xlsx\")\n",
    "best3_tff3_tile_data <- read_excel('~/Documents/barrets-segment-length-predictor/data/BEST3_TFF3_AND_GASTRIC_TILE_COUNTS_QC_PASSING.xlsx')\n",
    "best3_prague_length_data <- read.csv('~/Documents/barrets-segment-length-predictor/data/BEST3_ENDOSCOPY_CRF_CLEANED.csv')\n",
    "best3_manual_tff3_data <- read_excel(\"~/Documents/barrets-segment-length-predictor/data/BEST3_TFF3_MANUAL_COUNTS.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7d58df",
   "metadata": {},
   "source": [
    "Explore relationship between manual count of TFF3 positive gland groups and C and M segment lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c4ba93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Prague C ~ TFF3 positive manual gland count slide1 Spearman rho\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.39142142645184"
      ],
      "text/latex": [
       "0.39142142645184"
      ],
      "text/markdown": [
       "0.39142142645184"
      ],
      "text/plain": [
       "[1] 0.3914214"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Prague C ~ TFF3 positive manual gland count slide2 Spearman rho\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.377594317800165"
      ],
      "text/latex": [
       "0.377594317800165"
      ],
      "text/markdown": [
       "0.377594317800165"
      ],
      "text/plain": [
       "[1] 0.3775943"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Prague C ~ TFF3 positive manual gland count avg Spearman rho\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.384029311069795"
      ],
      "text/latex": [
       "0.384029311069795"
      ],
      "text/markdown": [
       "0.384029311069795"
      ],
      "text/plain": [
       "[1] 0.3840293"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Prague M ~ TFF3 positive manual gland count slide1 Spearman rho\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.428494636142958"
      ],
      "text/latex": [
       "0.428494636142958"
      ],
      "text/markdown": [
       "0.428494636142958"
      ],
      "text/plain": [
       "[1] 0.4284946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Prague M ~ TFF3 positive manual gland count slide2 Spearman rho\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.395015183520179"
      ],
      "text/latex": [
       "0.395015183520179"
      ],
      "text/markdown": [
       "0.395015183520179"
      ],
      "text/plain": [
       "[1] 0.3950152"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Prague M ~ TFF3 positive manual gland count avg Spearman rho\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.418917534593376"
      ],
      "text/latex": [
       "0.418917534593376"
      ],
      "text/markdown": [
       "0.418917534593376"
      ],
      "text/plain": [
       "[1] 0.4189175"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# remove rows missing count or segment length data\n",
    "best3_manual_tff3_data <- setDT(best3_manual_tff3_data)\n",
    "best3_manual_tff3_data <- na.omit(best3_manual_tff3_data, \n",
    "                                  cols=c('TFF3CountSlide1', 'TFF3CountSlide2', 'PragueCLength', 'PragueMLength'))\n",
    "\n",
    "# add columns aggregating the counts of the two slides for each patient\n",
    "best3_manual_tff3_data$TFF3CountSlideSum <- best3_manual_tff3_data$TFF3CountSlide1 + best3_manual_tff3_data$TFF3CountSlide2\n",
    "best3_manual_tff3_data$TFF3CountSlideAvg <- best3_manual_tff3_data$TFF3CountSlideSum / 2\n",
    "\n",
    "# correlation metrics\n",
    "print('Prague C ~ TFF3 positive manual gland count slide1 Spearman rho')\n",
    "cor(best3_manual_tff3_data$TFF3CountSlide1, best3_manual_tff3_data$PragueCLength, method = c(\"spearman\"))\n",
    "\n",
    "print('Prague C ~ TFF3 positive manual gland count slide2 Spearman rho')\n",
    "cor(best3_manual_tff3_data$TFF3CountSlide2, best3_manual_tff3_data$PragueCLength, method = c(\"spearman\"))\n",
    "\n",
    "print('Prague C ~ TFF3 positive manual gland count avg Spearman rho')\n",
    "cor(best3_manual_tff3_data$TFF3CountSlideAvg, best3_manual_tff3_data$PragueCLength, method = c(\"spearman\"))\n",
    "\n",
    "print('Prague M ~ TFF3 positive manual gland count slide1 Spearman rho')\n",
    "cor(best3_manual_tff3_data$TFF3CountSlide1, best3_manual_tff3_data$PragueMLength, method = c(\"spearman\"))\n",
    "\n",
    "print('Prague M ~ TFF3 positive manual gland count slide2 Spearman rho')\n",
    "cor(best3_manual_tff3_data$TFF3CountSlide2, best3_manual_tff3_data$PragueMLength, method = c(\"spearman\"))\n",
    "\n",
    "print('Prague M ~ TFF3 positive manual gland count avg Spearman rho')\n",
    "cor(best3_manual_tff3_data$TFF3CountSlideAvg, best3_manual_tff3_data$PragueMLength, method = c(\"spearman\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01dc607",
   "metadata": {},
   "source": [
    "Plot BEST3 TFF3 manual count vs segment length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e43df633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAADAFBMVEUAAAABAQECAgIDAwME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\n",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAADAFBMVEUAAAABAQECAgIDAwME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\nMECQABj8f9nfKnHIQxm+AAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(best3_manual_tff3_data$PragueMLength, best3_manual_tff3_data$TFF3CountSlideAvg)\n",
    "plot(best3_manual_tff3_data$PragueCLength, best3_manual_tff3_data$TFF3CountSlideAvg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7845a83a",
   "metadata": {},
   "source": [
    "Merge data appropriately and add new columns for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "923c7d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge tile count and Prague length data and perform some cleaning tasks\n",
    "best2_tff3_prague_data = merge(best2_tff3_tile_data, best2_prague_length_data, by='Case')\n",
    "best3_tff3_prague_data = merge(best3_tff3_tile_data, best3_prague_length_data, by='Case')\n",
    "tff3_prague_data = rbind(best2_tff3_prague_data[, c('Case', 'Gastric_count', 'TFF3_positive_count', 'PRAGUE_C', 'PRAGUE_M')],\n",
    "                            best3_tff3_prague_data[, c('Case', 'Gastric_count', 'TFF3_positive_count', 'PRAGUE_C', 'PRAGUE_M')])\n",
    "tff3_prague_data$PRAGUE_C <- as.numeric(tff3_prague_data$PRAGUE_C)\n",
    "tff3_prague_data$PRAGUE_M <- as.numeric(tff3_prague_data$PRAGUE_M)\n",
    "tff3_prague_data$TFF3_positive_count <- as.numeric(tff3_prague_data$TFF3_positive_count)\n",
    "tff3_prague_data$Gastric_count <- as.numeric(tff3_prague_data$Gastric_count)\n",
    "\n",
    "\n",
    "# Add C≥1, C>=2, C>=3, M>=1, M≥3, M>=4, and M>=5 columns\n",
    "tff3_prague_data$PRAGUE_C_gtet_1cm <- ifelse(tff3_prague_data$PRAGUE_C >= 1, 1, 0)\n",
    "tff3_prague_data$PRAGUE_C_gtet_2cm <- ifelse(tff3_prague_data$PRAGUE_C >= 2, 1, 0)\n",
    "tff3_prague_data$PRAGUE_C_gtet_3cm <- ifelse(tff3_prague_data$PRAGUE_C >= 3, 1, 0)\n",
    "tff3_prague_data$PRAGUE_M_gtet_1cm <- ifelse(tff3_prague_data$PRAGUE_M >= 1, 1, 0)\n",
    "tff3_prague_data$PRAGUE_M_gtet_3cm <- ifelse(tff3_prague_data$PRAGUE_M >= 3, 1, 0)\n",
    "tff3_prague_data$PRAGUE_M_gtet_4cm <- ifelse(tff3_prague_data$PRAGUE_M >= 4, 1, 0)\n",
    "tff3_prague_data$PRAGUE_M_gtet_5cm <- ifelse(tff3_prague_data$PRAGUE_M >= 5, 1, 0)\n",
    "\n",
    "# Add C>=1 OR M>=1 column, a C≥1 OR M≥3 column, a C≥2 OR M≥4 colum, and a C≥3 OR M≥5 column\n",
    "tff3_prague_data$C_gtet_1_or_M_gtet_1 <- ifelse(tff3_prague_data$PRAGUE_C >= 1 | tff3_prague_data$PRAGUE_M >= 1, 1, 0)\n",
    "tff3_prague_data$C_gtet_1_or_M_gtet_3 <- ifelse(tff3_prague_data$PRAGUE_C >= 1 | tff3_prague_data$PRAGUE_M >= 3, 1, 0)\n",
    "tff3_prague_data$C_gtet_2_or_M_gtet_4 <- ifelse(tff3_prague_data$PRAGUE_C >= 2 | tff3_prague_data$PRAGUE_M >= 4, 1, 0)\n",
    "tff3_prague_data$C_gtet_3_or_M_gtet_5 <- ifelse(tff3_prague_data$PRAGUE_C >= 3 | tff3_prague_data$PRAGUE_M >= 5, 1, 0)\n",
    "\n",
    "\n",
    "\n",
    "# Create doubled C and M columns to have only integer values for Poisson regression models\n",
    "tff3_prague_data$PRAGUE_M_doubled <- tff3_prague_data$PRAGUE_M * 2\n",
    "tff3_prague_data$PRAGUE_C_doubled <- tff3_prague_data$PRAGUE_C * 2\n",
    "\n",
    "# Re-split data into BEST2 and BEST3 pieces\n",
    "best2_tff3_prague_data <- head(tff3_prague_data, nrow(best2_tff3_prague_data))\n",
    "best3_tff3_prague_data <- tail(tff3_prague_data, nrow(best3_tff3_prague_data))\n",
    "\n",
    "# Convert to data.table\n",
    "best2_tff3_prague_data <- setDT(best2_tff3_prague_data)\n",
    "best3_tff3_prague_data <- setDT(best3_tff3_prague_data)\n",
    "tff3_prague_data <- setDT(tff3_prague_data)\n",
    "\n",
    "\n",
    "# Create versions of the above data tables with no patients with no patients with TFF3 positive tile counts of 0\n",
    "best2_tff3_prague_data_nozeros <- best2_tff3_prague_data[best2_tff3_prague_data$TFF3_positive_count != 0,]\n",
    "best3_tff3_prague_data_nozeros <- best3_tff3_prague_data[best3_tff3_prague_data$TFF3_positive_count != 0,]\n",
    "tff3_prague_data_nozeros <- tff3_prague_data[tff3_prague_data$TFF3_positive_count != 0,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1197d17",
   "metadata": {},
   "source": [
    "Show how many patients have long segments by diagnostic criteria in BEST2 and BEST3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c130502a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"BEST2 long segment patients: 315\"\n",
      "[1] \"BEST3 long segment patients: 47\"\n",
      "[1] \"Total BEST2 patients: 529\"\n",
      "[1] \"Total BEST3 patients: 158\"\n"
     ]
    }
   ],
   "source": [
    "print(paste0(\"BEST2 long segment patients: \", sum(best2_tff3_prague_data$C_gtet_1_or_M_gtet_3)))\n",
    "print(paste0(\"BEST3 long segment patients: \", sum(best3_tff3_prague_data$C_gtet_1_or_M_gtet_3)))\n",
    "print(paste0(\"Total BEST2 patients: \", nrow(best2_tff3_prague_data)))\n",
    "print(paste0(\"Total BEST3 patients: \", nrow(best3_tff3_prague_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270b9471",
   "metadata": {},
   "source": [
    "Compute Spearman's correlation coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1252c622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Prague C ~ TFF3 positive tile count Spearman rho\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.7317658191829"
      ],
      "text/latex": [
       "0.7317658191829"
      ],
      "text/markdown": [
       "0.7317658191829"
      ],
      "text/plain": [
       "[1] 0.7317658"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Prague M ~ TFF3 positive tile count Spearman rho\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.772828108085845"
      ],
      "text/latex": [
       "0.772828108085845"
      ],
      "text/markdown": [
       "0.772828108085845"
      ],
      "text/plain": [
       "[1] 0.7728281"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Prague C ~ Gastric tile count Spearman rho\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "-0.0236222781209249"
      ],
      "text/latex": [
       "-0.0236222781209249"
      ],
      "text/markdown": [
       "-0.0236222781209249"
      ],
      "text/plain": [
       "[1] -0.02362228"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Prague M ~ Gastric tile count Spearman rho\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "-0.0462860111190123"
      ],
      "text/latex": [
       "-0.0462860111190123"
      ],
      "text/markdown": [
       "-0.0462860111190123"
      ],
      "text/plain": [
       "[1] -0.04628601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# correlation metrics\n",
    "print('Prague C ~ TFF3 positive tile count Spearman rho')\n",
    "cor(best2_tff3_prague_data$TFF3_positive_count, best2_tff3_prague_data$PRAGUE_C, method = c(\"spearman\"))\n",
    "print('Prague M ~ TFF3 positive tile count Spearman rho')\n",
    "cor(best2_tff3_prague_data$TFF3_positive_count, best2_tff3_prague_data$PRAGUE_M, method = c(\"spearman\"))\n",
    "print('Prague C ~ Gastric tile count Spearman rho')\n",
    "cor(best2_tff3_prague_data$Gastric_count, best2_tff3_prague_data$PRAGUE_C, method = c(\"spearman\"))\n",
    "print('Prague M ~ Gastric tile count Spearman rho')\n",
    "cor(best2_tff3_prague_data$Gastric_count, best2_tff3_prague_data$PRAGUE_M, method = c(\"spearman\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aea849",
   "metadata": {},
   "source": [
    "CLASSIFICATION SECTION\n",
    "\n",
    "Train 5-fold cross validation logistic regression models for predicting segment length class: (C≥1 OR M≥3) vs. (C<1 AND M<3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eddc1b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”"
     ]
    }
   ],
   "source": [
    "# create 5 folds for cross validation across 691 patients from BEST2 and BEST3 \n",
    "# (138 patients per val fold, 553 per training fold)\n",
    "set.seed(366)\n",
    "\n",
    "# For BEST2 only analyses\n",
    "tff3_prague_data_shuffled <- best2_tff3_prague_data[sample(nrow(best2_tff3_prague_data)),]\n",
    "\n",
    "# split folds into training and validation components\n",
    "fold_size = round(nrow(tff3_prague_data_shuffled)/5)\n",
    "n <- nrow(tff3_prague_data_shuffled)\n",
    "r  <- rep(1:ceiling(n/fold_size), each=fold_size)[1:n]\n",
    "d <- split(tff3_prague_data_shuffled, r)\n",
    "val1 <- d[[\"1\"]]\n",
    "val2 <- d[[\"2\"]]\n",
    "val3 <- d[[\"3\"]]\n",
    "val4 <- d[[\"4\"]]\n",
    "val5 <- d[[\"5\"]]\n",
    "train1 <- rbind(val2, val3, val4, val5)\n",
    "train2 <- rbind(val1, val3, val4, val5)\n",
    "train3 <- rbind(val1, val2, val4, val5)\n",
    "train4 <- rbind(val1, val2, val3, val5)\n",
    "train5 <- rbind(val1, val2, val3, val4)\n",
    "\n",
    "# 5-fold classification models trained on training components (C>=1 or M>=3)\n",
    "logreg_c_gtet_1cm_or_m_gtet_1cm_1 <- glm(C_gtet_1_or_M_gtet_1 ~ TFF3_positive_count, family='binomial', data = train1)\n",
    "logreg_c_gtet_1cm_or_m_gtet_1cm_2 <- glm(C_gtet_1_or_M_gtet_1 ~ TFF3_positive_count, family='binomial', data = train2)\n",
    "logreg_c_gtet_1cm_or_m_gtet_1cm_3 <- glm(C_gtet_1_or_M_gtet_1 ~ TFF3_positive_count, family='binomial', data = train3)\n",
    "logreg_c_gtet_1cm_or_m_gtet_1cm_4 <- glm(C_gtet_1_or_M_gtet_1 ~ TFF3_positive_count, family='binomial', data = train4)\n",
    "logreg_c_gtet_1cm_or_m_gtet_1cm_5 <- glm(C_gtet_1_or_M_gtet_1 ~ TFF3_positive_count, family='binomial', data = train5)\n",
    "\n",
    "# 5-fold classification models trained on training components (C>=1 or M>=3)\n",
    "logreg_c_gtet_1cm_or_m_gtet_3cm_1 <- glm(C_gtet_1_or_M_gtet_3 ~ TFF3_positive_count, family='binomial', data = train1)\n",
    "logreg_c_gtet_1cm_or_m_gtet_3cm_2 <- glm(C_gtet_1_or_M_gtet_3 ~ TFF3_positive_count, family='binomial', data = train2)\n",
    "logreg_c_gtet_1cm_or_m_gtet_3cm_3 <- glm(C_gtet_1_or_M_gtet_3 ~ TFF3_positive_count, family='binomial', data = train3)\n",
    "logreg_c_gtet_1cm_or_m_gtet_3cm_4 <- glm(C_gtet_1_or_M_gtet_3 ~ TFF3_positive_count, family='binomial', data = train4)\n",
    "logreg_c_gtet_1cm_or_m_gtet_3cm_5 <- glm(C_gtet_1_or_M_gtet_3 ~ TFF3_positive_count, family='binomial', data = train5)\n",
    "\n",
    "# 5-fold classification models trained on training components (C>=2 or M>=4)\n",
    "logreg_c_gtet_2cm_or_m_gtet_4cm_1 <- glm(C_gtet_2_or_M_gtet_4 ~ TFF3_positive_count, family='binomial', data = train1)\n",
    "logreg_c_gtet_2cm_or_m_gtet_4cm_2 <- glm(C_gtet_2_or_M_gtet_4 ~ TFF3_positive_count, family='binomial', data = train2)\n",
    "logreg_c_gtet_2cm_or_m_gtet_4cm_3 <- glm(C_gtet_2_or_M_gtet_4 ~ TFF3_positive_count, family='binomial', data = train3)\n",
    "logreg_c_gtet_2cm_or_m_gtet_4cm_4 <- glm(C_gtet_2_or_M_gtet_4 ~ TFF3_positive_count, family='binomial', data = train4)\n",
    "logreg_c_gtet_2cm_or_m_gtet_4cm_5 <- glm(C_gtet_2_or_M_gtet_4 ~ TFF3_positive_count, family='binomial', data = train5)\n",
    "\n",
    "# 5-fold classification models trained on training components (C>=3 or M>=5)\n",
    "logreg_c_gtet_3cm_or_m_gtet_5cm_1 <- glm(C_gtet_3_or_M_gtet_5 ~ TFF3_positive_count, family='binomial', data = train1)\n",
    "logreg_c_gtet_3cm_or_m_gtet_5cm_2 <- glm(C_gtet_3_or_M_gtet_5 ~ TFF3_positive_count, family='binomial', data = train2)\n",
    "logreg_c_gtet_3cm_or_m_gtet_5cm_3 <- glm(C_gtet_3_or_M_gtet_5 ~ TFF3_positive_count, family='binomial', data = train3)\n",
    "logreg_c_gtet_3cm_or_m_gtet_5cm_4 <- glm(C_gtet_3_or_M_gtet_5 ~ TFF3_positive_count, family='binomial', data = train4)\n",
    "logreg_c_gtet_3cm_or_m_gtet_5cm_5 <- glm(C_gtet_3_or_M_gtet_5 ~ TFF3_positive_count, family='binomial', data = train5)\n",
    "\n",
    "# 5-fold classification models trained on training components (C>=1)\n",
    "logreg_c_gtet_1cm_1 <- glm(PRAGUE_C_gtet_1cm ~ TFF3_positive_count, family='binomial', data = train1)\n",
    "logreg_c_gtet_1cm_2 <- glm(PRAGUE_C_gtet_1cm ~ TFF3_positive_count, family='binomial', data = train2)\n",
    "logreg_c_gtet_1cm_3 <- glm(PRAGUE_C_gtet_1cm ~ TFF3_positive_count, family='binomial', data = train3)\n",
    "logreg_c_gtet_1cm_4 <- glm(PRAGUE_C_gtet_1cm ~ TFF3_positive_count, family='binomial', data = train4)\n",
    "logreg_c_gtet_1cm_5 <- glm(PRAGUE_C_gtet_1cm ~ TFF3_positive_count, family='binomial', data = train5)\n",
    "\n",
    "# 5-fold classification models trained on training components (C>=2)\n",
    "logreg_c_gtet_2cm_1 <- glm(PRAGUE_C_gtet_2cm ~ TFF3_positive_count, family='binomial', data = train1)\n",
    "logreg_c_gtet_2cm_2 <- glm(PRAGUE_C_gtet_2cm ~ TFF3_positive_count, family='binomial', data = train2)\n",
    "logreg_c_gtet_2cm_3 <- glm(PRAGUE_C_gtet_2cm ~ TFF3_positive_count, family='binomial', data = train3)\n",
    "logreg_c_gtet_2cm_4 <- glm(PRAGUE_C_gtet_2cm ~ TFF3_positive_count, family='binomial', data = train4)\n",
    "logreg_c_gtet_2cm_5 <- glm(PRAGUE_C_gtet_2cm ~ TFF3_positive_count, family='binomial', data = train5)\n",
    "\n",
    "# 5-fold classification models trained on training components (C>=3)\n",
    "logreg_c_gtet_3cm_1 <- glm(PRAGUE_C_gtet_3cm ~ TFF3_positive_count, family='binomial', data = train1)\n",
    "logreg_c_gtet_3cm_2 <- glm(PRAGUE_C_gtet_3cm ~ TFF3_positive_count, family='binomial', data = train2)\n",
    "logreg_c_gtet_3cm_3 <- glm(PRAGUE_C_gtet_3cm ~ TFF3_positive_count, family='binomial', data = train3)\n",
    "logreg_c_gtet_3cm_4 <- glm(PRAGUE_C_gtet_3cm ~ TFF3_positive_count, family='binomial', data = train4)\n",
    "logreg_c_gtet_3cm_5 <- glm(PRAGUE_C_gtet_3cm ~ TFF3_positive_count, family='binomial', data = train5)\n",
    "\n",
    "# 5-fold classification models trained on training components (M>=1)\n",
    "logreg_m_gtet_1cm_1 <- glm(PRAGUE_M_gtet_1cm ~ TFF3_positive_count, family='binomial', data = train1)\n",
    "logreg_m_gtet_1cm_2 <- glm(PRAGUE_M_gtet_1cm ~ TFF3_positive_count, family='binomial', data = train2)\n",
    "logreg_m_gtet_1cm_3 <- glm(PRAGUE_M_gtet_1cm ~ TFF3_positive_count, family='binomial', data = train3)\n",
    "logreg_m_gtet_1cm_4 <- glm(PRAGUE_M_gtet_1cm ~ TFF3_positive_count, family='binomial', data = train4)\n",
    "logreg_m_gtet_1cm_5 <- glm(PRAGUE_M_gtet_1cm ~ TFF3_positive_count, family='binomial', data = train5)\n",
    "\n",
    "# 5-fold classification models trained on training components (M>=3)\n",
    "logreg_m_gtet_3cm_1 <- glm(PRAGUE_M_gtet_3cm ~ TFF3_positive_count, family='binomial', data = train1)\n",
    "logreg_m_gtet_3cm_2 <- glm(PRAGUE_M_gtet_3cm ~ TFF3_positive_count, family='binomial', data = train2)\n",
    "logreg_m_gtet_3cm_3 <- glm(PRAGUE_M_gtet_3cm ~ TFF3_positive_count, family='binomial', data = train3)\n",
    "logreg_m_gtet_3cm_4 <- glm(PRAGUE_M_gtet_3cm ~ TFF3_positive_count, family='binomial', data = train4)\n",
    "logreg_m_gtet_3cm_5 <- glm(PRAGUE_M_gtet_3cm ~ TFF3_positive_count, family='binomial', data = train5)\n",
    "\n",
    "# 5-fold classification models trained on training components (M>=4)\n",
    "logreg_m_gtet_4cm_1 <- glm(PRAGUE_M_gtet_4cm ~ TFF3_positive_count, family='binomial', data = train1)\n",
    "logreg_m_gtet_4cm_2 <- glm(PRAGUE_M_gtet_4cm ~ TFF3_positive_count, family='binomial', data = train2)\n",
    "logreg_m_gtet_4cm_3 <- glm(PRAGUE_M_gtet_4cm ~ TFF3_positive_count, family='binomial', data = train3)\n",
    "logreg_m_gtet_4cm_4 <- glm(PRAGUE_M_gtet_4cm ~ TFF3_positive_count, family='binomial', data = train4)\n",
    "logreg_m_gtet_4cm_5 <- glm(PRAGUE_M_gtet_4cm ~ TFF3_positive_count, family='binomial', data = train5)\n",
    "\n",
    "# 5-fold classification models trained on training components (M>=5)\n",
    "logreg_m_gtet_5cm_1 <- glm(PRAGUE_M_gtet_5cm ~ TFF3_positive_count, family='binomial', data = train1)\n",
    "logreg_m_gtet_5cm_2 <- glm(PRAGUE_M_gtet_5cm ~ TFF3_positive_count, family='binomial', data = train2)\n",
    "logreg_m_gtet_5cm_3 <- glm(PRAGUE_M_gtet_5cm ~ TFF3_positive_count, family='binomial', data = train3)\n",
    "logreg_m_gtet_5cm_4 <- glm(PRAGUE_M_gtet_5cm ~ TFF3_positive_count, family='binomial', data = train4)\n",
    "logreg_m_gtet_5cm_5 <- glm(PRAGUE_M_gtet_5cm ~ TFF3_positive_count, family='binomial', data = train5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d5b8af",
   "metadata": {},
   "source": [
    "We can now evalute model performance on validation component of each fold. Let's first define performance metric functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e7c7ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RSQUARE = function(y_actual,y_predict){\n",
    "  cor(y_actual,y_predict)^2\n",
    "}\n",
    "RMSE = function(y_actual, y_predict){\n",
    "    sqrt(mean((y_predict - y_actual)^2))\n",
    "}\n",
    "METRIFY = function(y_actual, y_predict, model){\n",
    "    acc = Accuracy(ifelse(y_predict >= 0.5, 1, 0), y_actual)\n",
    "    acc_balanced = bal_accuracy_vec(factor(y_actual), factor(ifelse(y_predict >= 0.5, 1, 0)))\n",
    "    prec_long = Precision(y_actual, ifelse(y_predict >= 0.5, 1, 0), positive=1)\n",
    "    prec_short = Precision(y_actual, ifelse(y_predict >= 0.5, 1, 0), positive=0)\n",
    "    rec_long = Recall(y_actual, ifelse(y_predict >= 0.5, 1, 0), positive=1)\n",
    "    rec_short = Recall(y_actual, ifelse(y_predict >= 0.5, 1, 0), positive=0)\n",
    "    f1_long = F1_Score(y_actual, ifelse(y_predict >= 0.5, 1, 0), positive=1)\n",
    "    f1_short = F1_Score(y_actual, ifelse(y_predict >= 0.5, 1, 0), positive=0)\n",
    "    tile_cutoff = unname(dose.p(model, p=0.5)[1])\n",
    "    tile_cutoff_se = unname(attr(dose.p(model, p=0.5), \"SE\"))\n",
    "    \n",
    "    list(Accuracy=acc, Balanced_acc=acc_balanced, Precision_long=prec_long, Precision_short=prec_short, \n",
    "         Recall_long=rec_long, Recall_short=rec_short, F1_long=f1_long, F1_short=f1_short, \n",
    "         Tile_cutoff=tile_cutoff, Tile_cutoff_SE=tile_cutoff_se)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb6cd7f",
   "metadata": {},
   "source": [
    "Get classification predictions for each fold on validation components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf490ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C>=1 or M>=1\n",
    "logreg_c_gtet_1cm_or_m_gtet_1cm_1_pred <- predict(logreg_c_gtet_1cm_or_m_gtet_1cm_1, newdata=data.frame(TFF3_positive_count=val1$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_1cm_or_m_gtet_1cm_2_pred <- predict(logreg_c_gtet_1cm_or_m_gtet_1cm_2, newdata=data.frame(TFF3_positive_count=val2$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_1cm_or_m_gtet_1cm_3_pred <- predict(logreg_c_gtet_1cm_or_m_gtet_1cm_3, newdata=data.frame(TFF3_positive_count=val3$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_1cm_or_m_gtet_1cm_4_pred <- predict(logreg_c_gtet_1cm_or_m_gtet_1cm_4, newdata=data.frame(TFF3_positive_count=val4$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_1cm_or_m_gtet_1cm_5_pred <- predict(logreg_c_gtet_1cm_or_m_gtet_1cm_5, newdata=data.frame(TFF3_positive_count=val5$TFF3_positive_count), type='response')\n",
    "\n",
    "# C>=1 or M>=3\n",
    "logreg_c_gtet_1cm_or_m_gtet_3cm_1_pred <- predict(logreg_c_gtet_1cm_or_m_gtet_3cm_1, newdata=data.frame(TFF3_positive_count=val1$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_1cm_or_m_gtet_3cm_2_pred <- predict(logreg_c_gtet_1cm_or_m_gtet_3cm_2, newdata=data.frame(TFF3_positive_count=val2$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_1cm_or_m_gtet_3cm_3_pred <- predict(logreg_c_gtet_1cm_or_m_gtet_3cm_3, newdata=data.frame(TFF3_positive_count=val3$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_1cm_or_m_gtet_3cm_4_pred <- predict(logreg_c_gtet_1cm_or_m_gtet_3cm_4, newdata=data.frame(TFF3_positive_count=val4$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_1cm_or_m_gtet_3cm_5_pred <- predict(logreg_c_gtet_1cm_or_m_gtet_3cm_5, newdata=data.frame(TFF3_positive_count=val5$TFF3_positive_count), type='response')\n",
    "\n",
    "# C>=2 or M>=4\n",
    "logreg_c_gtet_2cm_or_m_gtet_4cm_1_pred <- predict(logreg_c_gtet_2cm_or_m_gtet_4cm_1, newdata=data.frame(TFF3_positive_count=val1$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_2cm_or_m_gtet_4cm_2_pred <- predict(logreg_c_gtet_2cm_or_m_gtet_4cm_2, newdata=data.frame(TFF3_positive_count=val2$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_2cm_or_m_gtet_4cm_3_pred <- predict(logreg_c_gtet_2cm_or_m_gtet_4cm_3, newdata=data.frame(TFF3_positive_count=val3$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_2cm_or_m_gtet_4cm_4_pred <- predict(logreg_c_gtet_2cm_or_m_gtet_4cm_4, newdata=data.frame(TFF3_positive_count=val4$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_2cm_or_m_gtet_4cm_5_pred <- predict(logreg_c_gtet_2cm_or_m_gtet_4cm_5, newdata=data.frame(TFF3_positive_count=val5$TFF3_positive_count), type='response')\n",
    "\n",
    "# C>=3 or M>=5\n",
    "logreg_c_gtet_3cm_or_m_gtet_5cm_1_pred <- predict(logreg_c_gtet_3cm_or_m_gtet_5cm_1, newdata=data.frame(TFF3_positive_count=val1$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_3cm_or_m_gtet_5cm_2_pred <- predict(logreg_c_gtet_3cm_or_m_gtet_5cm_2, newdata=data.frame(TFF3_positive_count=val2$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_3cm_or_m_gtet_5cm_3_pred <- predict(logreg_c_gtet_3cm_or_m_gtet_5cm_3, newdata=data.frame(TFF3_positive_count=val3$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_3cm_or_m_gtet_5cm_4_pred <- predict(logreg_c_gtet_3cm_or_m_gtet_5cm_4, newdata=data.frame(TFF3_positive_count=val4$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_3cm_or_m_gtet_5cm_5_pred <- predict(logreg_c_gtet_3cm_or_m_gtet_5cm_5, newdata=data.frame(TFF3_positive_count=val5$TFF3_positive_count), type='response')\n",
    "\n",
    "# C>=1\n",
    "logreg_c_gtet_1cm_1_pred <- predict(logreg_c_gtet_1cm_1, newdata=data.frame(TFF3_positive_count=val1$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_1cm_2_pred <- predict(logreg_c_gtet_1cm_2, newdata=data.frame(TFF3_positive_count=val2$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_1cm_3_pred <- predict(logreg_c_gtet_1cm_3, newdata=data.frame(TFF3_positive_count=val3$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_1cm_4_pred <- predict(logreg_c_gtet_1cm_4, newdata=data.frame(TFF3_positive_count=val4$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_1cm_5_pred <- predict(logreg_c_gtet_1cm_5, newdata=data.frame(TFF3_positive_count=val5$TFF3_positive_count), type='response')\n",
    "\n",
    "# C>=2\n",
    "logreg_c_gtet_2cm_1_pred <- predict(logreg_c_gtet_2cm_1, newdata=data.frame(TFF3_positive_count=val1$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_2cm_2_pred <- predict(logreg_c_gtet_2cm_2, newdata=data.frame(TFF3_positive_count=val2$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_2cm_3_pred <- predict(logreg_c_gtet_2cm_3, newdata=data.frame(TFF3_positive_count=val3$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_2cm_4_pred <- predict(logreg_c_gtet_2cm_4, newdata=data.frame(TFF3_positive_count=val4$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_2cm_5_pred <- predict(logreg_c_gtet_2cm_5, newdata=data.frame(TFF3_positive_count=val5$TFF3_positive_count), type='response')\n",
    "\n",
    "# C>=3\n",
    "logreg_c_gtet_3cm_1_pred <- predict(logreg_c_gtet_3cm_1, newdata=data.frame(TFF3_positive_count=val1$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_3cm_2_pred <- predict(logreg_c_gtet_3cm_2, newdata=data.frame(TFF3_positive_count=val2$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_3cm_3_pred <- predict(logreg_c_gtet_3cm_3, newdata=data.frame(TFF3_positive_count=val3$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_3cm_4_pred <- predict(logreg_c_gtet_3cm_4, newdata=data.frame(TFF3_positive_count=val4$TFF3_positive_count), type='response')\n",
    "logreg_c_gtet_3cm_5_pred <- predict(logreg_c_gtet_3cm_5, newdata=data.frame(TFF3_positive_count=val5$TFF3_positive_count), type='response')\n",
    "\n",
    "# M>=1\n",
    "logreg_m_gtet_1cm_1_pred <- predict(logreg_m_gtet_1cm_1, newdata=data.frame(TFF3_positive_count=val1$TFF3_positive_count), type='response')\n",
    "logreg_m_gtet_1cm_2_pred <- predict(logreg_m_gtet_1cm_2, newdata=data.frame(TFF3_positive_count=val2$TFF3_positive_count), type='response')\n",
    "logreg_m_gtet_1cm_3_pred <- predict(logreg_m_gtet_1cm_3, newdata=data.frame(TFF3_positive_count=val3$TFF3_positive_count), type='response')\n",
    "logreg_m_gtet_1cm_4_pred <- predict(logreg_m_gtet_1cm_4, newdata=data.frame(TFF3_positive_count=val4$TFF3_positive_count), type='response')\n",
    "logreg_m_gtet_1cm_5_pred <- predict(logreg_m_gtet_1cm_5, newdata=data.frame(TFF3_positive_count=val5$TFF3_positive_count), type='response')\n",
    "\n",
    "# M>=3\n",
    "logreg_m_gtet_3cm_1_pred <- predict(logreg_m_gtet_3cm_1, newdata=data.frame(TFF3_positive_count=val1$TFF3_positive_count), type='response')\n",
    "logreg_m_gtet_3cm_2_pred <- predict(logreg_m_gtet_3cm_2, newdata=data.frame(TFF3_positive_count=val2$TFF3_positive_count), type='response')\n",
    "logreg_m_gtet_3cm_3_pred <- predict(logreg_m_gtet_3cm_3, newdata=data.frame(TFF3_positive_count=val3$TFF3_positive_count), type='response')\n",
    "logreg_m_gtet_3cm_4_pred <- predict(logreg_m_gtet_3cm_4, newdata=data.frame(TFF3_positive_count=val4$TFF3_positive_count), type='response')\n",
    "logreg_m_gtet_3cm_5_pred <- predict(logreg_m_gtet_3cm_5, newdata=data.frame(TFF3_positive_count=val5$TFF3_positive_count), type='response')\n",
    "\n",
    "# M>=4\n",
    "logreg_m_gtet_4cm_1_pred <- predict(logreg_m_gtet_4cm_1, newdata=data.frame(TFF3_positive_count=val1$TFF3_positive_count), type='response')\n",
    "logreg_m_gtet_4cm_2_pred <- predict(logreg_m_gtet_4cm_2, newdata=data.frame(TFF3_positive_count=val2$TFF3_positive_count), type='response')\n",
    "logreg_m_gtet_4cm_3_pred <- predict(logreg_m_gtet_4cm_3, newdata=data.frame(TFF3_positive_count=val3$TFF3_positive_count), type='response')\n",
    "logreg_m_gtet_4cm_4_pred <- predict(logreg_m_gtet_4cm_4, newdata=data.frame(TFF3_positive_count=val4$TFF3_positive_count), type='response')\n",
    "logreg_m_gtet_4cm_5_pred <- predict(logreg_m_gtet_4cm_5, newdata=data.frame(TFF3_positive_count=val5$TFF3_positive_count), type='response')\n",
    "\n",
    "# M>=5\n",
    "logreg_m_gtet_5cm_1_pred <- predict(logreg_m_gtet_5cm_1, newdata=data.frame(TFF3_positive_count=val1$TFF3_positive_count), type='response')\n",
    "logreg_m_gtet_5cm_2_pred <- predict(logreg_m_gtet_5cm_2, newdata=data.frame(TFF3_positive_count=val2$TFF3_positive_count), type='response')\n",
    "logreg_m_gtet_5cm_3_pred <- predict(logreg_m_gtet_5cm_3, newdata=data.frame(TFF3_positive_count=val3$TFF3_positive_count), type='response')\n",
    "logreg_m_gtet_5cm_4_pred <- predict(logreg_m_gtet_5cm_4, newdata=data.frame(TFF3_positive_count=val4$TFF3_positive_count), type='response')\n",
    "logreg_m_gtet_5cm_5_pred <- predict(logreg_m_gtet_5cm_5, newdata=data.frame(TFF3_positive_count=val5$TFF3_positive_count), type='response')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3e2f0d",
   "metadata": {},
   "source": [
    "Get performance metric results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9168192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C>=1 or M>=1\n",
    "fold1_c1m1 = METRIFY(val1$C_gtet_1_or_M_gtet_1, logreg_c_gtet_1cm_or_m_gtet_1cm_1_pred, logreg_c_gtet_1cm_or_m_gtet_1cm_1)\n",
    "fold2_c1m1 = METRIFY(val2$C_gtet_1_or_M_gtet_1, logreg_c_gtet_1cm_or_m_gtet_1cm_2_pred, logreg_c_gtet_1cm_or_m_gtet_1cm_2)\n",
    "fold3_c1m1 = METRIFY(val3$C_gtet_1_or_M_gtet_1, logreg_c_gtet_1cm_or_m_gtet_1cm_3_pred, logreg_c_gtet_1cm_or_m_gtet_1cm_3)\n",
    "fold4_c1m1 = METRIFY(val4$C_gtet_1_or_M_gtet_1, logreg_c_gtet_1cm_or_m_gtet_1cm_4_pred, logreg_c_gtet_1cm_or_m_gtet_1cm_4)\n",
    "fold5_c1m1 = METRIFY(val5$C_gtet_1_or_M_gtet_1, logreg_c_gtet_1cm_or_m_gtet_1cm_5_pred, logreg_c_gtet_1cm_or_m_gtet_1cm_5)\n",
    "\n",
    "# C>=1 or M>=3\n",
    "fold1_c1m3 = METRIFY(val1$C_gtet_1_or_M_gtet_3, logreg_c_gtet_1cm_or_m_gtet_3cm_1_pred, logreg_c_gtet_1cm_or_m_gtet_3cm_1)\n",
    "fold2_c1m3 = METRIFY(val2$C_gtet_1_or_M_gtet_3, logreg_c_gtet_1cm_or_m_gtet_3cm_2_pred, logreg_c_gtet_1cm_or_m_gtet_3cm_2)\n",
    "fold3_c1m3 = METRIFY(val3$C_gtet_1_or_M_gtet_3, logreg_c_gtet_1cm_or_m_gtet_3cm_3_pred, logreg_c_gtet_1cm_or_m_gtet_3cm_3)\n",
    "fold4_c1m3 = METRIFY(val4$C_gtet_1_or_M_gtet_3, logreg_c_gtet_1cm_or_m_gtet_3cm_4_pred, logreg_c_gtet_1cm_or_m_gtet_3cm_4)\n",
    "fold5_c1m3 = METRIFY(val5$C_gtet_1_or_M_gtet_3, logreg_c_gtet_1cm_or_m_gtet_3cm_5_pred, logreg_c_gtet_1cm_or_m_gtet_3cm_5)\n",
    "\n",
    "# C>=2 or M>=4\n",
    "fold1_c2m4 = METRIFY(val1$C_gtet_2_or_M_gtet_4, logreg_c_gtet_2cm_or_m_gtet_4cm_1_pred, logreg_c_gtet_2cm_or_m_gtet_4cm_1)\n",
    "fold2_c2m4 = METRIFY(val2$C_gtet_2_or_M_gtet_4, logreg_c_gtet_2cm_or_m_gtet_4cm_2_pred, logreg_c_gtet_2cm_or_m_gtet_4cm_2)\n",
    "fold3_c2m4 = METRIFY(val3$C_gtet_2_or_M_gtet_4, logreg_c_gtet_2cm_or_m_gtet_4cm_3_pred, logreg_c_gtet_2cm_or_m_gtet_4cm_3)\n",
    "fold4_c2m4 = METRIFY(val4$C_gtet_2_or_M_gtet_4, logreg_c_gtet_2cm_or_m_gtet_4cm_4_pred, logreg_c_gtet_2cm_or_m_gtet_4cm_4)\n",
    "fold5_c2m4 = METRIFY(val5$C_gtet_2_or_M_gtet_4, logreg_c_gtet_2cm_or_m_gtet_4cm_5_pred, logreg_c_gtet_2cm_or_m_gtet_4cm_5)\n",
    "\n",
    "# C>=3 or M>=5\n",
    "fold1_c3m5 = METRIFY(val1$C_gtet_3_or_M_gtet_5, logreg_c_gtet_3cm_or_m_gtet_5cm_1_pred, logreg_c_gtet_3cm_or_m_gtet_5cm_1)\n",
    "fold2_c3m5 = METRIFY(val2$C_gtet_3_or_M_gtet_5, logreg_c_gtet_3cm_or_m_gtet_5cm_2_pred, logreg_c_gtet_3cm_or_m_gtet_5cm_2)\n",
    "fold3_c3m5 = METRIFY(val3$C_gtet_3_or_M_gtet_5, logreg_c_gtet_3cm_or_m_gtet_5cm_3_pred, logreg_c_gtet_3cm_or_m_gtet_5cm_3)\n",
    "fold4_c3m5 = METRIFY(val4$C_gtet_3_or_M_gtet_5, logreg_c_gtet_3cm_or_m_gtet_5cm_4_pred, logreg_c_gtet_3cm_or_m_gtet_5cm_4)\n",
    "fold5_c3m5 = METRIFY(val5$C_gtet_3_or_M_gtet_5, logreg_c_gtet_3cm_or_m_gtet_5cm_5_pred, logreg_c_gtet_3cm_or_m_gtet_5cm_5)\n",
    "\n",
    "# C>=1\n",
    "fold1_c1 = METRIFY(val1$PRAGUE_C_gtet_1cm, logreg_c_gtet_1cm_1_pred, logreg_c_gtet_1cm_1)\n",
    "fold2_c1 = METRIFY(val2$PRAGUE_C_gtet_1cm, logreg_c_gtet_1cm_2_pred, logreg_c_gtet_1cm_2)\n",
    "fold3_c1 = METRIFY(val3$PRAGUE_C_gtet_1cm, logreg_c_gtet_1cm_3_pred, logreg_c_gtet_1cm_3)\n",
    "fold4_c1 = METRIFY(val4$PRAGUE_C_gtet_1cm, logreg_c_gtet_1cm_4_pred, logreg_c_gtet_1cm_4)\n",
    "fold5_c1 = METRIFY(val5$PRAGUE_C_gtet_1cm, logreg_c_gtet_1cm_5_pred, logreg_c_gtet_1cm_5)\n",
    "\n",
    "# C>=2\n",
    "fold1_c2 = METRIFY(val1$PRAGUE_C_gtet_2cm, logreg_c_gtet_2cm_1_pred, logreg_c_gtet_2cm_1)\n",
    "fold2_c2 = METRIFY(val2$PRAGUE_C_gtet_2cm, logreg_c_gtet_2cm_2_pred, logreg_c_gtet_2cm_2)\n",
    "fold3_c2 = METRIFY(val3$PRAGUE_C_gtet_2cm, logreg_c_gtet_2cm_3_pred, logreg_c_gtet_2cm_3)\n",
    "fold4_c2 = METRIFY(val4$PRAGUE_C_gtet_2cm, logreg_c_gtet_2cm_4_pred, logreg_c_gtet_2cm_4)\n",
    "fold5_c2 = METRIFY(val5$PRAGUE_C_gtet_2cm, logreg_c_gtet_2cm_5_pred, logreg_c_gtet_2cm_5)\n",
    "\n",
    "# C>=3\n",
    "fold1_c3 = METRIFY(val1$PRAGUE_C_gtet_3cm, logreg_c_gtet_3cm_1_pred, logreg_c_gtet_3cm_1)\n",
    "fold2_c3 = METRIFY(val2$PRAGUE_C_gtet_3cm, logreg_c_gtet_3cm_2_pred, logreg_c_gtet_3cm_2)\n",
    "fold3_c3 = METRIFY(val3$PRAGUE_C_gtet_3cm, logreg_c_gtet_3cm_3_pred, logreg_c_gtet_3cm_3)\n",
    "fold4_c3 = METRIFY(val4$PRAGUE_C_gtet_3cm, logreg_c_gtet_3cm_4_pred, logreg_c_gtet_3cm_4)\n",
    "fold5_c3 = METRIFY(val5$PRAGUE_C_gtet_3cm, logreg_c_gtet_3cm_5_pred, logreg_c_gtet_3cm_5)\n",
    "\n",
    "# M>=1\n",
    "fold1_m1 = METRIFY(val1$PRAGUE_M_gtet_1cm, logreg_m_gtet_1cm_1_pred, logreg_m_gtet_1cm_1)\n",
    "fold2_m1 = METRIFY(val2$PRAGUE_M_gtet_1cm, logreg_m_gtet_1cm_2_pred, logreg_m_gtet_1cm_2)\n",
    "fold3_m1 = METRIFY(val3$PRAGUE_M_gtet_1cm, logreg_m_gtet_1cm_3_pred, logreg_m_gtet_1cm_3)\n",
    "fold4_m1 = METRIFY(val4$PRAGUE_M_gtet_1cm, logreg_m_gtet_1cm_4_pred, logreg_m_gtet_1cm_4)\n",
    "fold5_m1 = METRIFY(val5$PRAGUE_M_gtet_1cm, logreg_m_gtet_1cm_5_pred, logreg_m_gtet_1cm_5)\n",
    "\n",
    "# M>=3\n",
    "fold1_m3 = METRIFY(val1$PRAGUE_M_gtet_3cm, logreg_m_gtet_3cm_1_pred, logreg_m_gtet_3cm_1)\n",
    "fold2_m3 = METRIFY(val2$PRAGUE_M_gtet_3cm, logreg_m_gtet_3cm_2_pred, logreg_m_gtet_3cm_2)\n",
    "fold3_m3 = METRIFY(val3$PRAGUE_M_gtet_3cm, logreg_m_gtet_3cm_3_pred, logreg_m_gtet_3cm_3)\n",
    "fold4_m3 = METRIFY(val4$PRAGUE_M_gtet_3cm, logreg_m_gtet_3cm_4_pred, logreg_m_gtet_3cm_4)\n",
    "fold5_m3 = METRIFY(val5$PRAGUE_M_gtet_3cm, logreg_m_gtet_3cm_5_pred, logreg_m_gtet_3cm_5)\n",
    "\n",
    "# M>=4\n",
    "fold1_m4 = METRIFY(val1$PRAGUE_M_gtet_4cm, logreg_m_gtet_4cm_1_pred, logreg_m_gtet_4cm_1)\n",
    "fold2_m4 = METRIFY(val2$PRAGUE_M_gtet_4cm, logreg_m_gtet_4cm_2_pred, logreg_m_gtet_4cm_2)\n",
    "fold3_m4 = METRIFY(val3$PRAGUE_M_gtet_4cm, logreg_m_gtet_4cm_3_pred, logreg_m_gtet_4cm_3)\n",
    "fold4_m4 = METRIFY(val4$PRAGUE_M_gtet_4cm, logreg_m_gtet_4cm_4_pred, logreg_m_gtet_4cm_4)\n",
    "fold5_m4 = METRIFY(val5$PRAGUE_M_gtet_4cm, logreg_m_gtet_4cm_5_pred, logreg_m_gtet_4cm_5)\n",
    "\n",
    "# M>=5\n",
    "fold1_m5 = METRIFY(val1$PRAGUE_M_gtet_5cm, logreg_m_gtet_5cm_1_pred, logreg_m_gtet_5cm_1)\n",
    "fold2_m5 = METRIFY(val2$PRAGUE_M_gtet_5cm, logreg_m_gtet_5cm_2_pred, logreg_m_gtet_5cm_2)\n",
    "fold3_m5 = METRIFY(val3$PRAGUE_M_gtet_5cm, logreg_m_gtet_5cm_3_pred, logreg_m_gtet_5cm_3)\n",
    "fold4_m5 = METRIFY(val4$PRAGUE_M_gtet_5cm, logreg_m_gtet_5cm_4_pred, logreg_m_gtet_5cm_4)\n",
    "fold5_m5 = METRIFY(val5$PRAGUE_M_gtet_5cm, logreg_m_gtet_5cm_5_pred, logreg_m_gtet_5cm_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff293bad",
   "metadata": {},
   "source": [
    "Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d43b41b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression C>=1cm or M>=1cm performance on validation folds:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Accuracy</th><th scope=col>Balanced_acc</th><th scope=col>Precision_long</th><th scope=col>Precision_short</th><th scope=col>Recall_long</th><th scope=col>Recall_short</th><th scope=col>F1_long</th><th scope=col>F1_short</th><th scope=col>Tile_cutoff</th><th scope=col>Tile_cutoff_SE</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Fold1</th><td>0.7924528</td><td>0.8143896</td><td>0.9245283</td><td>0.6603774</td><td>0.7313433</td><td>0.8974359</td><td>0.8166667</td><td>0.7608696</td><td>6.123937 </td><td>2.402157 </td></tr>\n",
       "\t<tr><th scope=row>Fold2</th><td>0.8773585</td><td>0.8786657</td><td>0.9152542</td><td>0.8297872</td><td>0.8709677</td><td>0.8863636</td><td>0.8925620</td><td>0.8571429</td><td>4.632022 </td><td>0.746372 </td></tr>\n",
       "\t<tr><th scope=row>Fold3</th><td>0.8113208</td><td>0.8559966</td><td>0.9821429</td><td>0.6200000</td><td>0.7432432</td><td>0.9687500</td><td>0.8461538</td><td>0.7560976</td><td>7.806023 </td><td>2.398120 </td></tr>\n",
       "\t<tr><th scope=row>Fold4</th><td>0.7924528</td><td>0.8475275</td><td>0.9827586</td><td>0.5625000</td><td>0.7307692</td><td>0.9642857</td><td>0.8382353</td><td>0.7105263</td><td>7.499915 </td><td>2.213443 </td></tr>\n",
       "\t<tr><th scope=row>Fold5</th><td>0.8571429</td><td>0.8517873</td><td>0.9275362</td><td>0.7222222</td><td>0.8648649</td><td>0.8387097</td><td>0.8951049</td><td>0.7761194</td><td>6.275538 </td><td>2.325775 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       "  & Accuracy & Balanced\\_acc & Precision\\_long & Precision\\_short & Recall\\_long & Recall\\_short & F1\\_long & F1\\_short & Tile\\_cutoff & Tile\\_cutoff\\_SE\\\\\n",
       "\\hline\n",
       "\tFold1 & 0.7924528 & 0.8143896 & 0.9245283 & 0.6603774 & 0.7313433 & 0.8974359 & 0.8166667 & 0.7608696 & 6.123937  & 2.402157 \\\\\n",
       "\tFold2 & 0.8773585 & 0.8786657 & 0.9152542 & 0.8297872 & 0.8709677 & 0.8863636 & 0.8925620 & 0.8571429 & 4.632022  & 0.746372 \\\\\n",
       "\tFold3 & 0.8113208 & 0.8559966 & 0.9821429 & 0.6200000 & 0.7432432 & 0.9687500 & 0.8461538 & 0.7560976 & 7.806023  & 2.398120 \\\\\n",
       "\tFold4 & 0.7924528 & 0.8475275 & 0.9827586 & 0.5625000 & 0.7307692 & 0.9642857 & 0.8382353 & 0.7105263 & 7.499915  & 2.213443 \\\\\n",
       "\tFold5 & 0.8571429 & 0.8517873 & 0.9275362 & 0.7222222 & 0.8648649 & 0.8387097 & 0.8951049 & 0.7761194 & 6.275538  & 2.325775 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Accuracy | Balanced_acc | Precision_long | Precision_short | Recall_long | Recall_short | F1_long | F1_short | Tile_cutoff | Tile_cutoff_SE |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Fold1 | 0.7924528 | 0.8143896 | 0.9245283 | 0.6603774 | 0.7313433 | 0.8974359 | 0.8166667 | 0.7608696 | 6.123937  | 2.402157  |\n",
       "| Fold2 | 0.8773585 | 0.8786657 | 0.9152542 | 0.8297872 | 0.8709677 | 0.8863636 | 0.8925620 | 0.8571429 | 4.632022  | 0.746372  |\n",
       "| Fold3 | 0.8113208 | 0.8559966 | 0.9821429 | 0.6200000 | 0.7432432 | 0.9687500 | 0.8461538 | 0.7560976 | 7.806023  | 2.398120  |\n",
       "| Fold4 | 0.7924528 | 0.8475275 | 0.9827586 | 0.5625000 | 0.7307692 | 0.9642857 | 0.8382353 | 0.7105263 | 7.499915  | 2.213443  |\n",
       "| Fold5 | 0.8571429 | 0.8517873 | 0.9275362 | 0.7222222 | 0.8648649 | 0.8387097 | 0.8951049 | 0.7761194 | 6.275538  | 2.325775  |\n",
       "\n"
      ],
      "text/plain": [
       "  Accuracy  Balanced_acc Precision_long Precision_short Recall_long\n",
       "1 0.7924528 0.8143896    0.9245283      0.6603774       0.7313433  \n",
       "2 0.8773585 0.8786657    0.9152542      0.8297872       0.8709677  \n",
       "3 0.8113208 0.8559966    0.9821429      0.6200000       0.7432432  \n",
       "4 0.7924528 0.8475275    0.9827586      0.5625000       0.7307692  \n",
       "5 0.8571429 0.8517873    0.9275362      0.7222222       0.8648649  \n",
       "  Recall_short F1_long   F1_short  Tile_cutoff Tile_cutoff_SE\n",
       "1 0.8974359    0.8166667 0.7608696 6.123937    2.402157      \n",
       "2 0.8863636    0.8925620 0.8571429 4.632022    0.746372      \n",
       "3 0.9687500    0.8461538 0.7560976 7.806023    2.398120      \n",
       "4 0.9642857    0.8382353 0.7105263 7.499915    2.213443      \n",
       "5 0.8387097    0.8951049 0.7761194 6.275538    2.325775      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Means:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.826145552560647</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.849673328989952</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.9464440497783</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.678977362951068</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.788237672878982</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.911108985100921</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.857744537102826</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.772151140422081</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>6.46748706648847</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>2.01717332068548</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.826145552560647\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.849673328989952\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.9464440497783\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.678977362951068\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.788237672878982\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.911108985100921\n",
       "\\item[F1\\textbackslash{}\\_long] 0.857744537102826\n",
       "\\item[F1\\textbackslash{}\\_short] 0.772151140422081\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 6.46748706648847\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 2.01717332068548\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.826145552560647Balanced_acc\n",
       ":   0.849673328989952Precision_long\n",
       ":   0.9464440497783Precision_short\n",
       ":   0.678977362951068Recall_long\n",
       ":   0.788237672878982Recall_short\n",
       ":   0.911108985100921F1_long\n",
       ":   0.857744537102826F1_short\n",
       ":   0.772151140422081Tile_cutoff\n",
       ":   6.46748706648847Tile_cutoff_SE\n",
       ":   2.01717332068548\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "      0.8261456       0.8496733       0.9464440       0.6789774       0.7882377 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "      0.9111090       0.8577445       0.7721511       6.4674871       2.0171733 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Standard deviations:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.038967202950946</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.023100631105573</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.0331804268133532</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.102475607656944</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.072938472269387</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.0552068756781799</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.0346785129429883</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.0534367602453039</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>1.2630704687612</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>0.714497265437513</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.038967202950946\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.023100631105573\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.0331804268133532\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.102475607656944\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.072938472269387\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.0552068756781799\n",
       "\\item[F1\\textbackslash{}\\_long] 0.0346785129429883\n",
       "\\item[F1\\textbackslash{}\\_short] 0.0534367602453039\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 1.2630704687612\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 0.714497265437513\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.038967202950946Balanced_acc\n",
       ":   0.023100631105573Precision_long\n",
       ":   0.0331804268133532Precision_short\n",
       ":   0.102475607656944Recall_long\n",
       ":   0.072938472269387Recall_short\n",
       ":   0.0552068756781799F1_long\n",
       ":   0.0346785129429883F1_short\n",
       ":   0.0534367602453039Tile_cutoff\n",
       ":   1.2630704687612Tile_cutoff_SE\n",
       ":   0.714497265437513\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "     0.03896720      0.02310063      0.03318043      0.10247561      0.07293847 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "     0.05520688      0.03467851      0.05343676      1.26307047      0.71449727 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C>=1 or M>=1 \n",
    "results = rbindlist(list(fold1_c1m1, fold2_c1m1, fold3_c1m1, fold4_c1m1, fold5_c1m1))\n",
    "row.names(results) = list(\"Fold1\", \"Fold2\", \"Fold3\", \"Fold4\", \"Fold5\")\n",
    "print('Logistic regression C>=1cm or M>=1cm performance on validation folds:')\n",
    "results\n",
    "print(\"Means:\")\n",
    "colMeans(results)\n",
    "print(\"Standard deviations:\")\n",
    "sapply(results, sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59f7ea71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression C>=1cm or M>=3cm performance on validation folds:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Accuracy</th><th scope=col>Balanced_acc</th><th scope=col>Precision_long</th><th scope=col>Precision_short</th><th scope=col>Recall_long</th><th scope=col>Recall_short</th><th scope=col>F1_long</th><th scope=col>F1_short</th><th scope=col>Tile_cutoff</th><th scope=col>Tile_cutoff_SE</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Fold1</th><td>0.8018868</td><td>0.8224638</td><td>0.9756098</td><td>0.6923077</td><td>0.6666667</td><td>0.9782609</td><td>0.7920792</td><td>0.8108108</td><td>17.80157 </td><td>3.489401 </td></tr>\n",
       "\t<tr><th scope=row>Fold2</th><td>0.8584906</td><td>0.8641246</td><td>0.9375000</td><td>0.7931034</td><td>0.7894737</td><td>0.9387755</td><td>0.8571429</td><td>0.8598131</td><td>13.33450 </td><td>2.040552 </td></tr>\n",
       "\t<tr><th scope=row>Fold3</th><td>0.7641509</td><td>0.8106061</td><td>1.0000000</td><td>0.6153846</td><td>0.6212121</td><td>1.0000000</td><td>0.7663551</td><td>0.7619048</td><td>20.13999 </td><td>3.658029 </td></tr>\n",
       "\t<tr><th scope=row>Fold4</th><td>0.7830189</td><td>0.8015691</td><td>0.9074074</td><td>0.6538462</td><td>0.7313433</td><td>0.8717949</td><td>0.8099174</td><td>0.7472527</td><td>15.98679 </td><td>2.629123 </td></tr>\n",
       "\t<tr><th scope=row>Fold5</th><td>0.8666667</td><td>0.8778846</td><td>0.9473684</td><td>0.7708333</td><td>0.8307692</td><td>0.9250000</td><td>0.8852459</td><td>0.8409091</td><td>16.42950 </td><td>3.132873 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       "  & Accuracy & Balanced\\_acc & Precision\\_long & Precision\\_short & Recall\\_long & Recall\\_short & F1\\_long & F1\\_short & Tile\\_cutoff & Tile\\_cutoff\\_SE\\\\\n",
       "\\hline\n",
       "\tFold1 & 0.8018868 & 0.8224638 & 0.9756098 & 0.6923077 & 0.6666667 & 0.9782609 & 0.7920792 & 0.8108108 & 17.80157  & 3.489401 \\\\\n",
       "\tFold2 & 0.8584906 & 0.8641246 & 0.9375000 & 0.7931034 & 0.7894737 & 0.9387755 & 0.8571429 & 0.8598131 & 13.33450  & 2.040552 \\\\\n",
       "\tFold3 & 0.7641509 & 0.8106061 & 1.0000000 & 0.6153846 & 0.6212121 & 1.0000000 & 0.7663551 & 0.7619048 & 20.13999  & 3.658029 \\\\\n",
       "\tFold4 & 0.7830189 & 0.8015691 & 0.9074074 & 0.6538462 & 0.7313433 & 0.8717949 & 0.8099174 & 0.7472527 & 15.98679  & 2.629123 \\\\\n",
       "\tFold5 & 0.8666667 & 0.8778846 & 0.9473684 & 0.7708333 & 0.8307692 & 0.9250000 & 0.8852459 & 0.8409091 & 16.42950  & 3.132873 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Accuracy | Balanced_acc | Precision_long | Precision_short | Recall_long | Recall_short | F1_long | F1_short | Tile_cutoff | Tile_cutoff_SE |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Fold1 | 0.8018868 | 0.8224638 | 0.9756098 | 0.6923077 | 0.6666667 | 0.9782609 | 0.7920792 | 0.8108108 | 17.80157  | 3.489401  |\n",
       "| Fold2 | 0.8584906 | 0.8641246 | 0.9375000 | 0.7931034 | 0.7894737 | 0.9387755 | 0.8571429 | 0.8598131 | 13.33450  | 2.040552  |\n",
       "| Fold3 | 0.7641509 | 0.8106061 | 1.0000000 | 0.6153846 | 0.6212121 | 1.0000000 | 0.7663551 | 0.7619048 | 20.13999  | 3.658029  |\n",
       "| Fold4 | 0.7830189 | 0.8015691 | 0.9074074 | 0.6538462 | 0.7313433 | 0.8717949 | 0.8099174 | 0.7472527 | 15.98679  | 2.629123  |\n",
       "| Fold5 | 0.8666667 | 0.8778846 | 0.9473684 | 0.7708333 | 0.8307692 | 0.9250000 | 0.8852459 | 0.8409091 | 16.42950  | 3.132873  |\n",
       "\n"
      ],
      "text/plain": [
       "  Accuracy  Balanced_acc Precision_long Precision_short Recall_long\n",
       "1 0.8018868 0.8224638    0.9756098      0.6923077       0.6666667  \n",
       "2 0.8584906 0.8641246    0.9375000      0.7931034       0.7894737  \n",
       "3 0.7641509 0.8106061    1.0000000      0.6153846       0.6212121  \n",
       "4 0.7830189 0.8015691    0.9074074      0.6538462       0.7313433  \n",
       "5 0.8666667 0.8778846    0.9473684      0.7708333       0.8307692  \n",
       "  Recall_short F1_long   F1_short  Tile_cutoff Tile_cutoff_SE\n",
       "1 0.9782609    0.7920792 0.8108108 17.80157    3.489401      \n",
       "2 0.9387755    0.8571429 0.8598131 13.33450    2.040552      \n",
       "3 1.0000000    0.7663551 0.7619048 20.13999    3.658029      \n",
       "4 0.8717949    0.8099174 0.7472527 15.98679    2.629123      \n",
       "5 0.9250000    0.8852459 0.8409091 16.42950    3.132873      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Means:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.814842767295598</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.83532962380048</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.95357711691152</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.705095048629531</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.727892997288127</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.942766250312834</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.822148092452362</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.804138098997912</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>16.7384700090035</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>2.98999542311124</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.814842767295598\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.83532962380048\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.95357711691152\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.705095048629531\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.727892997288127\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.942766250312834\n",
       "\\item[F1\\textbackslash{}\\_long] 0.822148092452362\n",
       "\\item[F1\\textbackslash{}\\_short] 0.804138098997912\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 16.7384700090035\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 2.98999542311124\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.814842767295598Balanced_acc\n",
       ":   0.83532962380048Precision_long\n",
       ":   0.95357711691152Precision_short\n",
       ":   0.705095048629531Recall_long\n",
       ":   0.727892997288127Recall_short\n",
       ":   0.942766250312834F1_long\n",
       ":   0.822148092452362F1_short\n",
       ":   0.804138098997912Tile_cutoff\n",
       ":   16.7384700090035Tile_cutoff_SE\n",
       ":   2.98999542311124\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "      0.8148428       0.8353296       0.9535771       0.7050950       0.7278930 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "      0.9427663       0.8221481       0.8041381      16.7384700       2.9899954 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Standard deviations:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.0456648818749379</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.0337514336566973</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.0355991043844433</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.075671870624619</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.0859026742516144</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.0497596029040088</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.0484059638601964</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.0487748216340545</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>2.49739729392948</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>0.661014629542</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.0456648818749379\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.0337514336566973\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.0355991043844433\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.075671870624619\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.0859026742516144\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.0497596029040088\n",
       "\\item[F1\\textbackslash{}\\_long] 0.0484059638601964\n",
       "\\item[F1\\textbackslash{}\\_short] 0.0487748216340545\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 2.49739729392948\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 0.661014629542\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.0456648818749379Balanced_acc\n",
       ":   0.0337514336566973Precision_long\n",
       ":   0.0355991043844433Precision_short\n",
       ":   0.075671870624619Recall_long\n",
       ":   0.0859026742516144Recall_short\n",
       ":   0.0497596029040088F1_long\n",
       ":   0.0484059638601964F1_short\n",
       ":   0.0487748216340545Tile_cutoff\n",
       ":   2.49739729392948Tile_cutoff_SE\n",
       ":   0.661014629542\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "     0.04566488      0.03375143      0.03559910      0.07567187      0.08590267 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "     0.04975960      0.04840596      0.04877482      2.49739729      0.66101463 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C>=1 or M>=3 \n",
    "results = rbindlist(list(fold1_c1m3, fold2_c1m3, fold3_c1m3, fold4_c1m3, fold5_c1m3))\n",
    "row.names(results) = list(\"Fold1\", \"Fold2\", \"Fold3\", \"Fold4\", \"Fold5\")\n",
    "print('Logistic regression C>=1cm or M>=3cm performance on validation folds:')\n",
    "results\n",
    "print(\"Means:\")\n",
    "colMeans(results)\n",
    "print(\"Standard deviations:\")\n",
    "sapply(results, sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98279a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression C>=2cm or M>=4cm performance on validation folds:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Accuracy</th><th scope=col>Balanced_acc</th><th scope=col>Precision_long</th><th scope=col>Precision_short</th><th scope=col>Recall_long</th><th scope=col>Recall_short</th><th scope=col>F1_long</th><th scope=col>F1_short</th><th scope=col>Tile_cutoff</th><th scope=col>Tile_cutoff_SE</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Fold1</th><td>0.7641509</td><td>0.7388335</td><td>0.7647059</td><td>0.7638889</td><td>0.6046512</td><td>0.8730159</td><td>0.6753247</td><td>0.8148148</td><td>39.68862 </td><td>5.338240 </td></tr>\n",
       "\t<tr><th scope=row>Fold2</th><td>0.7547170</td><td>0.7399425</td><td>0.8235294</td><td>0.7222222</td><td>0.5833333</td><td>0.8965517</td><td>0.6829268</td><td>0.8000000</td><td>38.08739 </td><td>4.821616 </td></tr>\n",
       "\t<tr><th scope=row>Fold3</th><td>0.7358491</td><td>0.7440285</td><td>0.9354839</td><td>0.6533333</td><td>0.5272727</td><td>0.9607843</td><td>0.6744186</td><td>0.7777778</td><td>50.67257 </td><td>6.590058 </td></tr>\n",
       "\t<tr><th scope=row>Fold4</th><td>0.8490566</td><td>0.8472222</td><td>0.9285714</td><td>0.7968750</td><td>0.7500000</td><td>0.9444444</td><td>0.8297872</td><td>0.8644068</td><td>43.57168 </td><td>6.183573 </td></tr>\n",
       "\t<tr><th scope=row>Fold5</th><td>0.7428571</td><td>0.7723547</td><td>0.9473684</td><td>0.6268657</td><td>0.5901639</td><td>0.9545455</td><td>0.7272727</td><td>0.7567568</td><td>50.75117 </td><td>6.938955 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       "  & Accuracy & Balanced\\_acc & Precision\\_long & Precision\\_short & Recall\\_long & Recall\\_short & F1\\_long & F1\\_short & Tile\\_cutoff & Tile\\_cutoff\\_SE\\\\\n",
       "\\hline\n",
       "\tFold1 & 0.7641509 & 0.7388335 & 0.7647059 & 0.7638889 & 0.6046512 & 0.8730159 & 0.6753247 & 0.8148148 & 39.68862  & 5.338240 \\\\\n",
       "\tFold2 & 0.7547170 & 0.7399425 & 0.8235294 & 0.7222222 & 0.5833333 & 0.8965517 & 0.6829268 & 0.8000000 & 38.08739  & 4.821616 \\\\\n",
       "\tFold3 & 0.7358491 & 0.7440285 & 0.9354839 & 0.6533333 & 0.5272727 & 0.9607843 & 0.6744186 & 0.7777778 & 50.67257  & 6.590058 \\\\\n",
       "\tFold4 & 0.8490566 & 0.8472222 & 0.9285714 & 0.7968750 & 0.7500000 & 0.9444444 & 0.8297872 & 0.8644068 & 43.57168  & 6.183573 \\\\\n",
       "\tFold5 & 0.7428571 & 0.7723547 & 0.9473684 & 0.6268657 & 0.5901639 & 0.9545455 & 0.7272727 & 0.7567568 & 50.75117  & 6.938955 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Accuracy | Balanced_acc | Precision_long | Precision_short | Recall_long | Recall_short | F1_long | F1_short | Tile_cutoff | Tile_cutoff_SE |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Fold1 | 0.7641509 | 0.7388335 | 0.7647059 | 0.7638889 | 0.6046512 | 0.8730159 | 0.6753247 | 0.8148148 | 39.68862  | 5.338240  |\n",
       "| Fold2 | 0.7547170 | 0.7399425 | 0.8235294 | 0.7222222 | 0.5833333 | 0.8965517 | 0.6829268 | 0.8000000 | 38.08739  | 4.821616  |\n",
       "| Fold3 | 0.7358491 | 0.7440285 | 0.9354839 | 0.6533333 | 0.5272727 | 0.9607843 | 0.6744186 | 0.7777778 | 50.67257  | 6.590058  |\n",
       "| Fold4 | 0.8490566 | 0.8472222 | 0.9285714 | 0.7968750 | 0.7500000 | 0.9444444 | 0.8297872 | 0.8644068 | 43.57168  | 6.183573  |\n",
       "| Fold5 | 0.7428571 | 0.7723547 | 0.9473684 | 0.6268657 | 0.5901639 | 0.9545455 | 0.7272727 | 0.7567568 | 50.75117  | 6.938955  |\n",
       "\n"
      ],
      "text/plain": [
       "  Accuracy  Balanced_acc Precision_long Precision_short Recall_long\n",
       "1 0.7641509 0.7388335    0.7647059      0.7638889       0.6046512  \n",
       "2 0.7547170 0.7399425    0.8235294      0.7222222       0.5833333  \n",
       "3 0.7358491 0.7440285    0.9354839      0.6533333       0.5272727  \n",
       "4 0.8490566 0.8472222    0.9285714      0.7968750       0.7500000  \n",
       "5 0.7428571 0.7723547    0.9473684      0.6268657       0.5901639  \n",
       "  Recall_short F1_long   F1_short  Tile_cutoff Tile_cutoff_SE\n",
       "1 0.8730159    0.6753247 0.8148148 39.68862    5.338240      \n",
       "2 0.8965517    0.6829268 0.8000000 38.08739    4.821616      \n",
       "3 0.9607843    0.6744186 0.7777778 50.67257    6.590058      \n",
       "4 0.9444444    0.8297872 0.8644068 43.57168    6.183573      \n",
       "5 0.9545455    0.7272727 0.7567568 50.75117    6.938955      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Means:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.769326145552561</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.768476296769218</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.87993180294189</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.712637023217247</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.611084231564598</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.925868361973839</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.717946014111882</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.802751225802073</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>44.5542859990233</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>5.97448837538612</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.769326145552561\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.768476296769218\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.87993180294189\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.712637023217247\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.611084231564598\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.925868361973839\n",
       "\\item[F1\\textbackslash{}\\_long] 0.717946014111882\n",
       "\\item[F1\\textbackslash{}\\_short] 0.802751225802073\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 44.5542859990233\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 5.97448837538612\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.769326145552561Balanced_acc\n",
       ":   0.768476296769218Precision_long\n",
       ":   0.87993180294189Precision_short\n",
       ":   0.712637023217247Recall_long\n",
       ":   0.611084231564598Recall_short\n",
       ":   0.925868361973839F1_long\n",
       ":   0.717946014111882F1_short\n",
       ":   0.802751225802073Tile_cutoff\n",
       ":   44.5542859990233Tile_cutoff_SE\n",
       ":   5.97448837538612\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "      0.7693261       0.7684763       0.8799318       0.7126370       0.6110842 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "      0.9258684       0.7179460       0.8027512      44.5542860       5.9744884 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Standard deviations:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.0458761374756344</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.0461154170694053</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.0813292466023438</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.0719171726574545</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.0830227597266465</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.0388568559204585</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.0662061236885416</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.0409074291355439</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>5.96438845862387</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>0.878459659984539</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.0458761374756344\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.0461154170694053\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.0813292466023438\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.0719171726574545\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.0830227597266465\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.0388568559204585\n",
       "\\item[F1\\textbackslash{}\\_long] 0.0662061236885416\n",
       "\\item[F1\\textbackslash{}\\_short] 0.0409074291355439\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 5.96438845862387\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 0.878459659984539\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.0458761374756344Balanced_acc\n",
       ":   0.0461154170694053Precision_long\n",
       ":   0.0813292466023438Precision_short\n",
       ":   0.0719171726574545Recall_long\n",
       ":   0.0830227597266465Recall_short\n",
       ":   0.0388568559204585F1_long\n",
       ":   0.0662061236885416F1_short\n",
       ":   0.0409074291355439Tile_cutoff\n",
       ":   5.96438845862387Tile_cutoff_SE\n",
       ":   0.878459659984539\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "     0.04587614      0.04611542      0.08132925      0.07191717      0.08302276 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "     0.03885686      0.06620612      0.04090743      5.96438846      0.87845966 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C>=2 or M>=4 \n",
    "results = rbindlist(list(fold1_c2m4, fold2_c2m4, fold3_c2m4, fold4_c2m4, fold5_c2m4))\n",
    "row.names(results) = list(\"Fold1\", \"Fold2\", \"Fold3\", \"Fold4\", \"Fold5\")\n",
    "print('Logistic regression C>=2cm or M>=4cm performance on validation folds:')\n",
    "results\n",
    "print(\"Means:\")\n",
    "colMeans(results)\n",
    "print(\"Standard deviations:\")\n",
    "sapply(results, sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddb2390f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression C>=3cm or M>=5cm performance on validation folds:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Accuracy</th><th scope=col>Balanced_acc</th><th scope=col>Precision_long</th><th scope=col>Precision_short</th><th scope=col>Recall_long</th><th scope=col>Recall_short</th><th scope=col>F1_long</th><th scope=col>F1_short</th><th scope=col>Tile_cutoff</th><th scope=col>Tile_cutoff_SE</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Fold1</th><td>0.8207547</td><td>0.7287256</td><td>0.8888889</td><td>0.8068182</td><td>0.4848485</td><td>0.9726027</td><td>0.6274510</td><td>0.8819876</td><td>134.12951</td><td>18.68902 </td></tr>\n",
       "\t<tr><th scope=row>Fold2</th><td>0.8396226</td><td>0.7810458</td><td>0.8400000</td><td>0.8395062</td><td>0.6176471</td><td>0.9444444</td><td>0.7118644</td><td>0.8888889</td><td> 91.91892</td><td>10.80557 </td></tr>\n",
       "\t<tr><th scope=row>Fold3</th><td>0.6415094</td><td>0.6059626</td><td>0.9166667</td><td>0.6063830</td><td>0.2291667</td><td>0.9827586</td><td>0.3666667</td><td>0.7500000</td><td>159.50922</td><td>20.19925 </td></tr>\n",
       "\t<tr><th scope=row>Fold4</th><td>0.8018868</td><td>0.7522727</td><td>0.8800000</td><td>0.7777778</td><td>0.5500000</td><td>0.9545455</td><td>0.6769231</td><td>0.8571429</td><td>132.37814</td><td>18.54789 </td></tr>\n",
       "\t<tr><th scope=row>Fold5</th><td>0.7238095</td><td>0.6995598</td><td>0.8461538</td><td>0.6835443</td><td>0.4680851</td><td>0.9310345</td><td>0.6027397</td><td>0.7883212</td><td>141.61527</td><td>19.09947 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       "  & Accuracy & Balanced\\_acc & Precision\\_long & Precision\\_short & Recall\\_long & Recall\\_short & F1\\_long & F1\\_short & Tile\\_cutoff & Tile\\_cutoff\\_SE\\\\\n",
       "\\hline\n",
       "\tFold1 & 0.8207547 & 0.7287256 & 0.8888889 & 0.8068182 & 0.4848485 & 0.9726027 & 0.6274510 & 0.8819876 & 134.12951 & 18.68902 \\\\\n",
       "\tFold2 & 0.8396226 & 0.7810458 & 0.8400000 & 0.8395062 & 0.6176471 & 0.9444444 & 0.7118644 & 0.8888889 &  91.91892 & 10.80557 \\\\\n",
       "\tFold3 & 0.6415094 & 0.6059626 & 0.9166667 & 0.6063830 & 0.2291667 & 0.9827586 & 0.3666667 & 0.7500000 & 159.50922 & 20.19925 \\\\\n",
       "\tFold4 & 0.8018868 & 0.7522727 & 0.8800000 & 0.7777778 & 0.5500000 & 0.9545455 & 0.6769231 & 0.8571429 & 132.37814 & 18.54789 \\\\\n",
       "\tFold5 & 0.7238095 & 0.6995598 & 0.8461538 & 0.6835443 & 0.4680851 & 0.9310345 & 0.6027397 & 0.7883212 & 141.61527 & 19.09947 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Accuracy | Balanced_acc | Precision_long | Precision_short | Recall_long | Recall_short | F1_long | F1_short | Tile_cutoff | Tile_cutoff_SE |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Fold1 | 0.8207547 | 0.7287256 | 0.8888889 | 0.8068182 | 0.4848485 | 0.9726027 | 0.6274510 | 0.8819876 | 134.12951 | 18.68902  |\n",
       "| Fold2 | 0.8396226 | 0.7810458 | 0.8400000 | 0.8395062 | 0.6176471 | 0.9444444 | 0.7118644 | 0.8888889 |  91.91892 | 10.80557  |\n",
       "| Fold3 | 0.6415094 | 0.6059626 | 0.9166667 | 0.6063830 | 0.2291667 | 0.9827586 | 0.3666667 | 0.7500000 | 159.50922 | 20.19925  |\n",
       "| Fold4 | 0.8018868 | 0.7522727 | 0.8800000 | 0.7777778 | 0.5500000 | 0.9545455 | 0.6769231 | 0.8571429 | 132.37814 | 18.54789  |\n",
       "| Fold5 | 0.7238095 | 0.6995598 | 0.8461538 | 0.6835443 | 0.4680851 | 0.9310345 | 0.6027397 | 0.7883212 | 141.61527 | 19.09947  |\n",
       "\n"
      ],
      "text/plain": [
       "  Accuracy  Balanced_acc Precision_long Precision_short Recall_long\n",
       "1 0.8207547 0.7287256    0.8888889      0.8068182       0.4848485  \n",
       "2 0.8396226 0.7810458    0.8400000      0.8395062       0.6176471  \n",
       "3 0.6415094 0.6059626    0.9166667      0.6063830       0.2291667  \n",
       "4 0.8018868 0.7522727    0.8800000      0.7777778       0.5500000  \n",
       "5 0.7238095 0.6995598    0.8461538      0.6835443       0.4680851  \n",
       "  Recall_short F1_long   F1_short  Tile_cutoff Tile_cutoff_SE\n",
       "1 0.9726027    0.6274510 0.8819876 134.12951   18.68902      \n",
       "2 0.9444444    0.7118644 0.8888889  91.91892   10.80557      \n",
       "3 0.9827586    0.3666667 0.7500000 159.50922   20.19925      \n",
       "4 0.9545455    0.6769231 0.8571429 132.37814   18.54789      \n",
       "5 0.9310345    0.6027397 0.7883212 141.61527   19.09947      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Means:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.765516621743037</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.713513305888586</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.87434188034188</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.742805882991268</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.469949463344332</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.95707714843284</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.597128971357792</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.833268098310942</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>131.910212802543</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>17.4682407480063</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.765516621743037\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.713513305888586\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.87434188034188\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.742805882991268\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.469949463344332\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.95707714843284\n",
       "\\item[F1\\textbackslash{}\\_long] 0.597128971357792\n",
       "\\item[F1\\textbackslash{}\\_short] 0.833268098310942\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 131.910212802543\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 17.4682407480063\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.765516621743037Balanced_acc\n",
       ":   0.713513305888586Precision_long\n",
       ":   0.87434188034188Precision_short\n",
       ":   0.742805882991268Recall_long\n",
       ":   0.469949463344332Recall_short\n",
       ":   0.95707714843284F1_long\n",
       ":   0.597128971357792F1_short\n",
       ":   0.833268098310942Tile_cutoff\n",
       ":   131.910212802543Tile_cutoff_SE\n",
       ":   17.4682407480063\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "      0.7655166       0.7135133       0.8743419       0.7428059       0.4699495 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "      0.9570771       0.5971290       0.8332681     131.9102128      17.4682407 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Standard deviations:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.0821325198808936</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.0671866498278351</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.0316581242731347</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.0959097198674615</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.146990203732915</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.0208853843733942</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.135642082433695</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.0612190061808099</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>24.800913715896</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>3.78042453623298</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.0821325198808936\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.0671866498278351\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.0316581242731347\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.0959097198674615\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.146990203732915\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.0208853843733942\n",
       "\\item[F1\\textbackslash{}\\_long] 0.135642082433695\n",
       "\\item[F1\\textbackslash{}\\_short] 0.0612190061808099\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 24.800913715896\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 3.78042453623298\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.0821325198808936Balanced_acc\n",
       ":   0.0671866498278351Precision_long\n",
       ":   0.0316581242731347Precision_short\n",
       ":   0.0959097198674615Recall_long\n",
       ":   0.146990203732915Recall_short\n",
       ":   0.0208853843733942F1_long\n",
       ":   0.135642082433695F1_short\n",
       ":   0.0612190061808099Tile_cutoff\n",
       ":   24.800913715896Tile_cutoff_SE\n",
       ":   3.78042453623298\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "     0.08213252      0.06718665      0.03165812      0.09590972      0.14699020 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "     0.02088538      0.13564208      0.06121901     24.80091372      3.78042454 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C>=3 or M>=5 \n",
    "results = rbindlist(list(fold1_c3m5, fold2_c3m5, fold3_c3m5, fold4_c3m5, fold5_c3m5))\n",
    "row.names(results) = list(\"Fold1\", \"Fold2\", \"Fold3\", \"Fold4\", \"Fold5\")\n",
    "print('Logistic regression C>=3cm or M>=5cm performance on validation folds:')\n",
    "results\n",
    "print(\"Means:\")\n",
    "colMeans(results)\n",
    "print(\"Standard deviations:\")\n",
    "sapply(results, sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf5a3202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression C>=1cm performance on validation folds:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Accuracy</th><th scope=col>Balanced_acc</th><th scope=col>Precision_long</th><th scope=col>Precision_short</th><th scope=col>Recall_long</th><th scope=col>Recall_short</th><th scope=col>F1_long</th><th scope=col>F1_short</th><th scope=col>Tile_cutoff</th><th scope=col>Tile_cutoff_SE</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Fold1</th><td>0.7735849</td><td>0.7931034</td><td>1.0000000</td><td>0.6666667</td><td>0.5862069</td><td>1.0000000</td><td>0.7391304</td><td>0.8000000</td><td>41.26668 </td><td>6.640244 </td></tr>\n",
       "\t<tr><th scope=row>Fold2</th><td>0.7735849</td><td>0.7653571</td><td>0.8611111</td><td>0.7285714</td><td>0.6200000</td><td>0.9107143</td><td>0.7209302</td><td>0.8095238</td><td>30.38223 </td><td>4.877522 </td></tr>\n",
       "\t<tr><th scope=row>Fold3</th><td>0.7264151</td><td>0.7300570</td><td>0.8787879</td><td>0.6575342</td><td>0.5370370</td><td>0.9230769</td><td>0.6666667</td><td>0.7680000</td><td>35.06632 </td><td>5.492585 </td></tr>\n",
       "\t<tr><th scope=row>Fold4</th><td>0.7830189</td><td>0.7942661</td><td>0.8913043</td><td>0.7000000</td><td>0.6949153</td><td>0.8936170</td><td>0.7809524</td><td>0.7850467</td><td>34.05945 </td><td>5.523742 </td></tr>\n",
       "\t<tr><th scope=row>Fold5</th><td>0.7904762</td><td>0.8111111</td><td>0.9523810</td><td>0.6825397</td><td>0.6666667</td><td>0.9555556</td><td>0.7843137</td><td>0.7962963</td><td>36.34240 </td><td>6.100627 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       "  & Accuracy & Balanced\\_acc & Precision\\_long & Precision\\_short & Recall\\_long & Recall\\_short & F1\\_long & F1\\_short & Tile\\_cutoff & Tile\\_cutoff\\_SE\\\\\n",
       "\\hline\n",
       "\tFold1 & 0.7735849 & 0.7931034 & 1.0000000 & 0.6666667 & 0.5862069 & 1.0000000 & 0.7391304 & 0.8000000 & 41.26668  & 6.640244 \\\\\n",
       "\tFold2 & 0.7735849 & 0.7653571 & 0.8611111 & 0.7285714 & 0.6200000 & 0.9107143 & 0.7209302 & 0.8095238 & 30.38223  & 4.877522 \\\\\n",
       "\tFold3 & 0.7264151 & 0.7300570 & 0.8787879 & 0.6575342 & 0.5370370 & 0.9230769 & 0.6666667 & 0.7680000 & 35.06632  & 5.492585 \\\\\n",
       "\tFold4 & 0.7830189 & 0.7942661 & 0.8913043 & 0.7000000 & 0.6949153 & 0.8936170 & 0.7809524 & 0.7850467 & 34.05945  & 5.523742 \\\\\n",
       "\tFold5 & 0.7904762 & 0.8111111 & 0.9523810 & 0.6825397 & 0.6666667 & 0.9555556 & 0.7843137 & 0.7962963 & 36.34240  & 6.100627 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Accuracy | Balanced_acc | Precision_long | Precision_short | Recall_long | Recall_short | F1_long | F1_short | Tile_cutoff | Tile_cutoff_SE |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Fold1 | 0.7735849 | 0.7931034 | 1.0000000 | 0.6666667 | 0.5862069 | 1.0000000 | 0.7391304 | 0.8000000 | 41.26668  | 6.640244  |\n",
       "| Fold2 | 0.7735849 | 0.7653571 | 0.8611111 | 0.7285714 | 0.6200000 | 0.9107143 | 0.7209302 | 0.8095238 | 30.38223  | 4.877522  |\n",
       "| Fold3 | 0.7264151 | 0.7300570 | 0.8787879 | 0.6575342 | 0.5370370 | 0.9230769 | 0.6666667 | 0.7680000 | 35.06632  | 5.492585  |\n",
       "| Fold4 | 0.7830189 | 0.7942661 | 0.8913043 | 0.7000000 | 0.6949153 | 0.8936170 | 0.7809524 | 0.7850467 | 34.05945  | 5.523742  |\n",
       "| Fold5 | 0.7904762 | 0.8111111 | 0.9523810 | 0.6825397 | 0.6666667 | 0.9555556 | 0.7843137 | 0.7962963 | 36.34240  | 6.100627  |\n",
       "\n"
      ],
      "text/plain": [
       "  Accuracy  Balanced_acc Precision_long Precision_short Recall_long\n",
       "1 0.7735849 0.7931034    1.0000000      0.6666667       0.5862069  \n",
       "2 0.7735849 0.7653571    0.8611111      0.7285714       0.6200000  \n",
       "3 0.7264151 0.7300570    0.8787879      0.6575342       0.5370370  \n",
       "4 0.7830189 0.7942661    0.8913043      0.7000000       0.6949153  \n",
       "5 0.7904762 0.8111111    0.9523810      0.6825397       0.6666667  \n",
       "  Recall_short F1_long   F1_short  Tile_cutoff Tile_cutoff_SE\n",
       "1 1.0000000    0.7391304 0.8000000 41.26668    6.640244      \n",
       "2 0.9107143    0.7209302 0.8095238 30.38223    4.877522      \n",
       "3 0.9230769    0.6666667 0.7680000 35.06632    5.492585      \n",
       "4 0.8936170    0.7809524 0.7850467 34.05945    5.523742      \n",
       "5 0.9555556    0.7843137 0.7962963 36.34240    6.100627      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Means:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.769415992812219</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.778778964011608</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.916716858021206</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.687062404870624</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.620965170898543</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.936592757124672</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.738398688089998</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.791773366958414</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>35.4234125961485</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>5.72694395780815</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.769415992812219\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.778778964011608\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.916716858021206\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.687062404870624\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.620965170898543\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.936592757124672\n",
       "\\item[F1\\textbackslash{}\\_long] 0.738398688089998\n",
       "\\item[F1\\textbackslash{}\\_short] 0.791773366958414\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 35.4234125961485\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 5.72694395780815\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.769415992812219Balanced_acc\n",
       ":   0.778778964011608Precision_long\n",
       ":   0.916716858021206Precision_short\n",
       ":   0.687062404870624Recall_long\n",
       ":   0.620965170898543Recall_short\n",
       ":   0.936592757124672F1_long\n",
       ":   0.738398688089998F1_short\n",
       ":   0.791773366958414Tile_cutoff\n",
       ":   35.4234125961485Tile_cutoff_SE\n",
       ":   5.72694395780815\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "      0.7694160       0.7787790       0.9167169       0.6870624       0.6209652 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "      0.9365928       0.7383987       0.7917734      35.4234126       5.7269440 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Standard deviations:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.0250619585980838</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.0317977520419935</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.0578455088876604</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.0282786743978743</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.0628693931598639</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.042069445853283</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.0483998262524142</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.0159188035621712</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>3.94935870186318</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>0.669232533857598</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.0250619585980838\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.0317977520419935\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.0578455088876604\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.0282786743978743\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.0628693931598639\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.042069445853283\n",
       "\\item[F1\\textbackslash{}\\_long] 0.0483998262524142\n",
       "\\item[F1\\textbackslash{}\\_short] 0.0159188035621712\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 3.94935870186318\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 0.669232533857598\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.0250619585980838Balanced_acc\n",
       ":   0.0317977520419935Precision_long\n",
       ":   0.0578455088876604Precision_short\n",
       ":   0.0282786743978743Recall_long\n",
       ":   0.0628693931598639Recall_short\n",
       ":   0.042069445853283F1_long\n",
       ":   0.0483998262524142F1_short\n",
       ":   0.0159188035621712Tile_cutoff\n",
       ":   3.94935870186318Tile_cutoff_SE\n",
       ":   0.669232533857598\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "     0.02506196      0.03179775      0.05784551      0.02827867      0.06286939 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "     0.04206945      0.04839983      0.01591880      3.94935870      0.66923253 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C>=1\n",
    "results = rbindlist(list(fold1_c1, fold2_c1, fold3_c1, fold4_c1, fold5_c1))\n",
    "row.names(results) = list(\"Fold1\", \"Fold2\", \"Fold3\", \"Fold4\", \"Fold5\")\n",
    "print('Logistic regression C>=1cm performance on validation folds:')\n",
    "results\n",
    "print(\"Means:\")\n",
    "colMeans(results)\n",
    "print(\"Standard deviations:\")\n",
    "sapply(results, sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "936afd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression C>=2cm performance on validation folds:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Accuracy</th><th scope=col>Balanced_acc</th><th scope=col>Precision_long</th><th scope=col>Precision_short</th><th scope=col>Recall_long</th><th scope=col>Recall_short</th><th scope=col>F1_long</th><th scope=col>F1_short</th><th scope=col>Tile_cutoff</th><th scope=col>Tile_cutoff_SE</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Fold1</th><td>0.7735849</td><td>0.7030233</td><td>0.8947368</td><td>0.7471264</td><td>0.4358974</td><td>0.9701493</td><td>0.5862069</td><td>0.8441558</td><td> 99.67602</td><td>14.629629</td></tr>\n",
       "\t<tr><th scope=row>Fold2</th><td>0.7735849</td><td>0.7306502</td><td>0.7333333</td><td>0.7894737</td><td>0.5789474</td><td>0.8823529</td><td>0.6470588</td><td>0.8333333</td><td> 63.38298</td><td> 7.607368</td></tr>\n",
       "\t<tr><th scope=row>Fold3</th><td>0.6415094</td><td>0.6165414</td><td>0.8235294</td><td>0.6067416</td><td>0.2857143</td><td>0.9473684</td><td>0.4242424</td><td>0.7397260</td><td>111.51165</td><td>14.863609</td></tr>\n",
       "\t<tr><th scope=row>Fold4</th><td>0.8113208</td><td>0.7902174</td><td>0.9062500</td><td>0.7702703</td><td>0.6304348</td><td>0.9500000</td><td>0.7435897</td><td>0.8507463</td><td>103.20940</td><td>15.496086</td></tr>\n",
       "\t<tr><th scope=row>Fold5</th><td>0.7428571</td><td>0.7447388</td><td>0.9062500</td><td>0.6712329</td><td>0.5471698</td><td>0.9423077</td><td>0.6823529</td><td>0.7840000</td><td>117.60011</td><td>17.325635</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       "  & Accuracy & Balanced\\_acc & Precision\\_long & Precision\\_short & Recall\\_long & Recall\\_short & F1\\_long & F1\\_short & Tile\\_cutoff & Tile\\_cutoff\\_SE\\\\\n",
       "\\hline\n",
       "\tFold1 & 0.7735849 & 0.7030233 & 0.8947368 & 0.7471264 & 0.4358974 & 0.9701493 & 0.5862069 & 0.8441558 &  99.67602 & 14.629629\\\\\n",
       "\tFold2 & 0.7735849 & 0.7306502 & 0.7333333 & 0.7894737 & 0.5789474 & 0.8823529 & 0.6470588 & 0.8333333 &  63.38298 &  7.607368\\\\\n",
       "\tFold3 & 0.6415094 & 0.6165414 & 0.8235294 & 0.6067416 & 0.2857143 & 0.9473684 & 0.4242424 & 0.7397260 & 111.51165 & 14.863609\\\\\n",
       "\tFold4 & 0.8113208 & 0.7902174 & 0.9062500 & 0.7702703 & 0.6304348 & 0.9500000 & 0.7435897 & 0.8507463 & 103.20940 & 15.496086\\\\\n",
       "\tFold5 & 0.7428571 & 0.7447388 & 0.9062500 & 0.6712329 & 0.5471698 & 0.9423077 & 0.6823529 & 0.7840000 & 117.60011 & 17.325635\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Accuracy | Balanced_acc | Precision_long | Precision_short | Recall_long | Recall_short | F1_long | F1_short | Tile_cutoff | Tile_cutoff_SE |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Fold1 | 0.7735849 | 0.7030233 | 0.8947368 | 0.7471264 | 0.4358974 | 0.9701493 | 0.5862069 | 0.8441558 |  99.67602 | 14.629629 |\n",
       "| Fold2 | 0.7735849 | 0.7306502 | 0.7333333 | 0.7894737 | 0.5789474 | 0.8823529 | 0.6470588 | 0.8333333 |  63.38298 |  7.607368 |\n",
       "| Fold3 | 0.6415094 | 0.6165414 | 0.8235294 | 0.6067416 | 0.2857143 | 0.9473684 | 0.4242424 | 0.7397260 | 111.51165 | 14.863609 |\n",
       "| Fold4 | 0.8113208 | 0.7902174 | 0.9062500 | 0.7702703 | 0.6304348 | 0.9500000 | 0.7435897 | 0.8507463 | 103.20940 | 15.496086 |\n",
       "| Fold5 | 0.7428571 | 0.7447388 | 0.9062500 | 0.6712329 | 0.5471698 | 0.9423077 | 0.6823529 | 0.7840000 | 117.60011 | 17.325635 |\n",
       "\n"
      ],
      "text/plain": [
       "  Accuracy  Balanced_acc Precision_long Precision_short Recall_long\n",
       "1 0.7735849 0.7030233    0.8947368      0.7471264       0.4358974  \n",
       "2 0.7735849 0.7306502    0.7333333      0.7894737       0.5789474  \n",
       "3 0.6415094 0.6165414    0.8235294      0.6067416       0.2857143  \n",
       "4 0.8113208 0.7902174    0.9062500      0.7702703       0.6304348  \n",
       "5 0.7428571 0.7447388    0.9062500      0.6712329       0.5471698  \n",
       "  Recall_short F1_long   F1_short  Tile_cutoff Tile_cutoff_SE\n",
       "1 0.9701493    0.5862069 0.8441558  99.67602   14.629629     \n",
       "2 0.8823529    0.6470588 0.8333333  63.38298    7.607368     \n",
       "3 0.9473684    0.4242424 0.7397260 111.51165   14.863609     \n",
       "4 0.9500000    0.7435897 0.8507463 103.20940   15.496086     \n",
       "5 0.9423077    0.6823529 0.7840000 117.60011   17.325635     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Means:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.748571428571429</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.717034199223036</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.85281991744066</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.716968968201689</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.495632736792445</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.938435661653628</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.616690165817955</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.810392294708631</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>99.0760338789615</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>13.9844656830685</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.748571428571429\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.717034199223036\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.85281991744066\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.716968968201689\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.495632736792445\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.938435661653628\n",
       "\\item[F1\\textbackslash{}\\_long] 0.616690165817955\n",
       "\\item[F1\\textbackslash{}\\_short] 0.810392294708631\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 99.0760338789615\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 13.9844656830685\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.748571428571429Balanced_acc\n",
       ":   0.717034199223036Precision_long\n",
       ":   0.85281991744066Precision_short\n",
       ":   0.716968968201689Recall_long\n",
       ":   0.495632736792445Recall_short\n",
       ":   0.938435661653628F1_long\n",
       ":   0.616690165817955F1_short\n",
       ":   0.810392294708631Tile_cutoff\n",
       ":   99.0760338789615Tile_cutoff_SE\n",
       ":   13.9844656830685\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "      0.7485714       0.7170342       0.8528199       0.7169690       0.4956327 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "      0.9384357       0.6166902       0.8103923      99.0760339      13.9844657 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Standard deviations:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.0645827952220963</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.0644279290950856</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.0751690653166649</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.0762386127023547</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.1372980805826</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.0330890623614759</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.121760750264932</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.0473945837980633</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>21.1496128543992</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>3.71836366008217</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.0645827952220963\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.0644279290950856\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.0751690653166649\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.0762386127023547\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.1372980805826\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.0330890623614759\n",
       "\\item[F1\\textbackslash{}\\_long] 0.121760750264932\n",
       "\\item[F1\\textbackslash{}\\_short] 0.0473945837980633\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 21.1496128543992\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 3.71836366008217\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.0645827952220963Balanced_acc\n",
       ":   0.0644279290950856Precision_long\n",
       ":   0.0751690653166649Precision_short\n",
       ":   0.0762386127023547Recall_long\n",
       ":   0.1372980805826Recall_short\n",
       ":   0.0330890623614759F1_long\n",
       ":   0.121760750264932F1_short\n",
       ":   0.0473945837980633Tile_cutoff\n",
       ":   21.1496128543992Tile_cutoff_SE\n",
       ":   3.71836366008217\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "     0.06458280      0.06442793      0.07516907      0.07623861      0.13729808 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "     0.03308906      0.12176075      0.04739458     21.14961285      3.71836366 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C>=2\n",
    "results = rbindlist(list(fold1_c2, fold2_c2, fold3_c2, fold4_c2, fold5_c2))\n",
    "row.names(results) = list(\"Fold1\", \"Fold2\", \"Fold3\", \"Fold4\", \"Fold5\")\n",
    "print('Logistic regression C>=2cm performance on validation folds:')\n",
    "results\n",
    "print(\"Means:\")\n",
    "colMeans(results)\n",
    "print(\"Standard deviations:\")\n",
    "sapply(results, sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "373b66e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression C>=3cm performance on validation folds:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Accuracy</th><th scope=col>Balanced_acc</th><th scope=col>Precision_long</th><th scope=col>Precision_short</th><th scope=col>Recall_long</th><th scope=col>Recall_short</th><th scope=col>F1_long</th><th scope=col>F1_short</th><th scope=col>Tile_cutoff</th><th scope=col>Tile_cutoff_SE</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Fold1</th><td>0.8396226</td><td>0.7352688</td><td>0.9375000</td><td>0.8222222</td><td>0.4838710</td><td>0.9866667</td><td>0.6382979</td><td>0.8969697</td><td>215.4402 </td><td>30.03522 </td></tr>\n",
       "\t<tr><th scope=row>Fold2</th><td>0.8301887</td><td>0.7326467</td><td>0.7894737</td><td>0.8390805</td><td>0.5172414</td><td>0.9480519</td><td>0.6250000</td><td>0.8902439</td><td>159.9537 </td><td>20.79854 </td></tr>\n",
       "\t<tr><th scope=row>Fold3</th><td>0.6603774</td><td>0.5654784</td><td>0.8571429</td><td>0.6464646</td><td>0.1463415</td><td>0.9846154</td><td>0.2500000</td><td>0.7804878</td><td>229.2683 </td><td>29.41158 </td></tr>\n",
       "\t<tr><th scope=row>Fold4</th><td>0.7830189</td><td>0.7075397</td><td>0.8095238</td><td>0.7764706</td><td>0.4722222</td><td>0.9428571</td><td>0.5964912</td><td>0.8516129</td><td>172.3057 </td><td>22.50250 </td></tr>\n",
       "\t<tr><th scope=row>Fold5</th><td>0.7333333</td><td>0.6567599</td><td>0.8235294</td><td>0.7159091</td><td>0.3589744</td><td>0.9545455</td><td>0.5000000</td><td>0.8181818</td><td>210.7667 </td><td>29.36552 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       "  & Accuracy & Balanced\\_acc & Precision\\_long & Precision\\_short & Recall\\_long & Recall\\_short & F1\\_long & F1\\_short & Tile\\_cutoff & Tile\\_cutoff\\_SE\\\\\n",
       "\\hline\n",
       "\tFold1 & 0.8396226 & 0.7352688 & 0.9375000 & 0.8222222 & 0.4838710 & 0.9866667 & 0.6382979 & 0.8969697 & 215.4402  & 30.03522 \\\\\n",
       "\tFold2 & 0.8301887 & 0.7326467 & 0.7894737 & 0.8390805 & 0.5172414 & 0.9480519 & 0.6250000 & 0.8902439 & 159.9537  & 20.79854 \\\\\n",
       "\tFold3 & 0.6603774 & 0.5654784 & 0.8571429 & 0.6464646 & 0.1463415 & 0.9846154 & 0.2500000 & 0.7804878 & 229.2683  & 29.41158 \\\\\n",
       "\tFold4 & 0.7830189 & 0.7075397 & 0.8095238 & 0.7764706 & 0.4722222 & 0.9428571 & 0.5964912 & 0.8516129 & 172.3057  & 22.50250 \\\\\n",
       "\tFold5 & 0.7333333 & 0.6567599 & 0.8235294 & 0.7159091 & 0.3589744 & 0.9545455 & 0.5000000 & 0.8181818 & 210.7667  & 29.36552 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Accuracy | Balanced_acc | Precision_long | Precision_short | Recall_long | Recall_short | F1_long | F1_short | Tile_cutoff | Tile_cutoff_SE |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Fold1 | 0.8396226 | 0.7352688 | 0.9375000 | 0.8222222 | 0.4838710 | 0.9866667 | 0.6382979 | 0.8969697 | 215.4402  | 30.03522  |\n",
       "| Fold2 | 0.8301887 | 0.7326467 | 0.7894737 | 0.8390805 | 0.5172414 | 0.9480519 | 0.6250000 | 0.8902439 | 159.9537  | 20.79854  |\n",
       "| Fold3 | 0.6603774 | 0.5654784 | 0.8571429 | 0.6464646 | 0.1463415 | 0.9846154 | 0.2500000 | 0.7804878 | 229.2683  | 29.41158  |\n",
       "| Fold4 | 0.7830189 | 0.7075397 | 0.8095238 | 0.7764706 | 0.4722222 | 0.9428571 | 0.5964912 | 0.8516129 | 172.3057  | 22.50250  |\n",
       "| Fold5 | 0.7333333 | 0.6567599 | 0.8235294 | 0.7159091 | 0.3589744 | 0.9545455 | 0.5000000 | 0.8181818 | 210.7667  | 29.36552  |\n",
       "\n"
      ],
      "text/plain": [
       "  Accuracy  Balanced_acc Precision_long Precision_short Recall_long\n",
       "1 0.8396226 0.7352688    0.9375000      0.8222222       0.4838710  \n",
       "2 0.8301887 0.7326467    0.7894737      0.8390805       0.5172414  \n",
       "3 0.6603774 0.5654784    0.8571429      0.6464646       0.1463415  \n",
       "4 0.7830189 0.7075397    0.8095238      0.7764706       0.4722222  \n",
       "5 0.7333333 0.6567599    0.8235294      0.7159091       0.3589744  \n",
       "  Recall_short F1_long   F1_short  Tile_cutoff Tile_cutoff_SE\n",
       "1 0.9866667    0.6382979 0.8969697 215.4402    30.03522      \n",
       "2 0.9480519    0.6250000 0.8902439 159.9537    20.79854      \n",
       "3 0.9846154    0.2500000 0.7804878 229.2683    29.41158      \n",
       "4 0.9428571    0.5964912 0.8516129 172.3057    22.50250      \n",
       "5 0.9545455    0.5000000 0.8181818 210.7667    29.36552      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Means:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.769308176100629</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.679538698840009</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.84343395252838</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.760029401520274</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.395730078332699</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.963347319347319</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.52195782008212</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.847499225138879</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>197.54694048799</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>26.4226706180436</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.769308176100629\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.679538698840009\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.84343395252838\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.760029401520274\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.395730078332699\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.963347319347319\n",
       "\\item[F1\\textbackslash{}\\_long] 0.52195782008212\n",
       "\\item[F1\\textbackslash{}\\_short] 0.847499225138879\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 197.54694048799\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 26.4226706180436\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.769308176100629Balanced_acc\n",
       ":   0.679538698840009Precision_long\n",
       ":   0.84343395252838Precision_short\n",
       ":   0.760029401520274Recall_long\n",
       ":   0.395730078332699Recall_short\n",
       ":   0.963347319347319F1_long\n",
       ":   0.52195782008212F1_short\n",
       ":   0.847499225138879Tile_cutoff\n",
       ":   197.54694048799Tile_cutoff_SE\n",
       ":   26.4226706180436\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "      0.7693082       0.6795387       0.8434340       0.7600294       0.3957301 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "      0.9633473       0.5219578       0.8474992     197.5469405      26.4226706 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Standard deviations:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.07415971803562</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.0711318788807062</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.0580821712128598</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.0794211633904253</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.151600234897779</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.0207809473995966</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.161362270430997</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.0490953107845334</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>29.7974406141178</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>4.40576664081015</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.07415971803562\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.0711318788807062\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.0580821712128598\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.0794211633904253\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.151600234897779\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.0207809473995966\n",
       "\\item[F1\\textbackslash{}\\_long] 0.161362270430997\n",
       "\\item[F1\\textbackslash{}\\_short] 0.0490953107845334\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 29.7974406141178\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 4.40576664081015\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.07415971803562Balanced_acc\n",
       ":   0.0711318788807062Precision_long\n",
       ":   0.0580821712128598Precision_short\n",
       ":   0.0794211633904253Recall_long\n",
       ":   0.151600234897779Recall_short\n",
       ":   0.0207809473995966F1_long\n",
       ":   0.161362270430997F1_short\n",
       ":   0.0490953107845334Tile_cutoff\n",
       ":   29.7974406141178Tile_cutoff_SE\n",
       ":   4.40576664081015\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "     0.07415972      0.07113188      0.05808217      0.07942116      0.15160023 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "     0.02078095      0.16136227      0.04909531     29.79744061      4.40576664 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C>=3\n",
    "results = rbindlist(list(fold1_c3, fold2_c3, fold3_c3, fold4_c3, fold5_c3))\n",
    "row.names(results) = list(\"Fold1\", \"Fold2\", \"Fold3\", \"Fold4\", \"Fold5\")\n",
    "print('Logistic regression C>=3cm performance on validation folds:')\n",
    "results\n",
    "print(\"Means:\")\n",
    "colMeans(results)\n",
    "print(\"Standard deviations:\")\n",
    "sapply(results, sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a0827e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression M>=1cm performance on validation folds:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Accuracy</th><th scope=col>Balanced_acc</th><th scope=col>Precision_long</th><th scope=col>Precision_short</th><th scope=col>Recall_long</th><th scope=col>Recall_short</th><th scope=col>F1_long</th><th scope=col>F1_short</th><th scope=col>Tile_cutoff</th><th scope=col>Tile_cutoff_SE</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Fold1</th><td>0.7924528</td><td>0.8143896</td><td>0.9245283</td><td>0.6603774</td><td>0.7313433</td><td>0.8974359</td><td>0.8166667</td><td>0.7608696</td><td>6.123937 </td><td>2.402157 </td></tr>\n",
       "\t<tr><th scope=row>Fold2</th><td>0.8773585</td><td>0.8786657</td><td>0.9152542</td><td>0.8297872</td><td>0.8709677</td><td>0.8863636</td><td>0.8925620</td><td>0.8571429</td><td>4.632022 </td><td>0.746372 </td></tr>\n",
       "\t<tr><th scope=row>Fold3</th><td>0.8113208</td><td>0.8559966</td><td>0.9821429</td><td>0.6200000</td><td>0.7432432</td><td>0.9687500</td><td>0.8461538</td><td>0.7560976</td><td>7.806023 </td><td>2.398120 </td></tr>\n",
       "\t<tr><th scope=row>Fold4</th><td>0.7924528</td><td>0.8475275</td><td>0.9827586</td><td>0.5625000</td><td>0.7307692</td><td>0.9642857</td><td>0.8382353</td><td>0.7105263</td><td>7.499915 </td><td>2.213443 </td></tr>\n",
       "\t<tr><th scope=row>Fold5</th><td>0.8571429</td><td>0.8517873</td><td>0.9275362</td><td>0.7222222</td><td>0.8648649</td><td>0.8387097</td><td>0.8951049</td><td>0.7761194</td><td>6.275538 </td><td>2.325775 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       "  & Accuracy & Balanced\\_acc & Precision\\_long & Precision\\_short & Recall\\_long & Recall\\_short & F1\\_long & F1\\_short & Tile\\_cutoff & Tile\\_cutoff\\_SE\\\\\n",
       "\\hline\n",
       "\tFold1 & 0.7924528 & 0.8143896 & 0.9245283 & 0.6603774 & 0.7313433 & 0.8974359 & 0.8166667 & 0.7608696 & 6.123937  & 2.402157 \\\\\n",
       "\tFold2 & 0.8773585 & 0.8786657 & 0.9152542 & 0.8297872 & 0.8709677 & 0.8863636 & 0.8925620 & 0.8571429 & 4.632022  & 0.746372 \\\\\n",
       "\tFold3 & 0.8113208 & 0.8559966 & 0.9821429 & 0.6200000 & 0.7432432 & 0.9687500 & 0.8461538 & 0.7560976 & 7.806023  & 2.398120 \\\\\n",
       "\tFold4 & 0.7924528 & 0.8475275 & 0.9827586 & 0.5625000 & 0.7307692 & 0.9642857 & 0.8382353 & 0.7105263 & 7.499915  & 2.213443 \\\\\n",
       "\tFold5 & 0.8571429 & 0.8517873 & 0.9275362 & 0.7222222 & 0.8648649 & 0.8387097 & 0.8951049 & 0.7761194 & 6.275538  & 2.325775 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Accuracy | Balanced_acc | Precision_long | Precision_short | Recall_long | Recall_short | F1_long | F1_short | Tile_cutoff | Tile_cutoff_SE |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Fold1 | 0.7924528 | 0.8143896 | 0.9245283 | 0.6603774 | 0.7313433 | 0.8974359 | 0.8166667 | 0.7608696 | 6.123937  | 2.402157  |\n",
       "| Fold2 | 0.8773585 | 0.8786657 | 0.9152542 | 0.8297872 | 0.8709677 | 0.8863636 | 0.8925620 | 0.8571429 | 4.632022  | 0.746372  |\n",
       "| Fold3 | 0.8113208 | 0.8559966 | 0.9821429 | 0.6200000 | 0.7432432 | 0.9687500 | 0.8461538 | 0.7560976 | 7.806023  | 2.398120  |\n",
       "| Fold4 | 0.7924528 | 0.8475275 | 0.9827586 | 0.5625000 | 0.7307692 | 0.9642857 | 0.8382353 | 0.7105263 | 7.499915  | 2.213443  |\n",
       "| Fold5 | 0.8571429 | 0.8517873 | 0.9275362 | 0.7222222 | 0.8648649 | 0.8387097 | 0.8951049 | 0.7761194 | 6.275538  | 2.325775  |\n",
       "\n"
      ],
      "text/plain": [
       "  Accuracy  Balanced_acc Precision_long Precision_short Recall_long\n",
       "1 0.7924528 0.8143896    0.9245283      0.6603774       0.7313433  \n",
       "2 0.8773585 0.8786657    0.9152542      0.8297872       0.8709677  \n",
       "3 0.8113208 0.8559966    0.9821429      0.6200000       0.7432432  \n",
       "4 0.7924528 0.8475275    0.9827586      0.5625000       0.7307692  \n",
       "5 0.8571429 0.8517873    0.9275362      0.7222222       0.8648649  \n",
       "  Recall_short F1_long   F1_short  Tile_cutoff Tile_cutoff_SE\n",
       "1 0.8974359    0.8166667 0.7608696 6.123937    2.402157      \n",
       "2 0.8863636    0.8925620 0.8571429 4.632022    0.746372      \n",
       "3 0.9687500    0.8461538 0.7560976 7.806023    2.398120      \n",
       "4 0.9642857    0.8382353 0.7105263 7.499915    2.213443      \n",
       "5 0.8387097    0.8951049 0.7761194 6.275538    2.325775      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Means:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.826145552560647</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.849673328989952</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.9464440497783</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.678977362951068</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.788237672878982</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.911108985100921</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.857744537102826</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.772151140422081</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>6.46748706648847</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>2.01717332068548</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.826145552560647\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.849673328989952\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.9464440497783\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.678977362951068\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.788237672878982\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.911108985100921\n",
       "\\item[F1\\textbackslash{}\\_long] 0.857744537102826\n",
       "\\item[F1\\textbackslash{}\\_short] 0.772151140422081\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 6.46748706648847\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 2.01717332068548\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.826145552560647Balanced_acc\n",
       ":   0.849673328989952Precision_long\n",
       ":   0.9464440497783Precision_short\n",
       ":   0.678977362951068Recall_long\n",
       ":   0.788237672878982Recall_short\n",
       ":   0.911108985100921F1_long\n",
       ":   0.857744537102826F1_short\n",
       ":   0.772151140422081Tile_cutoff\n",
       ":   6.46748706648847Tile_cutoff_SE\n",
       ":   2.01717332068548\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "      0.8261456       0.8496733       0.9464440       0.6789774       0.7882377 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "      0.9111090       0.8577445       0.7721511       6.4674871       2.0171733 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Standard deviations:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.038967202950946</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.023100631105573</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.0331804268133532</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.102475607656944</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.072938472269387</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.0552068756781799</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.0346785129429883</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.0534367602453039</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>1.2630704687612</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>0.714497265437513</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.038967202950946\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.023100631105573\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.0331804268133532\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.102475607656944\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.072938472269387\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.0552068756781799\n",
       "\\item[F1\\textbackslash{}\\_long] 0.0346785129429883\n",
       "\\item[F1\\textbackslash{}\\_short] 0.0534367602453039\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 1.2630704687612\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 0.714497265437513\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.038967202950946Balanced_acc\n",
       ":   0.023100631105573Precision_long\n",
       ":   0.0331804268133532Precision_short\n",
       ":   0.102475607656944Recall_long\n",
       ":   0.072938472269387Recall_short\n",
       ":   0.0552068756781799F1_long\n",
       ":   0.0346785129429883F1_short\n",
       ":   0.0534367602453039Tile_cutoff\n",
       ":   1.2630704687612Tile_cutoff_SE\n",
       ":   0.714497265437513\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "     0.03896720      0.02310063      0.03318043      0.10247561      0.07293847 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "     0.05520688      0.03467851      0.05343676      1.26307047      0.71449727 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# M>=1\n",
    "results = rbindlist(list(fold1_m1, fold2_m1, fold3_m1, fold4_m1, fold5_m1))\n",
    "row.names(results) = list(\"Fold1\", \"Fold2\", \"Fold3\", \"Fold4\", \"Fold5\")\n",
    "print('Logistic regression M>=1cm performance on validation folds:')\n",
    "results\n",
    "print(\"Means:\")\n",
    "colMeans(results)\n",
    "print(\"Standard deviations:\")\n",
    "sapply(results, sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ac6a55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression M>=3cm performance on validation folds:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Accuracy</th><th scope=col>Balanced_acc</th><th scope=col>Precision_long</th><th scope=col>Precision_short</th><th scope=col>Recall_long</th><th scope=col>Recall_short</th><th scope=col>F1_long</th><th scope=col>F1_short</th><th scope=col>Tile_cutoff</th><th scope=col>Tile_cutoff_SE</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Fold1</th><td>0.8113208</td><td>0.8091168</td><td>0.9000000</td><td>0.7575758</td><td>0.6923077</td><td>0.9259259</td><td>0.7826087</td><td>0.8333333</td><td>25.35430 </td><td>3.939992 </td></tr>\n",
       "\t<tr><th scope=row>Fold2</th><td>0.8207547</td><td>0.8226496</td><td>0.9069767</td><td>0.7619048</td><td>0.7222222</td><td>0.9230769</td><td>0.8041237</td><td>0.8347826</td><td>22.79752 </td><td>3.199179 </td></tr>\n",
       "\t<tr><th scope=row>Fold3</th><td>0.7264151</td><td>0.7628299</td><td>0.9714286</td><td>0.6056338</td><td>0.5483871</td><td>0.9772727</td><td>0.7010309</td><td>0.7478261</td><td>32.01544 </td><td>4.806832 </td></tr>\n",
       "\t<tr><th scope=row>Fold4</th><td>0.7641509</td><td>0.7729895</td><td>0.8541667</td><td>0.6896552</td><td>0.6949153</td><td>0.8510638</td><td>0.7663551</td><td>0.7619048</td><td>23.76343 </td><td>3.547918 </td></tr>\n",
       "\t<tr><th scope=row>Fold5</th><td>0.8380952</td><td>0.8611111</td><td>0.9791667</td><td>0.7192982</td><td>0.7460317</td><td>0.9761905</td><td>0.8468468</td><td>0.8282828</td><td>28.14866 </td><td>4.411702 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       "  & Accuracy & Balanced\\_acc & Precision\\_long & Precision\\_short & Recall\\_long & Recall\\_short & F1\\_long & F1\\_short & Tile\\_cutoff & Tile\\_cutoff\\_SE\\\\\n",
       "\\hline\n",
       "\tFold1 & 0.8113208 & 0.8091168 & 0.9000000 & 0.7575758 & 0.6923077 & 0.9259259 & 0.7826087 & 0.8333333 & 25.35430  & 3.939992 \\\\\n",
       "\tFold2 & 0.8207547 & 0.8226496 & 0.9069767 & 0.7619048 & 0.7222222 & 0.9230769 & 0.8041237 & 0.8347826 & 22.79752  & 3.199179 \\\\\n",
       "\tFold3 & 0.7264151 & 0.7628299 & 0.9714286 & 0.6056338 & 0.5483871 & 0.9772727 & 0.7010309 & 0.7478261 & 32.01544  & 4.806832 \\\\\n",
       "\tFold4 & 0.7641509 & 0.7729895 & 0.8541667 & 0.6896552 & 0.6949153 & 0.8510638 & 0.7663551 & 0.7619048 & 23.76343  & 3.547918 \\\\\n",
       "\tFold5 & 0.8380952 & 0.8611111 & 0.9791667 & 0.7192982 & 0.7460317 & 0.9761905 & 0.8468468 & 0.8282828 & 28.14866  & 4.411702 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Accuracy | Balanced_acc | Precision_long | Precision_short | Recall_long | Recall_short | F1_long | F1_short | Tile_cutoff | Tile_cutoff_SE |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Fold1 | 0.8113208 | 0.8091168 | 0.9000000 | 0.7575758 | 0.6923077 | 0.9259259 | 0.7826087 | 0.8333333 | 25.35430  | 3.939992  |\n",
       "| Fold2 | 0.8207547 | 0.8226496 | 0.9069767 | 0.7619048 | 0.7222222 | 0.9230769 | 0.8041237 | 0.8347826 | 22.79752  | 3.199179  |\n",
       "| Fold3 | 0.7264151 | 0.7628299 | 0.9714286 | 0.6056338 | 0.5483871 | 0.9772727 | 0.7010309 | 0.7478261 | 32.01544  | 4.806832  |\n",
       "| Fold4 | 0.7641509 | 0.7729895 | 0.8541667 | 0.6896552 | 0.6949153 | 0.8510638 | 0.7663551 | 0.7619048 | 23.76343  | 3.547918  |\n",
       "| Fold5 | 0.8380952 | 0.8611111 | 0.9791667 | 0.7192982 | 0.7460317 | 0.9761905 | 0.8468468 | 0.8282828 | 28.14866  | 4.411702  |\n",
       "\n"
      ],
      "text/plain": [
       "  Accuracy  Balanced_acc Precision_long Precision_short Recall_long\n",
       "1 0.8113208 0.8091168    0.9000000      0.7575758       0.6923077  \n",
       "2 0.8207547 0.8226496    0.9069767      0.7619048       0.7222222  \n",
       "3 0.7264151 0.7628299    0.9714286      0.6056338       0.5483871  \n",
       "4 0.7641509 0.7729895    0.8541667      0.6896552       0.6949153  \n",
       "5 0.8380952 0.8611111    0.9791667      0.7192982       0.7460317  \n",
       "  Recall_short F1_long   F1_short  Tile_cutoff Tile_cutoff_SE\n",
       "1 0.9259259    0.7826087 0.8333333 25.35430    3.939992      \n",
       "2 0.9230769    0.8041237 0.8347826 22.79752    3.199179      \n",
       "3 0.9772727    0.7010309 0.7478261 32.01544    4.806832      \n",
       "4 0.8510638    0.7663551 0.7619048 23.76343    3.547918      \n",
       "5 0.9761905    0.8468468 0.8282828 28.14866    4.411702      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Means:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.79214734950584</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.805739389382643</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.92234772978959</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.70681354806505</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.680772802314628</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.930705976450657</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.780193064372239</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.80122592383462</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>26.4158705892846</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>3.98112454351814</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.79214734950584\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.805739389382643\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.92234772978959\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.70681354806505\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.680772802314628\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.930705976450657\n",
       "\\item[F1\\textbackslash{}\\_long] 0.780193064372239\n",
       "\\item[F1\\textbackslash{}\\_short] 0.80122592383462\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 26.4158705892846\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 3.98112454351814\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.79214734950584Balanced_acc\n",
       ":   0.805739389382643Precision_long\n",
       ":   0.92234772978959Precision_short\n",
       ":   0.70681354806505Recall_long\n",
       ":   0.680772802314628Recall_short\n",
       ":   0.930705976450657F1_long\n",
       ":   0.780193064372239F1_short\n",
       ":   0.80122592383462Tile_cutoff\n",
       ":   26.4158705892846Tile_cutoff_SE\n",
       ":   3.98112454351814\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "      0.7921473       0.8057394       0.9223477       0.7068135       0.6807728 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "      0.9307060       0.7801931       0.8012259      26.4158706       3.9811245 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Standard deviations:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.0458304962098707</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.0396142795573083</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.0524920617750363</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.0638346734406572</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.0771942708540043</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.0516266037578079</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.0535709106321927</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.0426811119701144</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>3.72869231649065</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>0.645753102906989</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.0458304962098707\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.0396142795573083\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.0524920617750363\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.0638346734406572\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.0771942708540043\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.0516266037578079\n",
       "\\item[F1\\textbackslash{}\\_long] 0.0535709106321927\n",
       "\\item[F1\\textbackslash{}\\_short] 0.0426811119701144\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 3.72869231649065\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 0.645753102906989\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.0458304962098707Balanced_acc\n",
       ":   0.0396142795573083Precision_long\n",
       ":   0.0524920617750363Precision_short\n",
       ":   0.0638346734406572Recall_long\n",
       ":   0.0771942708540043Recall_short\n",
       ":   0.0516266037578079F1_long\n",
       ":   0.0535709106321927F1_short\n",
       ":   0.0426811119701144Tile_cutoff\n",
       ":   3.72869231649065Tile_cutoff_SE\n",
       ":   0.645753102906989\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "     0.04583050      0.03961428      0.05249206      0.06383467      0.07719427 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "     0.05162660      0.05357091      0.04268111      3.72869232      0.64575310 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# M>=3\n",
    "results = rbindlist(list(fold1_m3, fold2_m3, fold3_m3, fold4_m3, fold5_m3))\n",
    "row.names(results) = list(\"Fold1\", \"Fold2\", \"Fold3\", \"Fold4\", \"Fold5\")\n",
    "print('Logistic regression M>=3cm performance on validation folds:')\n",
    "results\n",
    "print(\"Means:\")\n",
    "colMeans(results)\n",
    "print(\"Standard deviations:\")\n",
    "sapply(results, sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8bf3f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression M>=4cm performance on validation folds:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Accuracy</th><th scope=col>Balanced_acc</th><th scope=col>Precision_long</th><th scope=col>Precision_short</th><th scope=col>Recall_long</th><th scope=col>Recall_short</th><th scope=col>F1_long</th><th scope=col>F1_short</th><th scope=col>Tile_cutoff</th><th scope=col>Tile_cutoff_SE</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Fold1</th><td>0.8018868</td><td>0.7473485</td><td>0.9130435</td><td>0.7710843</td><td>0.5250000</td><td>0.9696970</td><td>0.6666667</td><td>0.8590604</td><td>60.29165 </td><td>7.463463 </td></tr>\n",
       "\t<tr><th scope=row>Fold2</th><td>0.7830189</td><td>0.7518939</td><td>0.7575758</td><td>0.7945205</td><td>0.6250000</td><td>0.8787879</td><td>0.6849315</td><td>0.8345324</td><td>49.65496 </td><td>5.847664 </td></tr>\n",
       "\t<tr><th scope=row>Fold3</th><td>0.6698113</td><td>0.6638177</td><td>0.9473684</td><td>0.6091954</td><td>0.3461538</td><td>0.9814815</td><td>0.5070423</td><td>0.7517730</td><td>74.03452 </td><td>8.838432 </td></tr>\n",
       "\t<tr><th scope=row>Fold4</th><td>0.8301887</td><td>0.8170290</td><td>0.8684211</td><td>0.8088235</td><td>0.7173913</td><td>0.9166667</td><td>0.7857143</td><td>0.8593750</td><td>61.61561 </td><td>8.053148 </td></tr>\n",
       "\t<tr><th scope=row>Fold5</th><td>0.7714286</td><td>0.7878289</td><td>0.9714286</td><td>0.6714286</td><td>0.5964912</td><td>0.9791667</td><td>0.7391304</td><td>0.7966102</td><td>74.58965 </td><td>9.625424 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       "  & Accuracy & Balanced\\_acc & Precision\\_long & Precision\\_short & Recall\\_long & Recall\\_short & F1\\_long & F1\\_short & Tile\\_cutoff & Tile\\_cutoff\\_SE\\\\\n",
       "\\hline\n",
       "\tFold1 & 0.8018868 & 0.7473485 & 0.9130435 & 0.7710843 & 0.5250000 & 0.9696970 & 0.6666667 & 0.8590604 & 60.29165  & 7.463463 \\\\\n",
       "\tFold2 & 0.7830189 & 0.7518939 & 0.7575758 & 0.7945205 & 0.6250000 & 0.8787879 & 0.6849315 & 0.8345324 & 49.65496  & 5.847664 \\\\\n",
       "\tFold3 & 0.6698113 & 0.6638177 & 0.9473684 & 0.6091954 & 0.3461538 & 0.9814815 & 0.5070423 & 0.7517730 & 74.03452  & 8.838432 \\\\\n",
       "\tFold4 & 0.8301887 & 0.8170290 & 0.8684211 & 0.8088235 & 0.7173913 & 0.9166667 & 0.7857143 & 0.8593750 & 61.61561  & 8.053148 \\\\\n",
       "\tFold5 & 0.7714286 & 0.7878289 & 0.9714286 & 0.6714286 & 0.5964912 & 0.9791667 & 0.7391304 & 0.7966102 & 74.58965  & 9.625424 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Accuracy | Balanced_acc | Precision_long | Precision_short | Recall_long | Recall_short | F1_long | F1_short | Tile_cutoff | Tile_cutoff_SE |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Fold1 | 0.8018868 | 0.7473485 | 0.9130435 | 0.7710843 | 0.5250000 | 0.9696970 | 0.6666667 | 0.8590604 | 60.29165  | 7.463463  |\n",
       "| Fold2 | 0.7830189 | 0.7518939 | 0.7575758 | 0.7945205 | 0.6250000 | 0.8787879 | 0.6849315 | 0.8345324 | 49.65496  | 5.847664  |\n",
       "| Fold3 | 0.6698113 | 0.6638177 | 0.9473684 | 0.6091954 | 0.3461538 | 0.9814815 | 0.5070423 | 0.7517730 | 74.03452  | 8.838432  |\n",
       "| Fold4 | 0.8301887 | 0.8170290 | 0.8684211 | 0.8088235 | 0.7173913 | 0.9166667 | 0.7857143 | 0.8593750 | 61.61561  | 8.053148  |\n",
       "| Fold5 | 0.7714286 | 0.7878289 | 0.9714286 | 0.6714286 | 0.5964912 | 0.9791667 | 0.7391304 | 0.7966102 | 74.58965  | 9.625424  |\n",
       "\n"
      ],
      "text/plain": [
       "  Accuracy  Balanced_acc Precision_long Precision_short Recall_long\n",
       "1 0.8018868 0.7473485    0.9130435      0.7710843       0.5250000  \n",
       "2 0.7830189 0.7518939    0.7575758      0.7945205       0.6250000  \n",
       "3 0.6698113 0.6638177    0.9473684      0.6091954       0.3461538  \n",
       "4 0.8301887 0.8170290    0.8684211      0.8088235       0.7173913  \n",
       "5 0.7714286 0.7878289    0.9714286      0.6714286       0.5964912  \n",
       "  Recall_short F1_long   F1_short  Tile_cutoff Tile_cutoff_SE\n",
       "1 0.9696970    0.6666667 0.8590604 60.29165    7.463463      \n",
       "2 0.8787879    0.6849315 0.8345324 49.65496    5.847664      \n",
       "3 0.9814815    0.5070423 0.7517730 74.03452    8.838432      \n",
       "4 0.9166667    0.7857143 0.8593750 61.61561    8.053148      \n",
       "5 0.9791667    0.7391304 0.7966102 74.58965    9.625424      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Means:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.771266846361186</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.753583604187151</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.891567456189882</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.731010477686758</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.562007275714369</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.945159932659933</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.676697029506801</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.82027019918444</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>64.0372782424556</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>7.96562632259677</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.771266846361186\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.753583604187151\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.891567456189882\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.731010477686758\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.562007275714369\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.945159932659933\n",
       "\\item[F1\\textbackslash{}\\_long] 0.676697029506801\n",
       "\\item[F1\\textbackslash{}\\_short] 0.82027019918444\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 64.0372782424556\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 7.96562632259677\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.771266846361186Balanced_acc\n",
       ":   0.753583604187151Precision_long\n",
       ":   0.891567456189882Precision_short\n",
       ":   0.731010477686758Recall_long\n",
       ":   0.562007275714369Recall_short\n",
       ":   0.945159932659933F1_long\n",
       ":   0.676697029506801F1_short\n",
       ":   0.82027019918444Tile_cutoff\n",
       ":   64.0372782424556Tile_cutoff_SE\n",
       ":   7.96562632259677\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "      0.7712668       0.7535836       0.8915675       0.7310105       0.5620073 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "      0.9451599       0.6766970       0.8202702      64.0372782       7.9656263 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Standard deviations:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.0609112537446576</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.0576578608499188</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.0843242198688443</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.0867225899295756</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.138981711158523</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.0455381565154862</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.105751891302118</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.0460676987372735</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>10.4647355616364</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>1.4372118172605</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.0609112537446576\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.0576578608499188\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.0843242198688443\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.0867225899295756\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.138981711158523\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.0455381565154862\n",
       "\\item[F1\\textbackslash{}\\_long] 0.105751891302118\n",
       "\\item[F1\\textbackslash{}\\_short] 0.0460676987372735\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 10.4647355616364\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 1.4372118172605\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.0609112537446576Balanced_acc\n",
       ":   0.0576578608499188Precision_long\n",
       ":   0.0843242198688443Precision_short\n",
       ":   0.0867225899295756Recall_long\n",
       ":   0.138981711158523Recall_short\n",
       ":   0.0455381565154862F1_long\n",
       ":   0.105751891302118F1_short\n",
       ":   0.0460676987372735Tile_cutoff\n",
       ":   10.4647355616364Tile_cutoff_SE\n",
       ":   1.4372118172605\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "     0.06091125      0.05765786      0.08432422      0.08672259      0.13898171 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "     0.04553816      0.10575189      0.04606770     10.46473556      1.43721182 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# M>=4\n",
    "results = rbindlist(list(fold1_m4, fold2_m4, fold3_m4, fold4_m4, fold5_m4))\n",
    "row.names(results) = list(\"Fold1\", \"Fold2\", \"Fold3\", \"Fold4\", \"Fold5\")\n",
    "print('Logistic regression M>=4cm performance on validation folds:')\n",
    "results\n",
    "print(\"Means:\")\n",
    "colMeans(results)\n",
    "print(\"Standard deviations:\")\n",
    "sapply(results, sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2517670f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression M>=5cm performance on validation folds:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Accuracy</th><th scope=col>Balanced_acc</th><th scope=col>Precision_long</th><th scope=col>Precision_short</th><th scope=col>Recall_long</th><th scope=col>Recall_short</th><th scope=col>F1_long</th><th scope=col>F1_short</th><th scope=col>Tile_cutoff</th><th scope=col>Tile_cutoff_SE</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Fold1</th><td>0.8490566</td><td>0.7535088</td><td>0.8888889</td><td>0.8409091</td><td>0.5333333</td><td>0.9736842</td><td>0.6666667</td><td>0.9024390</td><td>166.7215 </td><td>22.24327 </td></tr>\n",
       "\t<tr><th scope=row>Fold2</th><td>0.8301887</td><td>0.7586996</td><td>0.7083333</td><td>0.8658537</td><td>0.6071429</td><td>0.9102564</td><td>0.6538462</td><td>0.8875000</td><td>105.8656 </td><td>11.89924 </td></tr>\n",
       "\t<tr><th scope=row>Fold3</th><td>0.6603774</td><td>0.6029144</td><td>0.9090909</td><td>0.6315789</td><td>0.2222222</td><td>0.9836066</td><td>0.3571429</td><td>0.7692308</td><td>191.6891 </td><td>23.24246 </td></tr>\n",
       "\t<tr><th scope=row>Fold4</th><td>0.8113208</td><td>0.7484520</td><td>0.9090909</td><td>0.7857143</td><td>0.5263158</td><td>0.9705882</td><td>0.6666667</td><td>0.8684211</td><td>165.6450 </td><td>22.39686 </td></tr>\n",
       "\t<tr><th scope=row>Fold5</th><td>0.7333333</td><td>0.6851088</td><td>0.8571429</td><td>0.7023810</td><td>0.4186047</td><td>0.9516129</td><td>0.5625000</td><td>0.8082192</td><td>168.8066 </td><td>21.81099 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       "  & Accuracy & Balanced\\_acc & Precision\\_long & Precision\\_short & Recall\\_long & Recall\\_short & F1\\_long & F1\\_short & Tile\\_cutoff & Tile\\_cutoff\\_SE\\\\\n",
       "\\hline\n",
       "\tFold1 & 0.8490566 & 0.7535088 & 0.8888889 & 0.8409091 & 0.5333333 & 0.9736842 & 0.6666667 & 0.9024390 & 166.7215  & 22.24327 \\\\\n",
       "\tFold2 & 0.8301887 & 0.7586996 & 0.7083333 & 0.8658537 & 0.6071429 & 0.9102564 & 0.6538462 & 0.8875000 & 105.8656  & 11.89924 \\\\\n",
       "\tFold3 & 0.6603774 & 0.6029144 & 0.9090909 & 0.6315789 & 0.2222222 & 0.9836066 & 0.3571429 & 0.7692308 & 191.6891  & 23.24246 \\\\\n",
       "\tFold4 & 0.8113208 & 0.7484520 & 0.9090909 & 0.7857143 & 0.5263158 & 0.9705882 & 0.6666667 & 0.8684211 & 165.6450  & 22.39686 \\\\\n",
       "\tFold5 & 0.7333333 & 0.6851088 & 0.8571429 & 0.7023810 & 0.4186047 & 0.9516129 & 0.5625000 & 0.8082192 & 168.8066  & 21.81099 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Accuracy | Balanced_acc | Precision_long | Precision_short | Recall_long | Recall_short | F1_long | F1_short | Tile_cutoff | Tile_cutoff_SE |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Fold1 | 0.8490566 | 0.7535088 | 0.8888889 | 0.8409091 | 0.5333333 | 0.9736842 | 0.6666667 | 0.9024390 | 166.7215  | 22.24327  |\n",
       "| Fold2 | 0.8301887 | 0.7586996 | 0.7083333 | 0.8658537 | 0.6071429 | 0.9102564 | 0.6538462 | 0.8875000 | 105.8656  | 11.89924  |\n",
       "| Fold3 | 0.6603774 | 0.6029144 | 0.9090909 | 0.6315789 | 0.2222222 | 0.9836066 | 0.3571429 | 0.7692308 | 191.6891  | 23.24246  |\n",
       "| Fold4 | 0.8113208 | 0.7484520 | 0.9090909 | 0.7857143 | 0.5263158 | 0.9705882 | 0.6666667 | 0.8684211 | 165.6450  | 22.39686  |\n",
       "| Fold5 | 0.7333333 | 0.6851088 | 0.8571429 | 0.7023810 | 0.4186047 | 0.9516129 | 0.5625000 | 0.8082192 | 168.8066  | 21.81099  |\n",
       "\n"
      ],
      "text/plain": [
       "  Accuracy  Balanced_acc Precision_long Precision_short Recall_long\n",
       "1 0.8490566 0.7535088    0.8888889      0.8409091       0.5333333  \n",
       "2 0.8301887 0.7586996    0.7083333      0.8658537       0.6071429  \n",
       "3 0.6603774 0.6029144    0.9090909      0.6315789       0.2222222  \n",
       "4 0.8113208 0.7484520    0.9090909      0.7857143       0.5263158  \n",
       "5 0.7333333 0.6851088    0.8571429      0.7023810       0.4186047  \n",
       "  Recall_short F1_long   F1_short  Tile_cutoff Tile_cutoff_SE\n",
       "1 0.9736842    0.6666667 0.9024390 166.7215    22.24327      \n",
       "2 0.9102564    0.6538462 0.8875000 105.8656    11.89924      \n",
       "3 0.9836066    0.3571429 0.7692308 191.6891    23.24246      \n",
       "4 0.9705882    0.6666667 0.8684211 165.6450    22.39686      \n",
       "5 0.9516129    0.5625000 0.8082192 168.8066    21.81099      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Means:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.77685534591195</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.709736717001459</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.854509379509379</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.765287386981867</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.461523770666978</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.95794966333594</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.581364468864469</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.847162004866957</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>159.745571342856</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>20.3185641431156</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.77685534591195\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.709736717001459\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.854509379509379\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.765287386981867\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.461523770666978\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.95794966333594\n",
       "\\item[F1\\textbackslash{}\\_long] 0.581364468864469\n",
       "\\item[F1\\textbackslash{}\\_short] 0.847162004866957\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 159.745571342856\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 20.3185641431156\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.77685534591195Balanced_acc\n",
       ":   0.709736717001459Precision_long\n",
       ":   0.854509379509379Precision_short\n",
       ":   0.765287386981867Recall_long\n",
       ":   0.461523770666978Recall_short\n",
       ":   0.95794966333594F1_long\n",
       ":   0.581364468864469F1_short\n",
       ":   0.847162004866957Tile_cutoff\n",
       ":   159.745571342856Tile_cutoff_SE\n",
       ":   20.3185641431156\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "      0.7768553       0.7097367       0.8545094       0.7652874       0.4615238 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "      0.9579497       0.5813645       0.8471620     159.7455713      20.3185641 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Standard deviations:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>Accuracy</dt>\n",
       "\t\t<dd>0.0785916942462338</dd>\n",
       "\t<dt>Balanced_acc</dt>\n",
       "\t\t<dd>0.0667640979658089</dd>\n",
       "\t<dt>Precision_long</dt>\n",
       "\t\t<dd>0.0844313465014655</dd>\n",
       "\t<dt>Precision_short</dt>\n",
       "\t\t<dd>0.097576433641992</dd>\n",
       "\t<dt>Recall_long</dt>\n",
       "\t\t<dd>0.149722091927447</dd>\n",
       "\t<dt>Recall_short</dt>\n",
       "\t\t<dd>0.0290705461174466</dd>\n",
       "\t<dt>F1_long</dt>\n",
       "\t\t<dd>0.132700531184064</dd>\n",
       "\t<dt>F1_short</dt>\n",
       "\t\t<dd>0.0564013986891304</dd>\n",
       "\t<dt>Tile_cutoff</dt>\n",
       "\t\t<dd>31.972653978075</dd>\n",
       "\t<dt>Tile_cutoff_SE</dt>\n",
       "\t\t<dd>4.73511745498275</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.0785916942462338\n",
       "\\item[Balanced\\textbackslash{}\\_acc] 0.0667640979658089\n",
       "\\item[Precision\\textbackslash{}\\_long] 0.0844313465014655\n",
       "\\item[Precision\\textbackslash{}\\_short] 0.097576433641992\n",
       "\\item[Recall\\textbackslash{}\\_long] 0.149722091927447\n",
       "\\item[Recall\\textbackslash{}\\_short] 0.0290705461174466\n",
       "\\item[F1\\textbackslash{}\\_long] 0.132700531184064\n",
       "\\item[F1\\textbackslash{}\\_short] 0.0564013986891304\n",
       "\\item[Tile\\textbackslash{}\\_cutoff] 31.972653978075\n",
       "\\item[Tile\\textbackslash{}\\_cutoff\\textbackslash{}\\_SE] 4.73511745498275\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.0785916942462338Balanced_acc\n",
       ":   0.0667640979658089Precision_long\n",
       ":   0.0844313465014655Precision_short\n",
       ":   0.097576433641992Recall_long\n",
       ":   0.149722091927447Recall_short\n",
       ":   0.0290705461174466F1_long\n",
       ":   0.132700531184064F1_short\n",
       ":   0.0564013986891304Tile_cutoff\n",
       ":   31.972653978075Tile_cutoff_SE\n",
       ":   4.73511745498275\n",
       "\n"
      ],
      "text/plain": [
       "       Accuracy    Balanced_acc  Precision_long Precision_short     Recall_long \n",
       "     0.07859169      0.06676410      0.08443135      0.09757643      0.14972209 \n",
       "   Recall_short         F1_long        F1_short     Tile_cutoff  Tile_cutoff_SE \n",
       "     0.02907055      0.13270053      0.05640140     31.97265398      4.73511745 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# M>=5\n",
    "results = rbindlist(list(fold1_m5, fold2_m5, fold3_m5, fold4_m5, fold5_m5))\n",
    "row.names(results) = list(\"Fold1\", \"Fold2\", \"Fold3\", \"Fold4\", \"Fold5\")\n",
    "print('Logistic regression M>=5cm performance on validation folds:')\n",
    "results\n",
    "print(\"Means:\")\n",
    "colMeans(results)\n",
    "print(\"Standard deviations:\")\n",
    "sapply(results, sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a7cc08",
   "metadata": {},
   "source": [
    "Train a model on all BEST2 data and infer it on BEST3 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db7c8028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression C>=1 or M>=1cm performance on BEST3 test set:\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$Accuracy</dt>\n",
       "\t\t<dd>0.626582278481013</dd>\n",
       "\t<dt>$Balanced_acc</dt>\n",
       "\t\t<dd>0.602124183006536</dd>\n",
       "\t<dt>$Precision_long</dt>\n",
       "\t\t<dd>0.642201834862385</dd>\n",
       "\t<dt>$Precision_short</dt>\n",
       "\t\t<dd>0.591836734693878</dd>\n",
       "\t<dt>$Recall_long</dt>\n",
       "\t\t<dd>0.777777777777778</dd>\n",
       "\t<dt>$Recall_short</dt>\n",
       "\t\t<dd>0.426470588235294</dd>\n",
       "\t<dt>$F1_long</dt>\n",
       "\t\t<dd>0.703517587939699</dd>\n",
       "\t<dt>$F1_short</dt>\n",
       "\t\t<dd>0.495726495726496</dd>\n",
       "\t<dt>$Tile_cutoff</dt>\n",
       "\t\t<dd>6.61032258664991</dd>\n",
       "\t<dt>$Tile_cutoff_SE</dt>\n",
       "\t\t<dd><table>\n",
       "<tbody>\n",
       "\t<tr><td>1.785894</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$Accuracy] 0.626582278481013\n",
       "\\item[\\$Balanced\\_acc] 0.602124183006536\n",
       "\\item[\\$Precision\\_long] 0.642201834862385\n",
       "\\item[\\$Precision\\_short] 0.591836734693878\n",
       "\\item[\\$Recall\\_long] 0.777777777777778\n",
       "\\item[\\$Recall\\_short] 0.426470588235294\n",
       "\\item[\\$F1\\_long] 0.703517587939699\n",
       "\\item[\\$F1\\_short] 0.495726495726496\n",
       "\\item[\\$Tile\\_cutoff] 6.61032258664991\n",
       "\\item[\\$Tile\\_cutoff\\_SE] \\begin{tabular}{l}\n",
       "\t 1.785894\\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$Accuracy\n",
       ":   0.626582278481013\n",
       "$Balanced_acc\n",
       ":   0.602124183006536\n",
       "$Precision_long\n",
       ":   0.642201834862385\n",
       "$Precision_short\n",
       ":   0.591836734693878\n",
       "$Recall_long\n",
       ":   0.777777777777778\n",
       "$Recall_short\n",
       ":   0.426470588235294\n",
       "$F1_long\n",
       ":   0.703517587939699\n",
       "$F1_short\n",
       ":   0.495726495726496\n",
       "$Tile_cutoff\n",
       ":   6.61032258664991\n",
       "$Tile_cutoff_SE\n",
       ":   \n",
       "| 1.785894 |\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$Accuracy\n",
       "[1] 0.6265823\n",
       "\n",
       "$Balanced_acc\n",
       "[1] 0.6021242\n",
       "\n",
       "$Precision_long\n",
       "[1] 0.6422018\n",
       "\n",
       "$Precision_short\n",
       "[1] 0.5918367\n",
       "\n",
       "$Recall_long\n",
       "[1] 0.7777778\n",
       "\n",
       "$Recall_short\n",
       "[1] 0.4264706\n",
       "\n",
       "$F1_long\n",
       "[1] 0.7035176\n",
       "\n",
       "$F1_short\n",
       "[1] 0.4957265\n",
       "\n",
       "$Tile_cutoff\n",
       "[1] 6.610323\n",
       "\n",
       "$Tile_cutoff_SE\n",
       "         [,1]\n",
       "[1,] 1.785894\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  0  1\n",
       "         0 29 20\n",
       "         1 39 70\n",
       "                                          \n",
       "               Accuracy : 0.6266          \n",
       "                 95% CI : (0.5462, 0.7021)\n",
       "    No Information Rate : 0.5696          \n",
       "    P-Value [Acc > NIR] : 0.08539         \n",
       "                                          \n",
       "                  Kappa : 0.2115          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.01911         \n",
       "                                          \n",
       "            Sensitivity : 0.4265          \n",
       "            Specificity : 0.7778          \n",
       "         Pos Pred Value : 0.5918          \n",
       "         Neg Pred Value : 0.6422          \n",
       "             Prevalence : 0.4304          \n",
       "         Detection Rate : 0.1835          \n",
       "   Detection Prevalence : 0.3101          \n",
       "      Balanced Accuracy : 0.6021          \n",
       "                                          \n",
       "       'Positive' Class : 0               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C>=1 or M>=1cm\n",
    "\n",
    "print('Logistic regression C>=1 or M>=1cm performance on BEST3 test set:')\n",
    "\n",
    "# Train full BEST2 model\n",
    "logreg_c_gtet_1cm_or_m_gtet_1cm_best2 <- glm(C_gtet_1_or_M_gtet_1 ~ TFF3_positive_count, family='binomial', data = best2_tff3_prague_data)\n",
    "\n",
    "# Infer model on BEST3 data\n",
    "logreg_c_gtet_1cm_or_m_gtet_1cm_pred_best3 <- predict(logreg_c_gtet_1cm_or_m_gtet_1cm_best2, newdata=data.frame(TFF3_positive_count=best3_tff3_prague_data$TFF3_positive_count), type='response')\n",
    "\n",
    "# Print performance results\n",
    "METRIFY(best3_tff3_prague_data$C_gtet_1_or_M_gtet_1, logreg_c_gtet_1cm_or_m_gtet_1cm_pred_best3, logreg_c_gtet_1cm_or_m_gtet_1cm_best2)\n",
    "\n",
    "# Make confusion matrix\n",
    "confusionMatrix(factor(ifelse(logreg_c_gtet_1cm_or_m_gtet_1cm_pred_best3 >= 0.5, 1, 0)), \n",
    "                factor(best3_tff3_prague_data$C_gtet_1_or_M_gtet_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9299603e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression C>=1 or M>=3cm performance on BEST3 test set:\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$Accuracy</dt>\n",
       "\t\t<dd>0.746835443037975</dd>\n",
       "\t<dt>$Balanced_acc</dt>\n",
       "\t\t<dd>0.770749472877132</dd>\n",
       "\t<dt>$Precision_long</dt>\n",
       "\t\t<dd>0.549295774647887</dd>\n",
       "\t<dt>$Precision_short</dt>\n",
       "\t\t<dd>0.908045977011494</dd>\n",
       "\t<dt>$Recall_long</dt>\n",
       "\t\t<dd>0.829787234042553</dd>\n",
       "\t<dt>$Recall_short</dt>\n",
       "\t\t<dd>0.711711711711712</dd>\n",
       "\t<dt>$F1_long</dt>\n",
       "\t\t<dd>0.661016949152542</dd>\n",
       "\t<dt>$F1_short</dt>\n",
       "\t\t<dd>0.797979797979798</dd>\n",
       "\t<dt>$Tile_cutoff</dt>\n",
       "\t\t<dd>16.6991266147187</dd>\n",
       "\t<dt>$Tile_cutoff_SE</dt>\n",
       "\t\t<dd><table>\n",
       "<tbody>\n",
       "\t<tr><td>2.658796</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$Accuracy] 0.746835443037975\n",
       "\\item[\\$Balanced\\_acc] 0.770749472877132\n",
       "\\item[\\$Precision\\_long] 0.549295774647887\n",
       "\\item[\\$Precision\\_short] 0.908045977011494\n",
       "\\item[\\$Recall\\_long] 0.829787234042553\n",
       "\\item[\\$Recall\\_short] 0.711711711711712\n",
       "\\item[\\$F1\\_long] 0.661016949152542\n",
       "\\item[\\$F1\\_short] 0.797979797979798\n",
       "\\item[\\$Tile\\_cutoff] 16.6991266147187\n",
       "\\item[\\$Tile\\_cutoff\\_SE] \\begin{tabular}{l}\n",
       "\t 2.658796\\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$Accuracy\n",
       ":   0.746835443037975\n",
       "$Balanced_acc\n",
       ":   0.770749472877132\n",
       "$Precision_long\n",
       ":   0.549295774647887\n",
       "$Precision_short\n",
       ":   0.908045977011494\n",
       "$Recall_long\n",
       ":   0.829787234042553\n",
       "$Recall_short\n",
       ":   0.711711711711712\n",
       "$F1_long\n",
       ":   0.661016949152542\n",
       "$F1_short\n",
       ":   0.797979797979798\n",
       "$Tile_cutoff\n",
       ":   16.6991266147187\n",
       "$Tile_cutoff_SE\n",
       ":   \n",
       "| 2.658796 |\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$Accuracy\n",
       "[1] 0.7468354\n",
       "\n",
       "$Balanced_acc\n",
       "[1] 0.7707495\n",
       "\n",
       "$Precision_long\n",
       "[1] 0.5492958\n",
       "\n",
       "$Precision_short\n",
       "[1] 0.908046\n",
       "\n",
       "$Recall_long\n",
       "[1] 0.8297872\n",
       "\n",
       "$Recall_short\n",
       "[1] 0.7117117\n",
       "\n",
       "$F1_long\n",
       "[1] 0.6610169\n",
       "\n",
       "$F1_short\n",
       "[1] 0.7979798\n",
       "\n",
       "$Tile_cutoff\n",
       "[1] 16.69913\n",
       "\n",
       "$Tile_cutoff_SE\n",
       "         [,1]\n",
       "[1,] 2.658796\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  0  1\n",
       "         0 79  8\n",
       "         1 32 39\n",
       "                                          \n",
       "               Accuracy : 0.7468          \n",
       "                 95% CI : (0.6716, 0.8126)\n",
       "    No Information Rate : 0.7025          \n",
       "    P-Value [Acc > NIR] : 0.1281916       \n",
       "                                          \n",
       "                  Kappa : 0.472           \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.0002762       \n",
       "                                          \n",
       "            Sensitivity : 0.7117          \n",
       "            Specificity : 0.8298          \n",
       "         Pos Pred Value : 0.9080          \n",
       "         Neg Pred Value : 0.5493          \n",
       "             Prevalence : 0.7025          \n",
       "         Detection Rate : 0.5000          \n",
       "   Detection Prevalence : 0.5506          \n",
       "      Balanced Accuracy : 0.7707          \n",
       "                                          \n",
       "       'Positive' Class : 0               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C>=1 or M>=3cm\n",
    "\n",
    "print('Logistic regression C>=1 or M>=3cm performance on BEST3 test set:')\n",
    "\n",
    "# Train full BEST2 model\n",
    "logreg_c_gtet_1cm_or_m_gtet_3cm_best2 <- glm(C_gtet_1_or_M_gtet_3 ~ TFF3_positive_count, family='binomial', data = best2_tff3_prague_data)\n",
    "\n",
    "# Infer model on BEST3 data\n",
    "logreg_c_gtet_1cm_or_m_gtet_3cm_pred_best3 <- predict(logreg_c_gtet_1cm_or_m_gtet_3cm_best2, newdata=data.frame(TFF3_positive_count=best3_tff3_prague_data$TFF3_positive_count), type='response')\n",
    "\n",
    "# Print performance results\n",
    "METRIFY(best3_tff3_prague_data$C_gtet_1_or_M_gtet_3, logreg_c_gtet_1cm_or_m_gtet_3cm_pred_best3, logreg_c_gtet_1cm_or_m_gtet_3cm_best2)\n",
    "\n",
    "# Make confusion matrix\n",
    "confusionMatrix(factor(ifelse(logreg_c_gtet_1cm_or_m_gtet_3cm_pred_best3 >= 0.5, 1, 0)), \n",
    "                factor(best3_tff3_prague_data$C_gtet_1_or_M_gtet_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "444f3939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression C>=2cm or M>=4cm performance on BEST3 test set:\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$Accuracy</dt>\n",
       "\t\t<dd>0.835443037974684</dd>\n",
       "\t<dt>$Balanced_acc</dt>\n",
       "\t\t<dd>0.728727272727273</dd>\n",
       "\t<dt>$Precision_long</dt>\n",
       "\t\t<dd>0.620689655172414</dd>\n",
       "\t<dt>$Precision_short</dt>\n",
       "\t\t<dd>0.883720930232558</dd>\n",
       "\t<dt>$Recall_long</dt>\n",
       "\t\t<dd>0.545454545454545</dd>\n",
       "\t<dt>$Recall_short</dt>\n",
       "\t\t<dd>0.912</dd>\n",
       "\t<dt>$F1_long</dt>\n",
       "\t\t<dd>0.580645161290323</dd>\n",
       "\t<dt>$F1_short</dt>\n",
       "\t\t<dd>0.897637795275591</dd>\n",
       "\t<dt>$Tile_cutoff</dt>\n",
       "\t\t<dd>44.3188624248495</dd>\n",
       "\t<dt>$Tile_cutoff_SE</dt>\n",
       "\t\t<dd><table>\n",
       "<tbody>\n",
       "\t<tr><td>5.305232</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$Accuracy] 0.835443037974684\n",
       "\\item[\\$Balanced\\_acc] 0.728727272727273\n",
       "\\item[\\$Precision\\_long] 0.620689655172414\n",
       "\\item[\\$Precision\\_short] 0.883720930232558\n",
       "\\item[\\$Recall\\_long] 0.545454545454545\n",
       "\\item[\\$Recall\\_short] 0.912\n",
       "\\item[\\$F1\\_long] 0.580645161290323\n",
       "\\item[\\$F1\\_short] 0.897637795275591\n",
       "\\item[\\$Tile\\_cutoff] 44.3188624248495\n",
       "\\item[\\$Tile\\_cutoff\\_SE] \\begin{tabular}{l}\n",
       "\t 5.305232\\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$Accuracy\n",
       ":   0.835443037974684\n",
       "$Balanced_acc\n",
       ":   0.728727272727273\n",
       "$Precision_long\n",
       ":   0.620689655172414\n",
       "$Precision_short\n",
       ":   0.883720930232558\n",
       "$Recall_long\n",
       ":   0.545454545454545\n",
       "$Recall_short\n",
       ":   0.912\n",
       "$F1_long\n",
       ":   0.580645161290323\n",
       "$F1_short\n",
       ":   0.897637795275591\n",
       "$Tile_cutoff\n",
       ":   44.3188624248495\n",
       "$Tile_cutoff_SE\n",
       ":   \n",
       "| 5.305232 |\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$Accuracy\n",
       "[1] 0.835443\n",
       "\n",
       "$Balanced_acc\n",
       "[1] 0.7287273\n",
       "\n",
       "$Precision_long\n",
       "[1] 0.6206897\n",
       "\n",
       "$Precision_short\n",
       "[1] 0.8837209\n",
       "\n",
       "$Recall_long\n",
       "[1] 0.5454545\n",
       "\n",
       "$Recall_short\n",
       "[1] 0.912\n",
       "\n",
       "$F1_long\n",
       "[1] 0.5806452\n",
       "\n",
       "$F1_short\n",
       "[1] 0.8976378\n",
       "\n",
       "$Tile_cutoff\n",
       "[1] 44.31886\n",
       "\n",
       "$Tile_cutoff_SE\n",
       "         [,1]\n",
       "[1,] 5.305232\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   0   1\n",
       "         0 114  15\n",
       "         1  11  18\n",
       "                                          \n",
       "               Accuracy : 0.8354          \n",
       "                 95% CI : (0.7683, 0.8896)\n",
       "    No Information Rate : 0.7911          \n",
       "    P-Value [Acc > NIR] : 0.09925         \n",
       "                                          \n",
       "                  Kappa : 0.4788          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.55630         \n",
       "                                          \n",
       "            Sensitivity : 0.9120          \n",
       "            Specificity : 0.5455          \n",
       "         Pos Pred Value : 0.8837          \n",
       "         Neg Pred Value : 0.6207          \n",
       "             Prevalence : 0.7911          \n",
       "         Detection Rate : 0.7215          \n",
       "   Detection Prevalence : 0.8165          \n",
       "      Balanced Accuracy : 0.7287          \n",
       "                                          \n",
       "       'Positive' Class : 0               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C>=2 or M>=4cm\n",
    "\n",
    "print('Logistic regression C>=2cm or M>=4cm performance on BEST3 test set:')\n",
    "\n",
    "# Train full BEST2 model\n",
    "logreg_c_gtet_2cm_or_m_gtet_4cm_best2 <- glm(C_gtet_2_or_M_gtet_4 ~ TFF3_positive_count, family='binomial', data = best2_tff3_prague_data)\n",
    "\n",
    "# Infer model on BEST3 data\n",
    "logreg_c_gtet_2cm_or_m_gtet_4cm_pred_best3 <- predict(logreg_c_gtet_2cm_or_m_gtet_4cm_best2, newdata=data.frame(TFF3_positive_count=best3_tff3_prague_data$TFF3_positive_count), type='response')\n",
    "\n",
    "# Print performance results\n",
    "METRIFY(best3_tff3_prague_data$C_gtet_2_or_M_gtet_4, logreg_c_gtet_2cm_or_m_gtet_4cm_pred_best3, logreg_c_gtet_2cm_or_m_gtet_4cm_best2)\n",
    "\n",
    "# Make confusion matrix\n",
    "confusionMatrix(factor(ifelse(logreg_c_gtet_2cm_or_m_gtet_4cm_pred_best3 >= 0.5, 1, 0)), \n",
    "                factor(best3_tff3_prague_data$C_gtet_2_or_M_gtet_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "822b359f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression C>=3 or M>=5cm performance on BEST3 test set:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$Accuracy</dt>\n",
       "\t\t<dd>0.867088607594937</dd>\n",
       "\t<dt>$Balanced_acc</dt>\n",
       "\t\t<dd>0.63365539452496</dd>\n",
       "\t<dt>$Precision_long</dt>\n",
       "\t\t<dd>0.583333333333333</dd>\n",
       "\t<dt>$Precision_short</dt>\n",
       "\t\t<dd>0.89041095890411</dd>\n",
       "\t<dt>$Recall_long</dt>\n",
       "\t\t<dd>0.304347826086957</dd>\n",
       "\t<dt>$Recall_short</dt>\n",
       "\t\t<dd>0.962962962962963</dd>\n",
       "\t<dt>$F1_long</dt>\n",
       "\t\t<dd>0.4</dd>\n",
       "\t<dt>$F1_short</dt>\n",
       "\t\t<dd>0.925266903914591</dd>\n",
       "\t<dt>$Tile_cutoff</dt>\n",
       "\t\t<dd>131.712210574605</dd>\n",
       "\t<dt>$Tile_cutoff_SE</dt>\n",
       "\t\t<dd><table>\n",
       "<tbody>\n",
       "\t<tr><td>15.61124</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$Accuracy] 0.867088607594937\n",
       "\\item[\\$Balanced\\_acc] 0.63365539452496\n",
       "\\item[\\$Precision\\_long] 0.583333333333333\n",
       "\\item[\\$Precision\\_short] 0.89041095890411\n",
       "\\item[\\$Recall\\_long] 0.304347826086957\n",
       "\\item[\\$Recall\\_short] 0.962962962962963\n",
       "\\item[\\$F1\\_long] 0.4\n",
       "\\item[\\$F1\\_short] 0.925266903914591\n",
       "\\item[\\$Tile\\_cutoff] 131.712210574605\n",
       "\\item[\\$Tile\\_cutoff\\_SE] \\begin{tabular}{l}\n",
       "\t 15.61124\\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$Accuracy\n",
       ":   0.867088607594937\n",
       "$Balanced_acc\n",
       ":   0.63365539452496\n",
       "$Precision_long\n",
       ":   0.583333333333333\n",
       "$Precision_short\n",
       ":   0.89041095890411\n",
       "$Recall_long\n",
       ":   0.304347826086957\n",
       "$Recall_short\n",
       ":   0.962962962962963\n",
       "$F1_long\n",
       ":   0.4\n",
       "$F1_short\n",
       ":   0.925266903914591\n",
       "$Tile_cutoff\n",
       ":   131.712210574605\n",
       "$Tile_cutoff_SE\n",
       ":   \n",
       "| 15.61124 |\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$Accuracy\n",
       "[1] 0.8670886\n",
       "\n",
       "$Balanced_acc\n",
       "[1] 0.6336554\n",
       "\n",
       "$Precision_long\n",
       "[1] 0.5833333\n",
       "\n",
       "$Precision_short\n",
       "[1] 0.890411\n",
       "\n",
       "$Recall_long\n",
       "[1] 0.3043478\n",
       "\n",
       "$Recall_short\n",
       "[1] 0.962963\n",
       "\n",
       "$F1_long\n",
       "[1] 0.4\n",
       "\n",
       "$F1_short\n",
       "[1] 0.9252669\n",
       "\n",
       "$Tile_cutoff\n",
       "[1] 131.7122\n",
       "\n",
       "$Tile_cutoff_SE\n",
       "         [,1]\n",
       "[1,] 15.61124\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   0   1\n",
       "         0 130  16\n",
       "         1   5   7\n",
       "                                         \n",
       "               Accuracy : 0.8671         \n",
       "                 95% CI : (0.804, 0.9158)\n",
       "    No Information Rate : 0.8544         \n",
       "    P-Value [Acc > NIR] : 0.3767         \n",
       "                                         \n",
       "                  Kappa : 0.3335         \n",
       "                                         \n",
       " Mcnemar's Test P-Value : 0.0291         \n",
       "                                         \n",
       "            Sensitivity : 0.9630         \n",
       "            Specificity : 0.3043         \n",
       "         Pos Pred Value : 0.8904         \n",
       "         Neg Pred Value : 0.5833         \n",
       "             Prevalence : 0.8544         \n",
       "         Detection Rate : 0.8228         \n",
       "   Detection Prevalence : 0.9241         \n",
       "      Balanced Accuracy : 0.6337         \n",
       "                                         \n",
       "       'Positive' Class : 0              \n",
       "                                         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C>=3 or M>=5cm\n",
    "\n",
    "print('Logistic regression C>=3 or M>=5cm performance on BEST3 test set:')\n",
    "\n",
    "# Train full BEST2 model\n",
    "logreg_c_gtet_3cm_or_m_gtet_5cm_best2 <- glm(C_gtet_3_or_M_gtet_5 ~ TFF3_positive_count, family='binomial', data = best2_tff3_prague_data)\n",
    "\n",
    "# Infer model on BEST3 data\n",
    "logreg_c_gtet_3cm_or_m_gtet_5cm_pred_best3 <- predict(logreg_c_gtet_3cm_or_m_gtet_5cm_best2, newdata=data.frame(TFF3_positive_count=best3_tff3_prague_data$TFF3_positive_count), type='response')\n",
    "\n",
    "# Print performance results\n",
    "METRIFY(best3_tff3_prague_data$C_gtet_3_or_M_gtet_5, logreg_c_gtet_3cm_or_m_gtet_5cm_pred_best3, logreg_c_gtet_3cm_or_m_gtet_5cm_best2)\n",
    "\n",
    "# Make confusion matrix\n",
    "confusionMatrix(factor(ifelse(logreg_c_gtet_3cm_or_m_gtet_5cm_pred_best3 >= 0.5, 1, 0)), \n",
    "                factor(best3_tff3_prague_data$C_gtet_3_or_M_gtet_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e30038a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression C>=1cm performance on BEST3 test set:\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$Accuracy</dt>\n",
       "\t\t<dd>0.791139240506329</dd>\n",
       "\t<dt>$Balanced_acc</dt>\n",
       "\t\t<dd>0.692620387742339</dd>\n",
       "\t<dt>$Precision_long</dt>\n",
       "\t\t<dd>0.625</dd>\n",
       "\t<dt>$Precision_short</dt>\n",
       "\t\t<dd>0.833333333333333</dd>\n",
       "\t<dt>$Recall_long</dt>\n",
       "\t\t<dd>0.48780487804878</dd>\n",
       "\t<dt>$Recall_short</dt>\n",
       "\t\t<dd>0.897435897435897</dd>\n",
       "\t<dt>$F1_long</dt>\n",
       "\t\t<dd>0.547945205479452</dd>\n",
       "\t<dt>$F1_short</dt>\n",
       "\t\t<dd>0.864197530864197</dd>\n",
       "\t<dt>$Tile_cutoff</dt>\n",
       "\t\t<dd>35.3714919681507</dd>\n",
       "\t<dt>$Tile_cutoff_SE</dt>\n",
       "\t\t<dd><table>\n",
       "<tbody>\n",
       "\t<tr><td>5.123556</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$Accuracy] 0.791139240506329\n",
       "\\item[\\$Balanced\\_acc] 0.692620387742339\n",
       "\\item[\\$Precision\\_long] 0.625\n",
       "\\item[\\$Precision\\_short] 0.833333333333333\n",
       "\\item[\\$Recall\\_long] 0.48780487804878\n",
       "\\item[\\$Recall\\_short] 0.897435897435897\n",
       "\\item[\\$F1\\_long] 0.547945205479452\n",
       "\\item[\\$F1\\_short] 0.864197530864197\n",
       "\\item[\\$Tile\\_cutoff] 35.3714919681507\n",
       "\\item[\\$Tile\\_cutoff\\_SE] \\begin{tabular}{l}\n",
       "\t 5.123556\\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$Accuracy\n",
       ":   0.791139240506329\n",
       "$Balanced_acc\n",
       ":   0.692620387742339\n",
       "$Precision_long\n",
       ":   0.625\n",
       "$Precision_short\n",
       ":   0.833333333333333\n",
       "$Recall_long\n",
       ":   0.48780487804878\n",
       "$Recall_short\n",
       ":   0.897435897435897\n",
       "$F1_long\n",
       ":   0.547945205479452\n",
       "$F1_short\n",
       ":   0.864197530864197\n",
       "$Tile_cutoff\n",
       ":   35.3714919681507\n",
       "$Tile_cutoff_SE\n",
       ":   \n",
       "| 5.123556 |\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$Accuracy\n",
       "[1] 0.7911392\n",
       "\n",
       "$Balanced_acc\n",
       "[1] 0.6926204\n",
       "\n",
       "$Precision_long\n",
       "[1] 0.625\n",
       "\n",
       "$Precision_short\n",
       "[1] 0.8333333\n",
       "\n",
       "$Recall_long\n",
       "[1] 0.4878049\n",
       "\n",
       "$Recall_short\n",
       "[1] 0.8974359\n",
       "\n",
       "$F1_long\n",
       "[1] 0.5479452\n",
       "\n",
       "$F1_short\n",
       "[1] 0.8641975\n",
       "\n",
       "$Tile_cutoff\n",
       "[1] 35.37149\n",
       "\n",
       "$Tile_cutoff_SE\n",
       "         [,1]\n",
       "[1,] 5.123556\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   0   1\n",
       "         0 105  21\n",
       "         1  12  20\n",
       "                                          \n",
       "               Accuracy : 0.7911          \n",
       "                 95% CI : (0.7194, 0.8517)\n",
       "    No Information Rate : 0.7405          \n",
       "    P-Value [Acc > NIR] : 0.08451         \n",
       "                                          \n",
       "                  Kappa : 0.4148          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.16373         \n",
       "                                          \n",
       "            Sensitivity : 0.8974          \n",
       "            Specificity : 0.4878          \n",
       "         Pos Pred Value : 0.8333          \n",
       "         Neg Pred Value : 0.6250          \n",
       "             Prevalence : 0.7405          \n",
       "         Detection Rate : 0.6646          \n",
       "   Detection Prevalence : 0.7975          \n",
       "      Balanced Accuracy : 0.6926          \n",
       "                                          \n",
       "       'Positive' Class : 0               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C>=1cm\n",
    "\n",
    "print('Logistic regression C>=1cm performance on BEST3 test set:')\n",
    "\n",
    "# Train full BEST2 model\n",
    "logreg_c_gtet_1cm_best2 <- glm(PRAGUE_C_gtet_1cm ~ TFF3_positive_count, family='binomial', data = best2_tff3_prague_data)\n",
    "\n",
    "# Infer model on BEST3 data\n",
    "logreg_c_gtet_1cm_pred_best3 <- predict(logreg_c_gtet_1cm_best2, newdata=data.frame(TFF3_positive_count=best3_tff3_prague_data$TFF3_positive_count), type='response')\n",
    "\n",
    "# Print performance results\n",
    "METRIFY(best3_tff3_prague_data$PRAGUE_C_gtet_1cm, logreg_c_gtet_1cm_pred_best3, logreg_c_gtet_1cm_best2)\n",
    "\n",
    "# Make confusion matrix\n",
    "confusionMatrix(factor(ifelse(logreg_c_gtet_1cm_pred_best3 >= 0.5, 1, 0)), \n",
    "                factor(best3_tff3_prague_data$PRAGUE_C_gtet_1cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05135a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression C>=2cm performance on BEST3 test set:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$Accuracy</dt>\n",
       "\t\t<dd>0.854430379746835</dd>\n",
       "\t<dt>$Balanced_acc</dt>\n",
       "\t\t<dd>0.68364073777065</dd>\n",
       "\t<dt>$Precision_long</dt>\n",
       "\t\t<dd>0.666666666666667</dd>\n",
       "\t<dt>$Precision_short</dt>\n",
       "\t\t<dd>0.878571428571429</dd>\n",
       "\t<dt>$Recall_long</dt>\n",
       "\t\t<dd>0.413793103448276</dd>\n",
       "\t<dt>$Recall_short</dt>\n",
       "\t\t<dd>0.953488372093023</dd>\n",
       "\t<dt>$F1_long</dt>\n",
       "\t\t<dd>0.51063829787234</dd>\n",
       "\t<dt>$F1_short</dt>\n",
       "\t\t<dd>0.914498141263941</dd>\n",
       "\t<dt>$Tile_cutoff</dt>\n",
       "\t\t<dd>98.5270633466262</dd>\n",
       "\t<dt>$Tile_cutoff_SE</dt>\n",
       "\t\t<dd><table>\n",
       "<tbody>\n",
       "\t<tr><td>12.36228</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$Accuracy] 0.854430379746835\n",
       "\\item[\\$Balanced\\_acc] 0.68364073777065\n",
       "\\item[\\$Precision\\_long] 0.666666666666667\n",
       "\\item[\\$Precision\\_short] 0.878571428571429\n",
       "\\item[\\$Recall\\_long] 0.413793103448276\n",
       "\\item[\\$Recall\\_short] 0.953488372093023\n",
       "\\item[\\$F1\\_long] 0.51063829787234\n",
       "\\item[\\$F1\\_short] 0.914498141263941\n",
       "\\item[\\$Tile\\_cutoff] 98.5270633466262\n",
       "\\item[\\$Tile\\_cutoff\\_SE] \\begin{tabular}{l}\n",
       "\t 12.36228\\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$Accuracy\n",
       ":   0.854430379746835\n",
       "$Balanced_acc\n",
       ":   0.68364073777065\n",
       "$Precision_long\n",
       ":   0.666666666666667\n",
       "$Precision_short\n",
       ":   0.878571428571429\n",
       "$Recall_long\n",
       ":   0.413793103448276\n",
       "$Recall_short\n",
       ":   0.953488372093023\n",
       "$F1_long\n",
       ":   0.51063829787234\n",
       "$F1_short\n",
       ":   0.914498141263941\n",
       "$Tile_cutoff\n",
       ":   98.5270633466262\n",
       "$Tile_cutoff_SE\n",
       ":   \n",
       "| 12.36228 |\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$Accuracy\n",
       "[1] 0.8544304\n",
       "\n",
       "$Balanced_acc\n",
       "[1] 0.6836407\n",
       "\n",
       "$Precision_long\n",
       "[1] 0.6666667\n",
       "\n",
       "$Precision_short\n",
       "[1] 0.8785714\n",
       "\n",
       "$Recall_long\n",
       "[1] 0.4137931\n",
       "\n",
       "$Recall_short\n",
       "[1] 0.9534884\n",
       "\n",
       "$F1_long\n",
       "[1] 0.5106383\n",
       "\n",
       "$F1_short\n",
       "[1] 0.9144981\n",
       "\n",
       "$Tile_cutoff\n",
       "[1] 98.52706\n",
       "\n",
       "$Tile_cutoff_SE\n",
       "         [,1]\n",
       "[1,] 12.36228\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   0   1\n",
       "         0 123  17\n",
       "         1   6  12\n",
       "                                          \n",
       "               Accuracy : 0.8544          \n",
       "                 95% CI : (0.7896, 0.9054)\n",
       "    No Information Rate : 0.8165          \n",
       "    P-Value [Acc > NIR] : 0.12762         \n",
       "                                          \n",
       "                  Kappa : 0.4306          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.03706         \n",
       "                                          \n",
       "            Sensitivity : 0.9535          \n",
       "            Specificity : 0.4138          \n",
       "         Pos Pred Value : 0.8786          \n",
       "         Neg Pred Value : 0.6667          \n",
       "             Prevalence : 0.8165          \n",
       "         Detection Rate : 0.7785          \n",
       "   Detection Prevalence : 0.8861          \n",
       "      Balanced Accuracy : 0.6836          \n",
       "                                          \n",
       "       'Positive' Class : 0               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C>=2cm\n",
    "\n",
    "print('Logistic regression C>=2cm performance on BEST3 test set:')\n",
    "\n",
    "# Train full BEST2 model\n",
    "logreg_c_gtet_2cm_best2 <- glm(PRAGUE_C_gtet_2cm ~ TFF3_positive_count, family='binomial', data = best2_tff3_prague_data)\n",
    "\n",
    "# Infer model on BEST3 data\n",
    "logreg_c_gtet_2cm_pred_best3 <- predict(logreg_c_gtet_2cm_best2, newdata=data.frame(TFF3_positive_count=best3_tff3_prague_data$TFF3_positive_count), type='response')\n",
    "\n",
    "# Print performance results\n",
    "METRIFY(best3_tff3_prague_data$PRAGUE_C_gtet_2cm, logreg_c_gtet_2cm_pred_best3, logreg_c_gtet_2cm_best2)\n",
    "\n",
    "# Make confusion matrix\n",
    "confusionMatrix(factor(ifelse(logreg_c_gtet_2cm_pred_best3 >= 0.5, 1, 0)), \n",
    "                factor(best3_tff3_prague_data$PRAGUE_C_gtet_2cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66cac474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression C>=3cm performance on BEST3 test set:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$Accuracy</dt>\n",
       "\t\t<dd>0.879746835443038</dd>\n",
       "\t<dt>$Balanced_acc</dt>\n",
       "\t\t<dd>0.593253968253968</dd>\n",
       "\t<dt>$Precision_long</dt>\n",
       "\t\t<dd>0.444444444444444</dd>\n",
       "\t<dt>$Precision_short</dt>\n",
       "\t\t<dd>0.906040268456376</dd>\n",
       "\t<dt>$Recall_long</dt>\n",
       "\t\t<dd>0.222222222222222</dd>\n",
       "\t<dt>$Recall_short</dt>\n",
       "\t\t<dd>0.964285714285714</dd>\n",
       "\t<dt>$F1_long</dt>\n",
       "\t\t<dd>0.296296296296296</dd>\n",
       "\t<dt>$F1_short</dt>\n",
       "\t\t<dd>0.934256055363322</dd>\n",
       "\t<dt>$Tile_cutoff</dt>\n",
       "\t\t<dd>197.846403218408</dd>\n",
       "\t<dt>$Tile_cutoff_SE</dt>\n",
       "\t\t<dd><table>\n",
       "<tbody>\n",
       "\t<tr><td>23.76505</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$Accuracy] 0.879746835443038\n",
       "\\item[\\$Balanced\\_acc] 0.593253968253968\n",
       "\\item[\\$Precision\\_long] 0.444444444444444\n",
       "\\item[\\$Precision\\_short] 0.906040268456376\n",
       "\\item[\\$Recall\\_long] 0.222222222222222\n",
       "\\item[\\$Recall\\_short] 0.964285714285714\n",
       "\\item[\\$F1\\_long] 0.296296296296296\n",
       "\\item[\\$F1\\_short] 0.934256055363322\n",
       "\\item[\\$Tile\\_cutoff] 197.846403218408\n",
       "\\item[\\$Tile\\_cutoff\\_SE] \\begin{tabular}{l}\n",
       "\t 23.76505\\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$Accuracy\n",
       ":   0.879746835443038\n",
       "$Balanced_acc\n",
       ":   0.593253968253968\n",
       "$Precision_long\n",
       ":   0.444444444444444\n",
       "$Precision_short\n",
       ":   0.906040268456376\n",
       "$Recall_long\n",
       ":   0.222222222222222\n",
       "$Recall_short\n",
       ":   0.964285714285714\n",
       "$F1_long\n",
       ":   0.296296296296296\n",
       "$F1_short\n",
       ":   0.934256055363322\n",
       "$Tile_cutoff\n",
       ":   197.846403218408\n",
       "$Tile_cutoff_SE\n",
       ":   \n",
       "| 23.76505 |\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$Accuracy\n",
       "[1] 0.8797468\n",
       "\n",
       "$Balanced_acc\n",
       "[1] 0.593254\n",
       "\n",
       "$Precision_long\n",
       "[1] 0.4444444\n",
       "\n",
       "$Precision_short\n",
       "[1] 0.9060403\n",
       "\n",
       "$Recall_long\n",
       "[1] 0.2222222\n",
       "\n",
       "$Recall_short\n",
       "[1] 0.9642857\n",
       "\n",
       "$F1_long\n",
       "[1] 0.2962963\n",
       "\n",
       "$F1_short\n",
       "[1] 0.9342561\n",
       "\n",
       "$Tile_cutoff\n",
       "[1] 197.8464\n",
       "\n",
       "$Tile_cutoff_SE\n",
       "         [,1]\n",
       "[1,] 23.76505\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   0   1\n",
       "         0 135  14\n",
       "         1   5   4\n",
       "                                         \n",
       "               Accuracy : 0.8797         \n",
       "                 95% CI : (0.8186, 0.926)\n",
       "    No Information Rate : 0.8861         \n",
       "    P-Value [Acc > NIR] : 0.65655        \n",
       "                                         \n",
       "                  Kappa : 0.2385         \n",
       "                                         \n",
       " Mcnemar's Test P-Value : 0.06646        \n",
       "                                         \n",
       "            Sensitivity : 0.9643         \n",
       "            Specificity : 0.2222         \n",
       "         Pos Pred Value : 0.9060         \n",
       "         Neg Pred Value : 0.4444         \n",
       "             Prevalence : 0.8861         \n",
       "         Detection Rate : 0.8544         \n",
       "   Detection Prevalence : 0.9430         \n",
       "      Balanced Accuracy : 0.5933         \n",
       "                                         \n",
       "       'Positive' Class : 0              \n",
       "                                         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C>=3cm\n",
    "\n",
    "print('Logistic regression C>=3cm performance on BEST3 test set:')\n",
    "\n",
    "# Train full BEST2 model\n",
    "logreg_c_gtet_3cm_best2 <- glm(PRAGUE_C_gtet_3cm ~ TFF3_positive_count, family='binomial', data = best2_tff3_prague_data)\n",
    "\n",
    "# Infer model on BEST3 data\n",
    "logreg_c_gtet_3cm_pred_best3 <- predict(logreg_c_gtet_3cm_best2, newdata=data.frame(TFF3_positive_count=best3_tff3_prague_data$TFF3_positive_count), type='response')\n",
    "\n",
    "# Print performance results\n",
    "METRIFY(best3_tff3_prague_data$PRAGUE_C_gtet_3cm, logreg_c_gtet_3cm_pred_best3, logreg_c_gtet_3cm_best2)\n",
    "\n",
    "# Make confusion matrix\n",
    "confusionMatrix(factor(ifelse(logreg_c_gtet_3cm_pred_best3 >= 0.5, 1, 0)), \n",
    "                factor(best3_tff3_prague_data$PRAGUE_C_gtet_3cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "18fdc240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression M>=1cm performance on BEST3 test set:\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“glm.fit: algorithm did not converge”Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$Accuracy</dt>\n",
       "\t\t<dd>0.626582278481013</dd>\n",
       "\t<dt>$Balanced_acc</dt>\n",
       "\t\t<dd>0.602124183006536</dd>\n",
       "\t<dt>$Precision_long</dt>\n",
       "\t\t<dd>0.642201834862385</dd>\n",
       "\t<dt>$Precision_short</dt>\n",
       "\t\t<dd>0.591836734693878</dd>\n",
       "\t<dt>$Recall_long</dt>\n",
       "\t\t<dd>0.777777777777778</dd>\n",
       "\t<dt>$Recall_short</dt>\n",
       "\t\t<dd>0.426470588235294</dd>\n",
       "\t<dt>$F1_long</dt>\n",
       "\t\t<dd>0.703517587939699</dd>\n",
       "\t<dt>$F1_short</dt>\n",
       "\t\t<dd>0.495726495726496</dd>\n",
       "\t<dt>$Tile_cutoff</dt>\n",
       "\t\t<dd>6.61032258664991</dd>\n",
       "\t<dt>$Tile_cutoff_SE</dt>\n",
       "\t\t<dd><table>\n",
       "<tbody>\n",
       "\t<tr><td>1.785894</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$Accuracy] 0.626582278481013\n",
       "\\item[\\$Balanced\\_acc] 0.602124183006536\n",
       "\\item[\\$Precision\\_long] 0.642201834862385\n",
       "\\item[\\$Precision\\_short] 0.591836734693878\n",
       "\\item[\\$Recall\\_long] 0.777777777777778\n",
       "\\item[\\$Recall\\_short] 0.426470588235294\n",
       "\\item[\\$F1\\_long] 0.703517587939699\n",
       "\\item[\\$F1\\_short] 0.495726495726496\n",
       "\\item[\\$Tile\\_cutoff] 6.61032258664991\n",
       "\\item[\\$Tile\\_cutoff\\_SE] \\begin{tabular}{l}\n",
       "\t 1.785894\\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$Accuracy\n",
       ":   0.626582278481013\n",
       "$Balanced_acc\n",
       ":   0.602124183006536\n",
       "$Precision_long\n",
       ":   0.642201834862385\n",
       "$Precision_short\n",
       ":   0.591836734693878\n",
       "$Recall_long\n",
       ":   0.777777777777778\n",
       "$Recall_short\n",
       ":   0.426470588235294\n",
       "$F1_long\n",
       ":   0.703517587939699\n",
       "$F1_short\n",
       ":   0.495726495726496\n",
       "$Tile_cutoff\n",
       ":   6.61032258664991\n",
       "$Tile_cutoff_SE\n",
       ":   \n",
       "| 1.785894 |\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$Accuracy\n",
       "[1] 0.6265823\n",
       "\n",
       "$Balanced_acc\n",
       "[1] 0.6021242\n",
       "\n",
       "$Precision_long\n",
       "[1] 0.6422018\n",
       "\n",
       "$Precision_short\n",
       "[1] 0.5918367\n",
       "\n",
       "$Recall_long\n",
       "[1] 0.7777778\n",
       "\n",
       "$Recall_short\n",
       "[1] 0.4264706\n",
       "\n",
       "$F1_long\n",
       "[1] 0.7035176\n",
       "\n",
       "$F1_short\n",
       "[1] 0.4957265\n",
       "\n",
       "$Tile_cutoff\n",
       "[1] 6.610323\n",
       "\n",
       "$Tile_cutoff_SE\n",
       "         [,1]\n",
       "[1,] 1.785894\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  0  1\n",
       "         0 29 20\n",
       "         1 39 70\n",
       "                                          \n",
       "               Accuracy : 0.6266          \n",
       "                 95% CI : (0.5462, 0.7021)\n",
       "    No Information Rate : 0.5696          \n",
       "    P-Value [Acc > NIR] : 0.08539         \n",
       "                                          \n",
       "                  Kappa : 0.2115          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.01911         \n",
       "                                          \n",
       "            Sensitivity : 0.4265          \n",
       "            Specificity : 0.7778          \n",
       "         Pos Pred Value : 0.5918          \n",
       "         Neg Pred Value : 0.6422          \n",
       "             Prevalence : 0.4304          \n",
       "         Detection Rate : 0.1835          \n",
       "   Detection Prevalence : 0.3101          \n",
       "      Balanced Accuracy : 0.6021          \n",
       "                                          \n",
       "       'Positive' Class : 0               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# M>=1cm\n",
    "\n",
    "print('Logistic regression M>=1cm performance on BEST3 test set:')\n",
    "\n",
    "# Train full BEST2 model\n",
    "logreg_m_gtet_1cm_best2 <- glm(PRAGUE_M_gtet_1cm ~ TFF3_positive_count, family='binomial', data = best2_tff3_prague_data)\n",
    "\n",
    "# Infer model on BEST3 data\n",
    "logreg_m_gtet_1cm_pred_best3 <- predict(logreg_m_gtet_1cm_best2, newdata=data.frame(TFF3_positive_count=best3_tff3_prague_data$TFF3_positive_count), type='response')\n",
    "\n",
    "# Print performance results\n",
    "METRIFY(best3_tff3_prague_data$PRAGUE_M_gtet_1cm, logreg_m_gtet_1cm_pred_best3, logreg_m_gtet_1cm_best2)\n",
    "\n",
    "# Make confusion matrix\n",
    "confusionMatrix(factor(ifelse(logreg_m_gtet_1cm_pred_best3 >= 0.5, 1, 0)), \n",
    "                factor(best3_tff3_prague_data$PRAGUE_M_gtet_1cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "66a4d86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression M>=3cm performance on BEST3 test set:\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$Accuracy</dt>\n",
       "\t\t<dd>0.80379746835443</dd>\n",
       "\t<dt>$Balanced_acc</dt>\n",
       "\t\t<dd>0.766321913380737</dd>\n",
       "\t<dt>$Precision_long</dt>\n",
       "\t\t<dd>0.58695652173913</dd>\n",
       "\t<dt>$Precision_short</dt>\n",
       "\t\t<dd>0.892857142857143</dd>\n",
       "\t<dt>$Recall_long</dt>\n",
       "\t\t<dd>0.692307692307692</dd>\n",
       "\t<dt>$Recall_short</dt>\n",
       "\t\t<dd>0.840336134453782</dd>\n",
       "\t<dt>$F1_long</dt>\n",
       "\t\t<dd>0.635294117647059</dd>\n",
       "\t<dt>$F1_short</dt>\n",
       "\t\t<dd>0.865800865800866</dd>\n",
       "\t<dt>$Tile_cutoff</dt>\n",
       "\t\t<dd>26.3039455845149</dd>\n",
       "\t<dt>$Tile_cutoff_SE</dt>\n",
       "\t\t<dd><table>\n",
       "<tbody>\n",
       "\t<tr><td>3.554549</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$Accuracy] 0.80379746835443\n",
       "\\item[\\$Balanced\\_acc] 0.766321913380737\n",
       "\\item[\\$Precision\\_long] 0.58695652173913\n",
       "\\item[\\$Precision\\_short] 0.892857142857143\n",
       "\\item[\\$Recall\\_long] 0.692307692307692\n",
       "\\item[\\$Recall\\_short] 0.840336134453782\n",
       "\\item[\\$F1\\_long] 0.635294117647059\n",
       "\\item[\\$F1\\_short] 0.865800865800866\n",
       "\\item[\\$Tile\\_cutoff] 26.3039455845149\n",
       "\\item[\\$Tile\\_cutoff\\_SE] \\begin{tabular}{l}\n",
       "\t 3.554549\\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$Accuracy\n",
       ":   0.80379746835443\n",
       "$Balanced_acc\n",
       ":   0.766321913380737\n",
       "$Precision_long\n",
       ":   0.58695652173913\n",
       "$Precision_short\n",
       ":   0.892857142857143\n",
       "$Recall_long\n",
       ":   0.692307692307692\n",
       "$Recall_short\n",
       ":   0.840336134453782\n",
       "$F1_long\n",
       ":   0.635294117647059\n",
       "$F1_short\n",
       ":   0.865800865800866\n",
       "$Tile_cutoff\n",
       ":   26.3039455845149\n",
       "$Tile_cutoff_SE\n",
       ":   \n",
       "| 3.554549 |\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$Accuracy\n",
       "[1] 0.8037975\n",
       "\n",
       "$Balanced_acc\n",
       "[1] 0.7663219\n",
       "\n",
       "$Precision_long\n",
       "[1] 0.5869565\n",
       "\n",
       "$Precision_short\n",
       "[1] 0.8928571\n",
       "\n",
       "$Recall_long\n",
       "[1] 0.6923077\n",
       "\n",
       "$Recall_short\n",
       "[1] 0.8403361\n",
       "\n",
       "$F1_long\n",
       "[1] 0.6352941\n",
       "\n",
       "$F1_short\n",
       "[1] 0.8658009\n",
       "\n",
       "$Tile_cutoff\n",
       "[1] 26.30395\n",
       "\n",
       "$Tile_cutoff_SE\n",
       "         [,1]\n",
       "[1,] 3.554549\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   0   1\n",
       "         0 100  12\n",
       "         1  19  27\n",
       "                                          \n",
       "               Accuracy : 0.8038          \n",
       "                 95% CI : (0.7332, 0.8626)\n",
       "    No Information Rate : 0.7532          \n",
       "    P-Value [Acc > NIR] : 0.08073         \n",
       "                                          \n",
       "                  Kappa : 0.5023          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.28120         \n",
       "                                          \n",
       "            Sensitivity : 0.8403          \n",
       "            Specificity : 0.6923          \n",
       "         Pos Pred Value : 0.8929          \n",
       "         Neg Pred Value : 0.5870          \n",
       "             Prevalence : 0.7532          \n",
       "         Detection Rate : 0.6329          \n",
       "   Detection Prevalence : 0.7089          \n",
       "      Balanced Accuracy : 0.7663          \n",
       "                                          \n",
       "       'Positive' Class : 0               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# M>=3cm\n",
    "\n",
    "print('Logistic regression M>=3cm performance on BEST3 test set:')\n",
    "\n",
    "# Train full BEST2 model\n",
    "logreg_m_gtet_3cm_best2 <- glm(PRAGUE_M_gtet_3cm ~ TFF3_positive_count, family='binomial', data = best2_tff3_prague_data)\n",
    "\n",
    "# Infer model on BEST3 data\n",
    "logreg_m_gtet_3cm_pred_best3 <- predict(logreg_m_gtet_3cm_best2, newdata=data.frame(TFF3_positive_count=best3_tff3_prague_data$TFF3_positive_count), type='response')\n",
    "\n",
    "# Print performance results\n",
    "METRIFY(best3_tff3_prague_data$PRAGUE_M_gtet_3cm, logreg_m_gtet_3cm_pred_best3, logreg_m_gtet_3cm_best2)\n",
    "\n",
    "# Make confusion matrix\n",
    "confusionMatrix(factor(ifelse(logreg_m_gtet_3cm_pred_best3 >= 0.5, 1, 0)), \n",
    "                factor(best3_tff3_prague_data$PRAGUE_M_gtet_3cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4960123f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression M>=4cm performance on BEST3 test set:\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“glm.fit: fitted probabilities numerically 0 or 1 occurred”"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$Accuracy</dt>\n",
       "\t\t<dd>0.873417721518987</dd>\n",
       "\t<dt>$Balanced_acc</dt>\n",
       "\t\t<dd>0.754370629370629</dd>\n",
       "\t<dt>$Precision_long</dt>\n",
       "\t\t<dd>0.625</dd>\n",
       "\t<dt>$Precision_short</dt>\n",
       "\t\t<dd>0.917910447761194</dd>\n",
       "\t<dt>$Recall_long</dt>\n",
       "\t\t<dd>0.576923076923077</dd>\n",
       "\t<dt>$Recall_short</dt>\n",
       "\t\t<dd>0.931818181818182</dd>\n",
       "\t<dt>$F1_long</dt>\n",
       "\t\t<dd>0.6</dd>\n",
       "\t<dt>$F1_short</dt>\n",
       "\t\t<dd>0.924812030075188</dd>\n",
       "\t<dt>$Tile_cutoff</dt>\n",
       "\t\t<dd>63.6189079297109</dd>\n",
       "\t<dt>$Tile_cutoff_SE</dt>\n",
       "\t\t<dd><table>\n",
       "<tbody>\n",
       "\t<tr><td>7.07142</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$Accuracy] 0.873417721518987\n",
       "\\item[\\$Balanced\\_acc] 0.754370629370629\n",
       "\\item[\\$Precision\\_long] 0.625\n",
       "\\item[\\$Precision\\_short] 0.917910447761194\n",
       "\\item[\\$Recall\\_long] 0.576923076923077\n",
       "\\item[\\$Recall\\_short] 0.931818181818182\n",
       "\\item[\\$F1\\_long] 0.6\n",
       "\\item[\\$F1\\_short] 0.924812030075188\n",
       "\\item[\\$Tile\\_cutoff] 63.6189079297109\n",
       "\\item[\\$Tile\\_cutoff\\_SE] \\begin{tabular}{l}\n",
       "\t 7.07142\\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$Accuracy\n",
       ":   0.873417721518987\n",
       "$Balanced_acc\n",
       ":   0.754370629370629\n",
       "$Precision_long\n",
       ":   0.625\n",
       "$Precision_short\n",
       ":   0.917910447761194\n",
       "$Recall_long\n",
       ":   0.576923076923077\n",
       "$Recall_short\n",
       ":   0.931818181818182\n",
       "$F1_long\n",
       ":   0.6\n",
       "$F1_short\n",
       ":   0.924812030075188\n",
       "$Tile_cutoff\n",
       ":   63.6189079297109\n",
       "$Tile_cutoff_SE\n",
       ":   \n",
       "| 7.07142 |\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$Accuracy\n",
       "[1] 0.8734177\n",
       "\n",
       "$Balanced_acc\n",
       "[1] 0.7543706\n",
       "\n",
       "$Precision_long\n",
       "[1] 0.625\n",
       "\n",
       "$Precision_short\n",
       "[1] 0.9179104\n",
       "\n",
       "$Recall_long\n",
       "[1] 0.5769231\n",
       "\n",
       "$Recall_short\n",
       "[1] 0.9318182\n",
       "\n",
       "$F1_long\n",
       "[1] 0.6\n",
       "\n",
       "$F1_short\n",
       "[1] 0.924812\n",
       "\n",
       "$Tile_cutoff\n",
       "[1] 63.61891\n",
       "\n",
       "$Tile_cutoff_SE\n",
       "        [,1]\n",
       "[1,] 7.07142\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   0   1\n",
       "         0 123  11\n",
       "         1   9  15\n",
       "                                          \n",
       "               Accuracy : 0.8734          \n",
       "                 95% CI : (0.8113, 0.9209)\n",
       "    No Information Rate : 0.8354          \n",
       "    P-Value [Acc > NIR] : 0.1167          \n",
       "                                          \n",
       "                  Kappa : 0.525           \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.8231          \n",
       "                                          \n",
       "            Sensitivity : 0.9318          \n",
       "            Specificity : 0.5769          \n",
       "         Pos Pred Value : 0.9179          \n",
       "         Neg Pred Value : 0.6250          \n",
       "             Prevalence : 0.8354          \n",
       "         Detection Rate : 0.7785          \n",
       "   Detection Prevalence : 0.8481          \n",
       "      Balanced Accuracy : 0.7544          \n",
       "                                          \n",
       "       'Positive' Class : 0               \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# M>=4cm\n",
    "\n",
    "print('Logistic regression M>=4cm performance on BEST3 test set:')\n",
    "\n",
    "# Train full BEST2 model\n",
    "logreg_m_gtet_4cm_best2 <- glm(PRAGUE_M_gtet_4cm ~ TFF3_positive_count, family='binomial', data = best2_tff3_prague_data)\n",
    "\n",
    "# Infer msodel on BEST3 data\n",
    "logreg_m_gtet_4cm_pred_best3 <- predict(logreg_m_gtet_4cm_best2, newdata=data.frame(TFF3_positive_count=best3_tff3_prague_data$TFF3_positive_count), type='response')\n",
    "\n",
    "# Print performance results\n",
    "METRIFY(best3_tff3_prague_data$PRAGUE_M_gtet_4cm, logreg_m_gtet_4cm_pred_best3, logreg_m_gtet_4cm_best2)\n",
    "\n",
    "# Make confusion matrix\n",
    "confusionMatrix(factor(ifelse(logreg_m_gtet_4cm_pred_best3 >= 0.5, 1, 0)), \n",
    "                factor(best3_tff3_prague_data$PRAGUE_M_gtet_4cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a2eee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Logistic regression M>=5cm performance on BEST3 test set:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$Accuracy</dt>\n",
       "\t\t<dd>0.89873417721519</dd>\n",
       "\t<dt>$Balanced_acc</dt>\n",
       "\t\t<dd>0.652380952380952</dd>\n",
       "\t<dt>$Precision_long</dt>\n",
       "\t\t<dd>0.6</dd>\n",
       "\t<dt>$Precision_short</dt>\n",
       "\t\t<dd>0.918918918918919</dd>\n",
       "\t<dt>$Recall_long</dt>\n",
       "\t\t<dd>0.333333333333333</dd>\n",
       "\t<dt>$Recall_short</dt>\n",
       "\t\t<dd>0.971428571428571</dd>\n",
       "\t<dt>$F1_long</dt>\n",
       "\t\t<dd>0.428571428571429</dd>\n",
       "\t<dt>$F1_short</dt>\n",
       "\t\t<dd>0.944444444444445</dd>\n",
       "\t<dt>$Tile_cutoff</dt>\n",
       "\t\t<dd>159.377132545881</dd>\n",
       "\t<dt>$Tile_cutoff_SE</dt>\n",
       "\t\t<dd><table>\n",
       "<tbody>\n",
       "\t<tr><td>18.13779</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$Accuracy] 0.89873417721519\n",
       "\\item[\\$Balanced\\_acc] 0.652380952380952\n",
       "\\item[\\$Precision\\_long] 0.6\n",
       "\\item[\\$Precision\\_short] 0.918918918918919\n",
       "\\item[\\$Recall\\_long] 0.333333333333333\n",
       "\\item[\\$Recall\\_short] 0.971428571428571\n",
       "\\item[\\$F1\\_long] 0.428571428571429\n",
       "\\item[\\$F1\\_short] 0.944444444444445\n",
       "\\item[\\$Tile\\_cutoff] 159.377132545881\n",
       "\\item[\\$Tile\\_cutoff\\_SE] \\begin{tabular}{l}\n",
       "\t 18.13779\\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$Accuracy\n",
       ":   0.89873417721519\n",
       "$Balanced_acc\n",
       ":   0.652380952380952\n",
       "$Precision_long\n",
       ":   0.6\n",
       "$Precision_short\n",
       ":   0.918918918918919\n",
       "$Recall_long\n",
       ":   0.333333333333333\n",
       "$Recall_short\n",
       ":   0.971428571428571\n",
       "$F1_long\n",
       ":   0.428571428571429\n",
       "$F1_short\n",
       ":   0.944444444444445\n",
       "$Tile_cutoff\n",
       ":   159.377132545881\n",
       "$Tile_cutoff_SE\n",
       ":   \n",
       "| 18.13779 |\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$Accuracy\n",
       "[1] 0.8987342\n",
       "\n",
       "$Balanced_acc\n",
       "[1] 0.652381\n",
       "\n",
       "$Precision_long\n",
       "[1] 0.6\n",
       "\n",
       "$Precision_short\n",
       "[1] 0.9189189\n",
       "\n",
       "$Recall_long\n",
       "[1] 0.3333333\n",
       "\n",
       "$Recall_short\n",
       "[1] 0.9714286\n",
       "\n",
       "$F1_long\n",
       "[1] 0.4285714\n",
       "\n",
       "$F1_short\n",
       "[1] 0.9444444\n",
       "\n",
       "$Tile_cutoff\n",
       "[1] 159.3771\n",
       "\n",
       "$Tile_cutoff_SE\n",
       "         [,1]\n",
       "[1,] 18.13779\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction   0   1\n",
       "         0 136  12\n",
       "         1   4   6\n",
       "                                         \n",
       "               Accuracy : 0.8987         \n",
       "                 95% CI : (0.8408, 0.941)\n",
       "    No Information Rate : 0.8861         \n",
       "    P-Value [Acc > NIR] : 0.36421        \n",
       "                                         \n",
       "                  Kappa : 0.378          \n",
       "                                         \n",
       " Mcnemar's Test P-Value : 0.08012        \n",
       "                                         \n",
       "            Sensitivity : 0.9714         \n",
       "            Specificity : 0.3333         \n",
       "         Pos Pred Value : 0.9189         \n",
       "         Neg Pred Value : 0.6000         \n",
       "             Prevalence : 0.8861         \n",
       "         Detection Rate : 0.8608         \n",
       "   Detection Prevalence : 0.9367         \n",
       "      Balanced Accuracy : 0.6524         \n",
       "                                         \n",
       "       'Positive' Class : 0              \n",
       "                                         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# M>=5cm\n",
    "\n",
    "print('Logistic regression M>=5cm performance on BEST3 test set:')\n",
    "\n",
    "# Train full BEST2 model\n",
    "logreg_m_gtet_5cm_best2 <- glm(PRAGUE_M_gtet_5cm ~ TFF3_positive_count, family='binomial', data = best2_tff3_prague_data)\n",
    "\n",
    "# Infer model on BEST3 data\n",
    "logreg_m_gtet_5cm_pred_best3 <- predict(logreg_m_gtet_5cm_best2, newdata=data.frame(TFF3_positive_count=best3_tff3_prague_data$TFF3_positive_count), type='response')\n",
    "\n",
    "# Print performance results\n",
    "METRIFY(best3_tff3_prague_data$PRAGUE_M_gtet_5cm, logreg_m_gtet_5cm_pred_best3, logreg_m_gtet_5cm_best2)\n",
    "\n",
    "# Make confusion matrix\n",
    "confusionMatrix(factor(ifelse(logreg_m_gtet_5cm_pred_best3 >= 0.5, 1, 0)), \n",
    "                factor(best3_tff3_prague_data$PRAGUE_M_gtet_5cm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
